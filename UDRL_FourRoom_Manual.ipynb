{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "import torch.nn.functional as F\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from minigrid.wrappers import RGBImgObsWrapper\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import pygame\n",
    "from minigrid.core.constants import COLOR_NAMES\n",
    "from minigrid.core.grid import Grid\n",
    "from minigrid.core.mission import MissionSpace\n",
    "from minigrid.core.world_object import Goal, Wall\n",
    "from minigrid.manual_control import ManualControl\n",
    "from minigrid.minigrid_env import MiniGridEnv\n",
    "import random\n",
    "from minigrid.wrappers import RGBImgObsWrapper\n",
    "import pickle\n",
    "from env import FourRoomsEnv"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "initial_id",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "horizon_scale = 0.02\n",
    "return_scale = 0.02\n",
    "replay_size = 100000\n",
    "n_updates_per_iter = 200\n",
    "n_episodes_per_iter = 20\n",
    "last_few = 50\n",
    "batch_size = 32\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T13:21:05.300960Z",
     "start_time": "2024-07-09T13:21:05.297362Z"
    }
   },
   "id": "e19d8f5f86a45ad1",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class BF(nn.Module):\n",
    "    def __init__(self, obs_space, action_space, hidden_size, seed):\n",
    "        super(BF, self).__init__()\n",
    "        torch.manual_seed(seed)\n",
    "        # CNN\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        \n",
    "        conv_output_size = self._get_conv_output_size(obs_space)\n",
    "        \n",
    "        # fc_img\n",
    "        self.fc1 = nn.Linear(conv_output_size, hidden_size)\n",
    "        \n",
    "        # fc_command\n",
    "        self.commands = nn.Linear(2, hidden_size)\n",
    "        \n",
    "        # fc_combined\n",
    "        self.fc_comb = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, action_space)\n",
    "\n",
    "    def _get_conv_output_size(self, obs_space):\n",
    "        with torch.no_grad():\n",
    "            input = torch.zeros(1,obs_space[2], obs_space[0], obs_space[1])\n",
    "            output = self.conv1(input)\n",
    "            output = self.relu(output)\n",
    "            output = self.conv2(output)\n",
    "            output = self.relu(output)\n",
    "            output = self.pool(output)\n",
    "            output = output.view(1, -1)\n",
    "        return output.size(1) \n",
    "        \n",
    "    def forward(self, state, command):\n",
    "        state = self.relu(self.conv1(state))\n",
    "        state = self.relu(self.conv2(state))\n",
    "        state = self.pool(state)\n",
    "        state = state.view(state.size(0), -1)\n",
    "        \n",
    "        state_out = self.relu(self.fc1(state))\n",
    "        command_out = self.relu(self.commands(command))\n",
    "        \n",
    "        combined = torch.cat((state_out, command_out), dim=1)\n",
    "        combined = self.relu(self.fc_comb(combined))\n",
    "        \n",
    "        combined = self.relu(self.fc2(combined))\n",
    "        action_probs = self.fc3(combined)\n",
    "        return action_probs\n",
    "\n",
    "    \n",
    "    def action(self, state, desire, horizon):\n",
    "        command = torch.cat((desire * return_scale, horizon * horizon_scale), dim=-1).unsqueeze(0)\n",
    "        action_prob = self.forward(state, command)\n",
    "        probs = torch.softmax(action_prob, dim=-1)\n",
    "        m = Categorical(probs)\n",
    "        action = m.sample()\n",
    "        return action\n",
    "    \n",
    "    \n",
    "    def greedy_action(self, state, desire, horizon):\n",
    "        command = torch.cat((desire * return_scale, horizon * horizon_scale), dim=-1).unsqueeze(0)\n",
    "        action_prob = self.forward(state, command)\n",
    "        probs = torch.softmax(action_prob, dim=-1)\n",
    "        action = torch.argmax(probs).item()\n",
    "        return action"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T13:21:05.312505Z",
     "start_time": "2024-07-09T13:21:05.301954Z"
    }
   },
   "id": "832c8d2412194739",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class ReplayBuffer():\n",
    "    def __init__(self, max_size):\n",
    "        self.max_size = max_size\n",
    "        self.buffer = []\n",
    "\n",
    "    def add_sample(self, states, actions, rewards):\n",
    "        episode = {\"states\": states, \"actions\": actions, \"rewards\": rewards, \"summed_rewards\": sum(rewards)}\n",
    "        self.buffer.append(episode)\n",
    "        if len(self.buffer) > self.max_size:\n",
    "            self.buffer.sort(key=lambda i: i[\"summed_rewards\"], reverse=True)\n",
    "            self.buffer = self.buffer[:self.max_size]\n",
    "\n",
    "    def get_random_samples(self, batch_size):\n",
    "        if batch_size > len(self.buffer):\n",
    "            raise ValueError(\"Batch size larger than buffer size.\")\n",
    "        return random.sample(self.buffer, batch_size)\n",
    "\n",
    "    def get_nbest(self, n):\n",
    "        if n > len(self.buffer):\n",
    "            raise ValueError(\"n is larger than buffer size.\")\n",
    "        self.buffer.sort(key=lambda i: i[\"summed_rewards\"], reverse=True)\n",
    "        return self.buffer[:n]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "    \n",
    "    # clear the buffer \n",
    "    def clear(self):\n",
    "        self.buffer = []\n",
    "        print(\"Buffer has been cleared.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T13:21:05.325530Z",
     "start_time": "2024-07-09T13:21:05.319481Z"
    }
   },
   "id": "9295c24d81edd24d",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def load_data_to_replay_buffer(buffer, filename=\" \"):\n",
    "    with open(filename, 'rb') as f:\n",
    "        recorded_data = pickle.load(f)\n",
    "\n",
    "    for episode in recorded_data:\n",
    "        states, actions, rewards = episode\n",
    "        buffer.add_sample(states, actions, rewards)\n",
    "    \n",
    "    return 'Successfully Loading to Replay buffer'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T13:21:05.342158Z",
     "start_time": "2024-07-09T13:21:05.338493Z"
    }
   },
   "id": "4a7510b2e48cc385",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 220 episodes into the ReplayBuffer.\n",
      "Observation space: (104, 104, 3)\n",
      "Action space: 3\n",
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "env = FourRoomsEnv(render_mode=\"human\")\n",
    "env = RGBImgObsWrapper(env)\n",
    "action_space = 3\n",
    "obs_space = env.observation_space['image'].shape\n",
    "\n",
    "buffer = ReplayBuffer(replay_size)\n",
    "bf = BF(obs_space, action_space, 64, 1).to(device)\n",
    "load_data_to_replay_buffer(buffer, filename=\"fourRoomRecord.pkl\")\n",
    "optimizer = optim.Adam(params=bf.parameters(), lr=1e-3)\n",
    "\n",
    "print(f\"Loaded {len(buffer)} episodes into the ReplayBuffer.\")\n",
    "print(f\"Observation space: {obs_space}\")\n",
    "print(f\"Action space: {action_space}\")\n",
    "print(f\"Device: {device}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T13:21:06.105667Z",
     "start_time": "2024-07-09T13:21:05.356116Z"
    }
   },
   "id": "776e95d3bcd0c2cc",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[ 0.0992, -0.0849, -0.0373],\n",
      "          [ 0.0903, -0.1812,  0.1154],\n",
      "          [-0.0396,  0.0979,  0.0268]],\n",
      "\n",
      "         [[-0.0236,  0.0534,  0.0095],\n",
      "          [ 0.0703, -0.0750, -0.0140],\n",
      "          [-0.0173,  0.0279, -0.0008]],\n",
      "\n",
      "         [[ 0.1682,  0.0599, -0.0717],\n",
      "          [-0.1162, -0.0323, -0.0830],\n",
      "          [-0.0617,  0.0092,  0.1147]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1046, -0.1881,  0.1193],\n",
      "          [ 0.0538,  0.1825,  0.1270],\n",
      "          [-0.1753, -0.1830, -0.0928]],\n",
      "\n",
      "         [[ 0.1690, -0.0321,  0.0824],\n",
      "          [-0.0894,  0.1888, -0.0814],\n",
      "          [ 0.1443,  0.0023, -0.1014]],\n",
      "\n",
      "         [[ 0.0989, -0.1022,  0.0566],\n",
      "          [-0.0556, -0.0211, -0.1850],\n",
      "          [-0.0918,  0.1044, -0.0468]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1917,  0.1543, -0.0090],\n",
      "          [-0.1285,  0.1172,  0.0597],\n",
      "          [-0.1244,  0.1250,  0.1168]],\n",
      "\n",
      "         [[ 0.1707, -0.1079, -0.0317],\n",
      "          [-0.0037,  0.0281, -0.1461],\n",
      "          [-0.1366,  0.1047, -0.0451]],\n",
      "\n",
      "         [[ 0.0940,  0.0110,  0.0632],\n",
      "          [ 0.0423,  0.0700,  0.0954],\n",
      "          [-0.1782,  0.0969, -0.1353]]],\n",
      "\n",
      "\n",
      "        [[[-0.1452,  0.0117, -0.0328],\n",
      "          [ 0.1130, -0.1115, -0.1711],\n",
      "          [ 0.1401, -0.0285,  0.1082]],\n",
      "\n",
      "         [[ 0.0619, -0.1443,  0.0387],\n",
      "          [ 0.0462, -0.1289, -0.0913],\n",
      "          [ 0.0656,  0.0345, -0.0819]],\n",
      "\n",
      "         [[-0.0583,  0.1763, -0.0356],\n",
      "          [ 0.1085,  0.0833, -0.1244],\n",
      "          [-0.1637,  0.1847,  0.0100]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1319,  0.0399,  0.0619],\n",
      "          [ 0.1438,  0.1825, -0.1277],\n",
      "          [ 0.0241,  0.1436,  0.1394]],\n",
      "\n",
      "         [[ 0.1196, -0.1393, -0.1386],\n",
      "          [-0.1164,  0.0242,  0.1918],\n",
      "          [-0.1216,  0.1026, -0.1065]],\n",
      "\n",
      "         [[-0.1809, -0.0409,  0.1109],\n",
      "          [ 0.1787, -0.1195,  0.0418],\n",
      "          [ 0.1661,  0.1275,  0.1199]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1368,  0.1217,  0.0497],\n",
      "          [-0.1316, -0.1616, -0.0882],\n",
      "          [-0.0224, -0.1180,  0.0704]],\n",
      "\n",
      "         [[ 0.0596, -0.0436,  0.0740],\n",
      "          [ 0.0622,  0.1175,  0.1296],\n",
      "          [-0.0652,  0.1880, -0.0222]],\n",
      "\n",
      "         [[-0.0066, -0.1816, -0.1239],\n",
      "          [-0.1124, -0.0823,  0.1368],\n",
      "          [-0.0629, -0.1438,  0.0740]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0616,  0.1246, -0.0996],\n",
      "          [ 0.0417, -0.0701, -0.0432],\n",
      "          [-0.1534, -0.0877, -0.0589]],\n",
      "\n",
      "         [[ 0.0823,  0.0352,  0.0475],\n",
      "          [ 0.1921,  0.1876,  0.1313],\n",
      "          [ 0.0061, -0.1331,  0.1504]],\n",
      "\n",
      "         [[-0.0481, -0.0156, -0.1658],\n",
      "          [-0.0380, -0.1241,  0.1768],\n",
      "          [-0.1664, -0.1500, -0.0065]]],\n",
      "\n",
      "\n",
      "        [[[-0.1041,  0.0689, -0.0741],\n",
      "          [-0.0904,  0.0109,  0.1393],\n",
      "          [-0.1354,  0.0904,  0.1236]],\n",
      "\n",
      "         [[ 0.1883, -0.1347,  0.0466],\n",
      "          [-0.1423,  0.1643, -0.0747],\n",
      "          [ 0.1159,  0.0057, -0.0150]],\n",
      "\n",
      "         [[-0.0061,  0.0327,  0.0907],\n",
      "          [ 0.0309,  0.0587, -0.1731],\n",
      "          [ 0.1402,  0.1678,  0.1591]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1423, -0.1389, -0.0713],\n",
      "          [ 0.1697, -0.1466,  0.1746],\n",
      "          [-0.1514, -0.1356,  0.0941]],\n",
      "\n",
      "         [[-0.1383, -0.0441,  0.1400],\n",
      "          [ 0.1524,  0.1820, -0.0391],\n",
      "          [-0.1496,  0.1895, -0.0410]],\n",
      "\n",
      "         [[-0.0792,  0.0469, -0.1346],\n",
      "          [ 0.1265,  0.1206, -0.1527],\n",
      "          [-0.1581, -0.0169,  0.0808]]],\n",
      "\n",
      "\n",
      "        [[[-0.0056, -0.0976,  0.0044],\n",
      "          [-0.1809, -0.1360, -0.1281],\n",
      "          [ 0.1585,  0.1696, -0.0654]],\n",
      "\n",
      "         [[ 0.0086,  0.0858,  0.0231],\n",
      "          [-0.0964,  0.1110,  0.1183],\n",
      "          [-0.0112, -0.0237,  0.1749]],\n",
      "\n",
      "         [[ 0.1682, -0.1091,  0.1883],\n",
      "          [ 0.0476, -0.1278,  0.1053],\n",
      "          [-0.1437,  0.1778, -0.1237]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0544,  0.0586,  0.0458],\n",
      "          [ 0.1596, -0.0799, -0.0812],\n",
      "          [-0.1668, -0.0079, -0.0912]],\n",
      "\n",
      "         [[ 0.0077, -0.0395,  0.0639],\n",
      "          [ 0.1665,  0.0568, -0.0620],\n",
      "          [-0.0944, -0.1678,  0.1619]],\n",
      "\n",
      "         [[-0.0365,  0.0388,  0.0071],\n",
      "          [-0.1226,  0.1084,  0.1079],\n",
      "          [ 0.0097, -0.1094, -0.0818]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0027, -0.1100, -0.1074],\n",
      "          [-0.0287, -0.0554,  0.0472],\n",
      "          [-0.0506, -0.0255, -0.0735]],\n",
      "\n",
      "         [[-0.1759,  0.1678,  0.0367],\n",
      "          [ 0.1721, -0.0310, -0.0484],\n",
      "          [-0.1809, -0.0731,  0.1262]],\n",
      "\n",
      "         [[-0.1885, -0.0673,  0.1173],\n",
      "          [ 0.1109,  0.0711, -0.0381],\n",
      "          [-0.0146, -0.0365, -0.0709]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0803, -0.0655, -0.1081],\n",
      "          [ 0.0437, -0.1391, -0.0411],\n",
      "          [ 0.0983,  0.0719,  0.1638]],\n",
      "\n",
      "         [[-0.1313,  0.0017, -0.0568],\n",
      "          [-0.1076, -0.1083,  0.0485],\n",
      "          [ 0.0201, -0.0982, -0.1357]],\n",
      "\n",
      "         [[-0.1595,  0.1886, -0.0328],\n",
      "          [-0.0445, -0.0708, -0.0963],\n",
      "          [-0.1760, -0.1130,  0.1176]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0422, -0.0679, -0.0727],\n",
      "          [ 0.1229,  0.1387,  0.1854],\n",
      "          [ 0.0561,  0.0930, -0.0155]],\n",
      "\n",
      "         [[-0.1125, -0.1885,  0.1172],\n",
      "          [-0.0280,  0.0791,  0.0095],\n",
      "          [-0.1796, -0.0944,  0.0541]],\n",
      "\n",
      "         [[-0.0390, -0.1858,  0.0675],\n",
      "          [ 0.0074, -0.0618,  0.0777],\n",
      "          [ 0.0406, -0.0710,  0.1729]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0965,  0.0242, -0.0370],\n",
      "          [-0.1630,  0.1486, -0.0497],\n",
      "          [-0.1244,  0.1234,  0.0683]],\n",
      "\n",
      "         [[ 0.0476, -0.0382, -0.0601],\n",
      "          [ 0.0327,  0.1489,  0.0276],\n",
      "          [-0.0910,  0.1912,  0.0041]],\n",
      "\n",
      "         [[ 0.1521,  0.0469,  0.1725],\n",
      "          [ 0.1110, -0.0981,  0.1352],\n",
      "          [ 0.0012, -0.1545, -0.0403]]],\n",
      "\n",
      "\n",
      "        [[[-0.1737, -0.0997, -0.1363],\n",
      "          [ 0.1316, -0.0404, -0.0333],\n",
      "          [ 0.0922,  0.0783, -0.1270]],\n",
      "\n",
      "         [[ 0.0709,  0.0818, -0.1530],\n",
      "          [ 0.1673, -0.1171, -0.0753],\n",
      "          [-0.1585,  0.1759,  0.0366]],\n",
      "\n",
      "         [[ 0.1620,  0.0126,  0.1046],\n",
      "          [-0.0614, -0.1535,  0.0309],\n",
      "          [-0.0172, -0.0194, -0.0945]]]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0040,  0.0553,  0.0694, -0.1550,  0.0930,  0.0198,  0.1327,  0.1360,\n",
      "        -0.1516,  0.1848, -0.1893,  0.1106,  0.0135,  0.0911, -0.1041,  0.1157],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-4.1236e-02, -7.3658e-02,  2.7919e-02],\n",
      "          [ 4.5613e-02,  8.2605e-02, -8.7094e-03],\n",
      "          [ 8.0165e-02,  5.3536e-02, -4.1330e-02]],\n",
      "\n",
      "         [[-6.4279e-02,  4.6739e-02, -4.5656e-02],\n",
      "          [ 3.8225e-02, -7.1370e-02,  6.0797e-02],\n",
      "          [ 2.4976e-02, -9.5802e-03,  3.8219e-02]],\n",
      "\n",
      "         [[-5.9329e-02, -1.8217e-02,  8.1695e-04],\n",
      "          [-4.8152e-02, -2.1294e-02, -3.5938e-02],\n",
      "          [ 7.9420e-02,  7.0795e-02,  7.1873e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.7679e-04, -5.4447e-02, -4.7589e-02],\n",
      "          [ 1.7646e-02, -1.1904e-03,  5.8979e-02],\n",
      "          [-1.2633e-02, -6.7508e-02, -6.1634e-02]],\n",
      "\n",
      "         [[-2.4460e-02, -1.8456e-02,  9.5102e-03],\n",
      "          [-1.8689e-02,  3.0748e-02, -2.7715e-02],\n",
      "          [ 6.1163e-02,  1.9141e-02, -2.5620e-02]],\n",
      "\n",
      "         [[ 7.4267e-02,  2.1274e-02, -5.6633e-02],\n",
      "          [-4.6379e-02,  5.2251e-02,  3.8060e-02],\n",
      "          [ 6.5066e-02, -6.4013e-03,  5.8285e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.1432e-02,  2.5771e-02, -1.9287e-02],\n",
      "          [ 8.0332e-02,  1.6864e-02, -2.1501e-02],\n",
      "          [-1.1848e-03,  8.1921e-02,  5.5971e-02]],\n",
      "\n",
      "         [[-6.1755e-03,  8.1697e-02,  3.6595e-02],\n",
      "          [-4.4368e-02, -7.5839e-02,  4.8428e-02],\n",
      "          [ 7.8153e-02, -4.8552e-02,  3.4227e-02]],\n",
      "\n",
      "         [[ 3.5476e-03, -1.7818e-02, -2.2659e-02],\n",
      "          [ 2.3183e-02,  1.8371e-02,  5.6284e-02],\n",
      "          [ 3.0506e-02,  3.7921e-02,  7.3513e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.3725e-02, -1.7308e-02, -1.5984e-02],\n",
      "          [ 7.1117e-02, -4.3101e-02, -4.7761e-02],\n",
      "          [ 1.3038e-03, -1.9358e-02,  3.1543e-02]],\n",
      "\n",
      "         [[ 1.0129e-02, -4.9754e-02,  6.0596e-02],\n",
      "          [ 5.1873e-02,  1.8249e-02, -7.5427e-02],\n",
      "          [ 3.9160e-02,  5.5372e-02,  2.3200e-02]],\n",
      "\n",
      "         [[-3.2212e-02,  5.5889e-03, -3.2013e-02],\n",
      "          [ 7.8455e-02,  8.0468e-02, -9.7112e-03],\n",
      "          [-5.6066e-02,  4.9021e-02,  4.2532e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.4173e-02, -6.2704e-02,  2.8257e-02],\n",
      "          [-3.5563e-02, -7.3246e-02, -5.8190e-02],\n",
      "          [ 3.5326e-02,  3.1198e-02, -7.3139e-02]],\n",
      "\n",
      "         [[ 4.7256e-02,  6.3853e-02,  6.3261e-02],\n",
      "          [ 4.7054e-02, -1.3082e-02,  5.5839e-02],\n",
      "          [ 6.5240e-02,  4.3440e-02, -5.9938e-02]],\n",
      "\n",
      "         [[-2.9084e-02,  6.6018e-02,  6.3531e-02],\n",
      "          [ 5.3173e-02, -3.4830e-02, -1.6504e-02],\n",
      "          [-6.2084e-02, -4.7492e-02,  6.3969e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2137e-02, -4.2577e-02,  2.6227e-02],\n",
      "          [-6.9713e-02, -6.5555e-02, -4.7291e-02],\n",
      "          [-7.2986e-02,  5.2606e-02, -1.1926e-02]],\n",
      "\n",
      "         [[-4.6299e-02,  5.8394e-02, -1.8906e-02],\n",
      "          [ 4.3099e-02, -2.5832e-02, -6.9721e-02],\n",
      "          [ 1.8302e-02,  5.1891e-02, -8.1253e-02]],\n",
      "\n",
      "         [[ 8.6747e-03,  1.6609e-02,  9.5646e-03],\n",
      "          [-2.0621e-03, -2.5904e-02, -6.4695e-02],\n",
      "          [ 1.3592e-02, -5.5968e-02, -6.8854e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.4361e-02,  2.7676e-02,  2.7546e-02],\n",
      "          [ 1.8205e-02,  7.7608e-02,  7.2861e-02],\n",
      "          [-6.9361e-02,  2.1804e-02,  2.3218e-02]],\n",
      "\n",
      "         [[ 1.1797e-02, -2.7284e-02,  3.4267e-02],\n",
      "          [-2.5358e-02,  4.0662e-02,  2.1544e-02],\n",
      "          [ 5.3429e-02, -6.6555e-03, -2.2214e-02]],\n",
      "\n",
      "         [[ 6.4299e-02,  5.3020e-02,  2.9579e-02],\n",
      "          [-7.9903e-02,  3.4290e-02,  6.9229e-03],\n",
      "          [-8.2450e-02, -8.1643e-02,  1.2222e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.8976e-02, -7.7797e-02,  6.8023e-02],\n",
      "          [-4.4994e-02,  7.2360e-02, -5.8193e-02],\n",
      "          [ 4.1991e-02, -3.1752e-02,  6.0065e-02]],\n",
      "\n",
      "         [[ 8.0192e-02,  7.0460e-02, -4.2308e-02],\n",
      "          [-2.3139e-02, -5.2968e-02, -1.3790e-02],\n",
      "          [ 2.5274e-02,  5.7221e-02, -3.9782e-02]],\n",
      "\n",
      "         [[ 5.3617e-02, -1.7267e-02,  1.8678e-03],\n",
      "          [-5.4723e-02,  1.9575e-02,  1.0474e-02],\n",
      "          [ 5.4238e-02,  5.9764e-02,  6.7933e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.8543e-02, -1.7535e-03,  4.9787e-02],\n",
      "          [ 6.2174e-02,  5.9168e-02,  5.3224e-02],\n",
      "          [-2.7197e-02,  3.4544e-03, -3.3822e-02]],\n",
      "\n",
      "         [[ 4.2024e-02, -1.9306e-02, -8.2262e-02],\n",
      "          [-3.6150e-02, -6.3796e-02,  1.7668e-02],\n",
      "          [ 6.0293e-02, -4.0970e-03, -3.3787e-02]],\n",
      "\n",
      "         [[-2.5967e-02, -6.6704e-02,  3.7372e-02],\n",
      "          [ 4.9059e-02, -5.9161e-02,  5.9735e-02],\n",
      "          [ 2.8557e-02, -7.3186e-02,  5.0660e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.9413e-02, -2.3697e-03, -8.2830e-02],\n",
      "          [ 3.3907e-02, -3.3039e-02, -4.4618e-02],\n",
      "          [ 3.2681e-02,  2.1035e-02, -5.1041e-02]],\n",
      "\n",
      "         [[ 3.0136e-02,  1.0460e-02, -2.7138e-02],\n",
      "          [ 5.5860e-02,  2.5282e-03,  3.7339e-02],\n",
      "          [-1.7756e-02,  2.8183e-02,  2.0201e-02]],\n",
      "\n",
      "         [[ 6.4853e-02, -7.2424e-02, -1.8681e-02],\n",
      "          [ 4.4510e-02, -3.8268e-02, -6.0839e-02],\n",
      "          [ 5.3749e-02,  4.2660e-02,  7.6981e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.2285e-02, -2.2336e-02, -6.4659e-02],\n",
      "          [-5.3812e-02,  2.4656e-02, -1.5885e-02],\n",
      "          [ 7.8727e-02,  5.5047e-02,  7.2346e-03]],\n",
      "\n",
      "         [[ 8.0529e-02,  9.2148e-03,  1.7870e-02],\n",
      "          [ 8.1603e-02, -1.0195e-02,  2.5731e-02],\n",
      "          [-5.0756e-03,  7.7287e-02,  3.6662e-02]],\n",
      "\n",
      "         [[-2.7555e-02, -7.3827e-02,  1.0434e-02],\n",
      "          [-2.1619e-04,  3.5970e-02,  3.5168e-02],\n",
      "          [-7.6200e-02, -6.8836e-02, -2.2766e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.1553e-02, -9.2682e-04,  3.1271e-02],\n",
      "          [ 6.0733e-02,  6.4583e-02,  4.9872e-02],\n",
      "          [-4.5359e-05, -3.8887e-02,  5.8853e-02]],\n",
      "\n",
      "         [[ 4.0429e-02,  1.0457e-03,  1.2949e-02],\n",
      "          [ 2.8102e-02, -5.9151e-02, -6.4291e-02],\n",
      "          [-7.0861e-02,  9.9388e-03, -4.7859e-02]],\n",
      "\n",
      "         [[ 5.7980e-03, -6.5297e-02,  5.6802e-02],\n",
      "          [ 5.3100e-02, -2.0140e-02,  1.4892e-02],\n",
      "          [-6.2350e-03, -1.6070e-02,  6.2642e-02]]]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 7.5208e-02,  6.0345e-02, -6.7575e-02,  6.0818e-02,  5.0601e-02,\n",
      "        -1.6820e-02,  3.9552e-02,  9.2583e-03, -5.7397e-02, -5.1667e-02,\n",
      "        -2.3832e-02,  4.6532e-02, -3.6022e-03, -3.6833e-02,  7.7483e-02,\n",
      "         5.6653e-02,  2.8858e-02, -7.5291e-02,  3.3715e-02,  8.1460e-02,\n",
      "        -2.3700e-02, -3.9066e-02, -3.7014e-05, -1.8971e-02,  6.5050e-02,\n",
      "         7.8124e-02,  6.9410e-02, -3.2817e-02, -6.0212e-02,  3.3155e-03,\n",
      "        -6.3481e-02, -4.8421e-03], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-1.7394e-03,  1.5623e-03,  3.1037e-03,  ...,  1.7535e-03,\n",
      "         -8.2979e-04,  3.7567e-04],\n",
      "        [ 2.4900e-03, -1.1212e-03, -1.7239e-03,  ..., -1.4752e-03,\n",
      "         -5.0500e-04, -2.7525e-03],\n",
      "        [ 4.9736e-05, -2.0141e-03,  2.0003e-04,  ..., -5.9528e-04,\n",
      "         -4.4823e-04, -2.9627e-03],\n",
      "        ...,\n",
      "        [-1.5241e-03, -5.8839e-04, -5.5181e-04,  ...,  3.0132e-03,\n",
      "         -8.1285e-04,  2.7092e-03],\n",
      "        [ 3.1326e-03, -6.8393e-04, -2.1550e-03,  ..., -2.5760e-04,\n",
      "          1.0877e-03, -2.0006e-03],\n",
      "        [-6.6697e-04,  4.2340e-04, -1.7375e-03,  ..., -3.0531e-03,\n",
      "          3.2045e-03,  2.7390e-03]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-1.7243e-03,  1.3896e-03,  2.6753e-03, -2.2707e-03,  1.4352e-03,\n",
      "         1.6539e-03,  7.0894e-04, -3.3279e-04,  1.6567e-04,  2.2987e-03,\n",
      "         3.5001e-04,  6.7254e-04,  2.8798e-03,  2.9434e-03,  2.0488e-03,\n",
      "        -1.8023e-04,  9.2571e-04,  2.2074e-04,  1.8869e-03, -7.9932e-04,\n",
      "         4.7992e-04,  1.6364e-03, -6.7923e-05, -2.5247e-03, -2.5367e-03,\n",
      "        -1.9005e-03,  2.5407e-03, -1.3923e-03,  2.9283e-03,  1.1236e-04,\n",
      "        -3.3770e-04, -2.1596e-04,  7.2075e-05,  2.0589e-03, -1.3933e-03,\n",
      "        -4.4463e-04,  1.3283e-03,  1.1415e-03,  1.8816e-03, -5.3927e-04,\n",
      "        -1.2253e-03, -1.2167e-03, -3.6120e-04, -2.6651e-03,  1.1531e-03,\n",
      "        -2.0723e-03, -2.4994e-04, -5.0322e-04,  1.4842e-03, -6.7827e-04,\n",
      "        -1.5732e-03,  2.7628e-03, -3.2069e-03,  2.8629e-03,  2.1610e-03,\n",
      "        -3.0877e-03,  1.4955e-03,  2.2751e-03, -3.3597e-03,  1.3087e-03,\n",
      "         4.7125e-04,  2.3532e-03,  2.4409e-03,  1.4573e-03], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.4408, -0.6473],\n",
      "        [ 0.2353, -0.6327],\n",
      "        [-0.5640, -0.0163],\n",
      "        [ 0.0913,  0.3283],\n",
      "        [ 0.4684,  0.3873],\n",
      "        [-0.3844,  0.5157],\n",
      "        [ 0.3969,  0.1093],\n",
      "        [ 0.6512, -0.0231],\n",
      "        [-0.2826, -0.1176],\n",
      "        [ 0.6559,  0.3156],\n",
      "        [-0.3919, -0.2793],\n",
      "        [-0.0238, -0.5866],\n",
      "        [-0.2056, -0.0434],\n",
      "        [ 0.0710,  0.5237],\n",
      "        [-0.0704, -0.1586],\n",
      "        [ 0.3653,  0.2536],\n",
      "        [ 0.1220, -0.1743],\n",
      "        [ 0.6151,  0.2980],\n",
      "        [ 0.6748, -0.2162],\n",
      "        [-0.3315,  0.3870],\n",
      "        [-0.6664,  0.3041],\n",
      "        [-0.2115, -0.6322],\n",
      "        [ 0.3219, -0.5125],\n",
      "        [ 0.1220, -0.1061],\n",
      "        [-0.0907, -0.1524],\n",
      "        [ 0.0017,  0.0819],\n",
      "        [ 0.0642,  0.6667],\n",
      "        [ 0.2270,  0.5905],\n",
      "        [ 0.3800, -0.6372],\n",
      "        [ 0.3156,  0.3344],\n",
      "        [ 0.1894, -0.1041],\n",
      "        [ 0.2257,  0.0681],\n",
      "        [ 0.1542, -0.4016],\n",
      "        [-0.0823,  0.4092],\n",
      "        [-0.5192,  0.5769],\n",
      "        [-0.1916, -0.3469],\n",
      "        [ 0.3683, -0.2860],\n",
      "        [ 0.6843, -0.6701],\n",
      "        [-0.6066, -0.3085],\n",
      "        [-0.0753, -0.1131],\n",
      "        [-0.3603,  0.4549],\n",
      "        [-0.7060, -0.6339],\n",
      "        [-0.6918, -0.3144],\n",
      "        [ 0.4147, -0.4014],\n",
      "        [-0.0639,  0.5292],\n",
      "        [ 0.1385, -0.6069],\n",
      "        [ 0.2091, -0.0107],\n",
      "        [ 0.3457, -0.7044],\n",
      "        [-0.5921,  0.4210],\n",
      "        [ 0.4241,  0.1639],\n",
      "        [ 0.0203,  0.3476],\n",
      "        [ 0.0571, -0.5822],\n",
      "        [-0.4677,  0.1651],\n",
      "        [ 0.4061, -0.1004],\n",
      "        [ 0.3075,  0.3693],\n",
      "        [ 0.4124, -0.4846],\n",
      "        [-0.3569, -0.3838],\n",
      "        [-0.5419, -0.4666],\n",
      "        [ 0.6264,  0.4606],\n",
      "        [ 0.3087,  0.1821],\n",
      "        [ 0.3547,  0.1554],\n",
      "        [-0.5981, -0.5285],\n",
      "        [-0.0985,  0.1948],\n",
      "        [ 0.5318, -0.2661]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.3384,  0.5086,  0.2426,  0.1105,  0.1326,  0.2360, -0.2554,  0.1549,\n",
      "        -0.4502,  0.3913, -0.3635, -0.3466, -0.6913,  0.4303,  0.4828, -0.6276,\n",
      "        -0.1637,  0.3546, -0.6075,  0.4706,  0.2057, -0.4841, -0.2159,  0.3032,\n",
      "         0.1382, -0.5882, -0.1987,  0.0571,  0.2487,  0.0939,  0.5135,  0.1397,\n",
      "         0.1434, -0.0199, -0.0324,  0.1978,  0.6479,  0.3130, -0.4428,  0.0306,\n",
      "         0.5266, -0.4798, -0.3811,  0.5016, -0.2734,  0.5000, -0.0545, -0.0817,\n",
      "        -0.4054, -0.4906, -0.3367, -0.5243, -0.3777,  0.3151, -0.4870, -0.2596,\n",
      "        -0.0199,  0.6705,  0.1543,  0.1127, -0.3863,  0.0064,  0.3401, -0.6721],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0673, -0.0016,  0.0712,  ...,  0.0174,  0.0467,  0.0016],\n",
      "        [ 0.0233,  0.0819, -0.0582,  ...,  0.0181,  0.0558,  0.0468],\n",
      "        [-0.0668,  0.0829,  0.0355,  ..., -0.0067,  0.0565,  0.0736],\n",
      "        ...,\n",
      "        [ 0.0189,  0.0557,  0.0649,  ..., -0.0459,  0.0622,  0.0405],\n",
      "        [ 0.0063, -0.0344, -0.0662,  ...,  0.0069,  0.0174, -0.0077],\n",
      "        [ 0.0424, -0.0082, -0.0378,  ..., -0.0458,  0.0409, -0.0475]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0287, -0.0647,  0.0752,  0.0044, -0.0281, -0.0646, -0.0685, -0.0845,\n",
      "         0.0503,  0.0501, -0.0651,  0.0614, -0.0502,  0.0105, -0.0879,  0.0216,\n",
      "         0.0412, -0.0258,  0.0380,  0.0321,  0.0293, -0.0529, -0.0567, -0.0627,\n",
      "         0.0559, -0.0820, -0.0693,  0.0857,  0.0584,  0.0427, -0.0484,  0.0795,\n",
      "         0.0567, -0.0286, -0.0702,  0.0021,  0.0782,  0.0297,  0.0656, -0.0520,\n",
      "         0.0183,  0.0550, -0.0558,  0.0048, -0.0736, -0.0510, -0.0167,  0.0108,\n",
      "        -0.0032, -0.0664, -0.0523, -0.0567,  0.0243, -0.0400, -0.0540, -0.0391,\n",
      "         0.0009,  0.0610,  0.0655, -0.0738, -0.0379,  0.0232, -0.0481,  0.0813],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0390, -0.0007, -0.0832,  ..., -0.1241, -0.1060,  0.1201],\n",
      "        [-0.0513, -0.1135, -0.0094,  ...,  0.0994, -0.0930, -0.0850],\n",
      "        [ 0.0149,  0.0371, -0.0601,  ...,  0.0820, -0.1090, -0.0734],\n",
      "        ...,\n",
      "        [ 0.1141,  0.0178, -0.0219,  ..., -0.0035, -0.0817,  0.0114],\n",
      "        [ 0.0397,  0.1131,  0.0926,  ..., -0.0115, -0.0773, -0.0269],\n",
      "        [-0.1030,  0.0282,  0.0058,  ...,  0.0414, -0.0301,  0.0809]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0928,  0.0673, -0.1180, -0.0214, -0.0038,  0.0664, -0.0937, -0.0865,\n",
      "         0.0022,  0.0111, -0.0448,  0.0355, -0.0722,  0.0292, -0.1008, -0.0728,\n",
      "        -0.0978,  0.1233, -0.1049, -0.0113,  0.0663,  0.0616,  0.0070, -0.0263,\n",
      "         0.0622, -0.0368, -0.0042,  0.0282,  0.0255,  0.0099,  0.0197, -0.0178,\n",
      "        -0.0614, -0.0380,  0.0206, -0.1248, -0.0871,  0.0543,  0.0594,  0.0114,\n",
      "        -0.0133,  0.1102, -0.0636, -0.0844, -0.0590,  0.1171, -0.0520, -0.0665,\n",
      "        -0.0350,  0.0411, -0.1025,  0.0705,  0.0241, -0.1039, -0.0043,  0.0227,\n",
      "         0.0092, -0.0431, -0.0248, -0.0170, -0.1003, -0.0460,  0.0393,  0.0149],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0994,  0.1187, -0.0303,  0.0383,  0.1074,  0.0787,  0.0756, -0.1206,\n",
      "         -0.0232,  0.0039, -0.0047, -0.0411, -0.1025, -0.0318, -0.0539,  0.0197,\n",
      "         -0.0745, -0.0491, -0.0654, -0.1109,  0.1052, -0.0443, -0.0723,  0.0269,\n",
      "         -0.1148, -0.1210,  0.0638, -0.0272,  0.1120, -0.0818, -0.1161,  0.0832,\n",
      "         -0.1201, -0.1030, -0.0059, -0.0580, -0.1128,  0.0114,  0.0995,  0.1218,\n",
      "         -0.0597, -0.1057,  0.0174,  0.0111,  0.0412, -0.1214,  0.0080, -0.0311,\n",
      "          0.0445, -0.0903,  0.0612, -0.1036, -0.0581,  0.0152, -0.0704,  0.0718,\n",
      "          0.0490,  0.1000, -0.0253, -0.0662,  0.0602, -0.0891,  0.0298,  0.0895],\n",
      "        [-0.0327, -0.1219, -0.0873, -0.1053, -0.1104,  0.0530, -0.0948,  0.0536,\n",
      "          0.0991, -0.1101, -0.1099, -0.0212, -0.0799, -0.0391, -0.0161,  0.0384,\n",
      "          0.0880,  0.1046,  0.0477,  0.0611,  0.0171,  0.0291, -0.0441, -0.0662,\n",
      "         -0.1119, -0.0755,  0.0103, -0.0317, -0.0437,  0.0022,  0.0161, -0.1046,\n",
      "         -0.0382, -0.0674, -0.0720, -0.0146,  0.0131, -0.0826,  0.0320,  0.0697,\n",
      "          0.0218, -0.0682, -0.0463, -0.1049, -0.0800,  0.1029,  0.0584, -0.0543,\n",
      "         -0.1048,  0.0753, -0.0542,  0.0411, -0.0122, -0.1060,  0.0349,  0.0511,\n",
      "          0.0554,  0.1024, -0.0684,  0.0699,  0.0542,  0.1070,  0.1163, -0.1233],\n",
      "        [ 0.0424,  0.0483, -0.0872,  0.0811,  0.0082,  0.0681,  0.0435, -0.0498,\n",
      "          0.0191,  0.0184, -0.1000, -0.0511, -0.1246, -0.0989, -0.0241,  0.0500,\n",
      "         -0.0363,  0.0961,  0.0893,  0.0416, -0.0600, -0.0259,  0.1009, -0.1124,\n",
      "          0.0335,  0.0611,  0.0427, -0.0811, -0.1182, -0.0372,  0.0013,  0.0900,\n",
      "          0.0469,  0.0770,  0.0525, -0.0817,  0.0256, -0.0082, -0.0641, -0.1035,\n",
      "          0.0204,  0.0490,  0.0481,  0.0455,  0.1203,  0.0317,  0.0304,  0.0823,\n",
      "          0.0151,  0.0366, -0.0222,  0.0601, -0.1186,  0.0076,  0.0188,  0.0375,\n",
      "          0.0729,  0.1194,  0.0046,  0.1001, -0.0261, -0.0658, -0.0420,  0.1010]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0906, -0.0067,  0.0588], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "## OBSERVE THE WEIGHTS before training\n",
    "for p in bf.parameters():\n",
    "    print(p)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T13:21:06.248819Z",
     "start_time": "2024-07-09T13:21:06.107658Z"
    }
   },
   "id": "62f8539f4431f3b",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# FUNCTIONS FOR Sampling exploration commands\n",
    "def sampling_exploration(top_X_eps=last_few):\n",
    "    \"\"\"\n",
    "    This function calculates the new desired reward and new desired horizon based on the replay buffer.\n",
    "    New desired horizon is calculated by the mean length of the best last X episodes. \n",
    "    New desired reward is sampled from a uniform distribution given the mean and the std calculated from the last best X performances.\n",
    "    where X is the hyperparameter last_few.\n",
    "    \"\"\"\n",
    "    if len(buffer) < top_X_eps:\n",
    "        raise ValueError(\"Not enough episodes in the buffer to sample from.\")\n",
    "\n",
    "    top_X = buffer.get_nbest(top_X_eps)\n",
    "    if not top_X:\n",
    "        return torch.FloatTensor([0]), torch.FloatTensor([0])  # Default or minimal values if no data is available\n",
    "\n",
    "    # The exploratory desired horizon dh0 is set to the mean of the lengths of the selected episodes\n",
    "    new_desired_horizon = np.mean([len(i[\"states\"]) for i in top_X])\n",
    "    # Save all top_X cumulative returns in a list \n",
    "    returns = [i[\"summed_rewards\"] for i in top_X]\n",
    "    # From these returns calculate the mean and std\n",
    "    mean_returns = np.mean(returns)\n",
    "    std_returns = np.std(returns)\n",
    "    # Sample desired reward from a uniform distribution given the mean and the std\n",
    "    new_desired_reward = np.random.uniform(mean_returns, mean_returns + std_returns)\n",
    "\n",
    "    return torch.FloatTensor([new_desired_reward]), torch.FloatTensor([new_desired_horizon])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T13:21:06.254442Z",
     "start_time": "2024-07-09T13:21:06.249784Z"
    }
   },
   "id": "73c86ab216b68af3",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# FUNCTIONS FOR TRAINING\n",
    "def select_time_steps(saved_episode):\n",
    "    \"\"\"\n",
    "    Given a saved episode from the replay buffer, this function samples random time steps (t1 and t2) in that episode:\n",
    "    T = max time horizon in that episode.\n",
    "    Returns t1, t2, and T. Ensures that t1 and t2 are different and t1 < t2.\n",
    "    \"\"\"\n",
    "    T = len(saved_episode[\"states\"])  # episode max horizon\n",
    "    t1 = np.random.randint(0, T - 1)  # Ensure there is at least one step after t1\n",
    "    t2 = np.random.randint(t1 + 1, T)  # Ensure t2 is after t1\n",
    "\n",
    "    return t1, t2, T\n",
    "\n",
    "def create_training_input(episode, t1, t2):\n",
    "    \"\"\"\n",
    "    Based on the selected episode and the given time steps, this function returns 4 values:\n",
    "    1. state at t1\n",
    "    2. the desired reward: sum over all rewards from t1 to t2 (exclusive)\n",
    "    3. the time horizon: t2 - t1\n",
    "    4. the target action taken at t1\n",
    "    \n",
    "    Buffer episodes are structured as [cumulative episode reward, states, actions, rewards].\n",
    "    \"\"\"\n",
    "    state = episode[\"states\"][t1]\n",
    "    desired_reward = sum(episode[\"rewards\"][t1:t2])\n",
    "    time_horizon = t2 - t1\n",
    "    action = episode[\"actions\"][t1]\n",
    "    \n",
    "    return state, desired_reward, time_horizon, action\n",
    "\n",
    "def create_training_examples(batch_size):\n",
    "    \"\"\"\n",
    "    Creates a data set of training examples that can be used to create a data loader for training.\n",
    "    ============================================================\n",
    "    1. For the given batch_size, episode indices are randomly selected.\n",
    "    2. Based on these episodes, t1 and t2 are sampled for each selected episode.\n",
    "    3. For the selected episode and sampled t1 and t2, training values are gathered.\n",
    "    ______________________________________________________________\n",
    "    Output are four lists of length batch_size:\n",
    "    states, rewards, horizons, and actions.\n",
    "    \"\"\"\n",
    "    states = []\n",
    "    rewards = []\n",
    "    horizons = []\n",
    "    actions = []\n",
    "    episodes = buffer.get_random_samples(batch_size)\n",
    "    \n",
    "    for ep in episodes:\n",
    "        t1, t2, T = select_time_steps(ep)\n",
    "        t2 = T\n",
    "        state, desired_reward, time_horizon, action = create_training_input(ep, t1, t2)\n",
    "        \n",
    "\n",
    "        states.append(torch.FloatTensor(state))\n",
    "        rewards.append(torch.FloatTensor([desired_reward]))\n",
    "        horizons.append(torch.FloatTensor([time_horizon]))\n",
    "        actions.append(torch.tensor(action, dtype=torch.long))\n",
    "        \n",
    "    \n",
    "    # print(\"Number of states:\", len(states))\n",
    "    # print(\"Number of rewards:\", len(rewards))\n",
    "    # print(\"Number of horizons:\", len(horizons))\n",
    "    # print(\"Number of actions:\", len(actions))\n",
    "    \n",
    "    # for i in range(len(states)):\n",
    "    #      print(f\"State {i}: shape {states[i].shape}, type {type(states[i])}\")\n",
    "    # for i in range(len(states)):  \n",
    "    #      print(f\"Reward {i}: shape {rewards[i].shape}, type {type(rewards[i])}\")\n",
    "    # for i in range(len(states)):\n",
    "    #      print(f\"Horizon {i}: shape {horizons[i].shape}, type {type(horizons[i])}\")\n",
    "    # for i in range(len(states)):\n",
    "    #      print(f\"Action {i}: shape {actions[i].shape}, type {type(actions[i])}\")\n",
    "\n",
    "    return states, rewards, horizons, actions\n",
    "\n",
    "def train_behavior_function(batch_size):\n",
    "    \"\"\"\n",
    "    Trains the BF with on a cross entropy loss where the inputs are the action probabilities based on the state and command.\n",
    "    The targets are the actions appropriate to the states from the replay buffer.\n",
    "    \"\"\"\n",
    "    states, rewards, horizons, actions = create_training_examples(batch_size)\n",
    "\n",
    "    # Convert lists to tensors and move them to the appropriate device\n",
    "    state_tensors = torch.stack(states).to(device)\n",
    "    reward_tensors = torch.stack(rewards).to(device)\n",
    "    horizon_tensors = torch.stack(horizons).to(device)\n",
    "    action_tensors = torch.stack(actions).to(device)\n",
    "    \n",
    "    # print(\"State Tensor:          \", state_tensors.shape)\n",
    "    # print(\"\\tRewards tensor:      \", reward_tensors.shape)\n",
    "    # print(\"\\tHorizons tensor:     \", horizon_tensors.shape)\n",
    "    # print(\"\\tActions tensor:      \", action_tensors.shape)\n",
    "\n",
    "    # Ensure reward_tensors and horizon_tensors have correct shape for concatenation\n",
    "    command = torch.cat((reward_tensors, horizon_tensors), dim=1)\n",
    "    # Run model\n",
    "    outputs = bf(state_tensors, command).float()\n",
    "    # print(\"Outputs: \", outputs , \"Action Tensors: \", action_tensors)\n",
    "    # Compute cross entropy loss\n",
    "    loss = F.cross_entropy(outputs, action_tensors)\n",
    "\n",
    "    # Optimization step\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T13:21:06.264336Z",
     "start_time": "2024-07-09T13:21:06.255436Z"
    }
   },
   "id": "cf272e8f57ea2e12",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def evaluate(desired_return, desired_time_horizon):\n",
    "    \"\"\"\n",
    "    Runs one episode of the environment to evaluate the bf.\n",
    "    \"\"\"\n",
    "    obs, _ = env.reset() \n",
    "    state = obs['image']\n",
    "    total_rewards = 0\n",
    "    while True:\n",
    "        state_tensor = torch.from_numpy(state).float().permute(2, 0, 1).unsqueeze(0).to(device)\n",
    "        action = bf.action(state_tensor, desired_return.to(device), desired_time_horizon.to(device)).item()\n",
    "        next_obs, reward, done, truncated, _ = env.step(action)\n",
    "        next_state = next_obs['image']\n",
    "        \n",
    "        total_rewards += reward\n",
    "        state = next_state\n",
    "        desired_return -= reward\n",
    "        desired_time_horizon -= 1\n",
    "        desired_time_horizon = torch.FloatTensor([max(desired_time_horizon.item(), 1)])\n",
    "        \n",
    "        if done or truncated:\n",
    "            break\n",
    "    return total_rewards"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T13:21:06.271475Z",
     "start_time": "2024-07-09T13:21:06.266330Z"
    }
   },
   "id": "48b8c539e729145c",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "init_desired_reward = 13\n",
    "init_time_horizon = 50"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T13:21:06.276869Z",
     "start_time": "2024-07-09T13:21:06.272470Z"
    }
   },
   "id": "71639faa0d468614",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Algorithm 2 - Generates an Episode unsing the Behavior Function:\n",
    "def generate_episode(desired_return = torch.FloatTensor([init_desired_reward]), desired_time_horizon = torch.FloatTensor([init_time_horizon])):    \n",
    "    \"\"\"\n",
    "    Generates more samples for the replay buffer.\n",
    "    \"\"\"\n",
    "    obs, _ = env.reset()\n",
    "    state = obs['image']\n",
    "    states = []\n",
    "    actions = []\n",
    "    rewards = []\n",
    "    while True:\n",
    "        state_tensor = torch.from_numpy(state).float().permute(2, 0, 1).to(device) \n",
    "        action = bf.action(state_tensor.unsqueeze(0).to(device), desired_return.to(device), desired_time_horizon.to(device)).item()\n",
    "        next_obs, reward, done, truncated, _ = env.step(action)\n",
    "        next_state = next_obs['image']\n",
    "        \n",
    "        states.append(state_tensor.cpu().numpy())\n",
    "        actions.append(action)\n",
    "        rewards.append(reward)\n",
    "        \n",
    "        state = next_state\n",
    "        desired_return -= reward\n",
    "        desired_time_horizon -= 1\n",
    "        desired_time_horizon = torch.FloatTensor([np.maximum(desired_time_horizon, 1).item()])\n",
    "        \n",
    "        if done:\n",
    "            break \n",
    "\n",
    "    if len(states) < 2:\n",
    "        return generate_episode(desired_return, desired_time_horizon)\n",
    "    \n",
    "    return [states, actions, rewards]\n",
    "\n",
    "\n",
    "# Algorithm 1 - Upside - Down Reinforcement Learning \n",
    "def run_upside_down(max_episodes):\n",
    "    all_rewards = []\n",
    "    losses = []\n",
    "    average_100_reward = []\n",
    "    desired_rewards_history = []\n",
    "    horizon_history = []\n",
    "    \n",
    "    for ep in tqdm(range(1, max_episodes + 1), desc=\"Training Progress\"):\n",
    "\n",
    "        # improve|optimize bf based on replay buffer\n",
    "        loss_buffer = []\n",
    "        for i in range(n_updates_per_iter):\n",
    "            bf_loss = train_behavior_function(batch_size)\n",
    "            loss_buffer.append(bf_loss)\n",
    "        bf_loss = np.mean(loss_buffer)\n",
    "        losses.append(bf_loss)\n",
    "\n",
    "        # run x new episode and add to buffer\n",
    "        for i in range(n_episodes_per_iter):\n",
    "            # Sample exploratory commands based on buffer\n",
    "            new_desired_reward, new_desired_horizon = sampling_exploration()\n",
    "            generated_episode = generate_episode(new_desired_reward, new_desired_horizon)\n",
    "            buffer.add_sample(generated_episode[0], generated_episode[1], generated_episode[2])\n",
    "\n",
    "        new_desired_reward, new_desired_horizon = sampling_exploration()\n",
    "        # monitoring desired reward and desired horizon\n",
    "        desired_rewards_history.append(new_desired_reward.item())\n",
    "        horizon_history.append(new_desired_horizon.item())\n",
    "\n",
    "        ep_rewards = evaluate(new_desired_reward, new_desired_horizon)\n",
    "        all_rewards.append(ep_rewards)\n",
    "        average_100_reward.append(np.mean(all_rewards[-100:]))\n",
    "\n",
    "        print(\"\\rEpisode: {} | Rewards: {:.2f} | Mean_100_Rewards: {:.2f} | Loss: {:.2f}\".format(\n",
    "            ep, ep_rewards, np.mean(all_rewards[-100:]), bf_loss), end=\"\", flush=True)\n",
    "        if ep % 100 == 0:\n",
    "            print(\"\\rEpisode: {} | Rewards: {:.2f} | Mean_100_Rewards: {:.2f} | Loss: {:.2f}\".format(\n",
    "                ep, ep_rewards, np.mean(all_rewards[-100:]), bf_loss))\n",
    "\n",
    "    return all_rewards, average_100_reward, desired_rewards_history, horizon_history, losses"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T13:21:06.290347Z",
     "start_time": "2024-07-09T13:21:06.278864Z"
    }
   },
   "id": "51c566a669ed706d",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "env = FourRoomsEnv()\n",
    "env = RGBImgObsWrapper(env)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T13:21:06.303710Z",
     "start_time": "2024-07-09T13:21:06.292336Z"
    }
   },
   "id": "86993dbe385faa44",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reward: -41.00\n",
      "Total Reward: -41.10\n",
      "Total Reward: -41.20\n",
      "Total Reward: -41.30\n",
      "Total Reward: -41.40\n",
      "Total Reward: -41.50\n",
      "Total Reward: -41.60\n",
      "Total Reward: -41.70\n",
      "Total Reward: -41.80\n",
      "Total Reward: -41.90\n",
      "Total Reward: -42.00\n",
      "Total Reward: -42.10\n",
      "Total Reward: -41.20\n",
      "Total Reward: -41.30\n",
      "Total Reward: -41.40\n",
      "Total Reward: -41.50\n",
      "Total Reward: -41.60\n",
      "Total Reward: -41.70\n",
      "Total Reward: -41.80\n",
      "Total Reward: -41.90\n",
      "Total Reward: -42.00\n",
      "Total Reward: -42.10\n",
      "Total Reward: -42.20\n",
      "Total Reward: -42.30\n",
      "Total Reward: -32.30\n",
      "Total Reward: -33.70\n",
      "Total Reward: -49.00\n",
      "Total Reward: -49.10\n",
      "Total Reward: -49.20\n",
      "Total Reward: -48.30\n",
      "Total Reward: -48.40\n",
      "Total Reward: -47.50\n",
      "Total Reward: -47.60\n",
      "Total Reward: -48.70\n",
      "Total Reward: -48.80\n",
      "Total Reward: -48.90\n",
      "Total Reward: -48.00\n",
      "Total Reward: -49.10\n",
      "Total Reward: -50.20\n",
      "Total Reward: -50.30\n",
      "Total Reward: -50.40\n",
      "Total Reward: -50.50\n",
      "Total Reward: -50.60\n",
      "Total Reward: -50.70\n",
      "Total Reward: -49.80\n",
      "Total Reward: -48.90\n",
      "Total Reward: -48.00\n",
      "Total Reward: -48.10\n",
      "Total Reward: -47.20\n",
      "Total Reward: -47.30\n",
      "Total Reward: -47.40\n",
      "Total Reward: -47.50\n",
      "Total Reward: -47.60\n",
      "Total Reward: -47.70\n",
      "Total Reward: -46.80\n",
      "Total Reward: -46.90\n",
      "Total Reward: -48.00\n",
      "Total Reward: -48.10\n",
      "Total Reward: -48.20\n",
      "Total Reward: -48.30\n",
      "Total Reward: -48.40\n",
      "Total Reward: -49.50\n",
      "Total Reward: -50.60\n",
      "Total Reward: -51.70\n",
      "Total Reward: -51.80\n",
      "Total Reward: -51.90\n",
      "Total Reward: -52.00\n",
      "Total Reward: -52.10\n",
      "Total Reward: -53.20\n",
      "Total Reward: -53.30\n",
      "Total Reward: -52.40\n",
      "Total Reward: -52.50\n",
      "Total Reward: -53.60\n",
      "Total Reward: -53.70\n",
      "Total Reward: -53.80\n",
      "Total Reward: -53.90\n",
      "Total Reward: -54.00\n",
      "Total Reward: -54.10\n",
      "Total Reward: -54.20\n",
      "Total Reward: -54.30\n",
      "Total Reward: -54.40\n",
      "Total Reward: -54.50\n",
      "Total Reward: -54.60\n",
      "Total Reward: -55.70\n",
      "Total Reward: -55.80\n",
      "Total Reward: -55.90\n",
      "Total Reward: -56.00\n",
      "Total Reward: -56.10\n",
      "Total Reward: -56.20\n",
      "Total Reward: -56.30\n",
      "Total Reward: -56.40\n",
      "Total Reward: -56.50\n",
      "Total Reward: -56.60\n",
      "Total Reward: -56.70\n",
      "Total Reward: -56.80\n",
      "Total Reward: -56.90\n",
      "Total Reward: -57.00\n",
      "Total Reward: -56.10\n",
      "Total Reward: -56.20\n",
      "Total Reward: -56.30\n",
      "Total Reward: -56.40\n",
      "Total Reward: -55.50\n",
      "Total Reward: -55.60\n",
      "Total Reward: -55.70\n",
      "Total Reward: -55.80\n",
      "Total Reward: -55.90\n",
      "Total Reward: -55.00\n",
      "Total Reward: -54.10\n",
      "Total Reward: -54.20\n",
      "Total Reward: -55.30\n",
      "Total Reward: -55.40\n",
      "Total Reward: -55.50\n",
      "Total Reward: -55.60\n",
      "Total Reward: -54.70\n",
      "Total Reward: -54.80\n",
      "Total Reward: -54.90\n",
      "Total Reward: -55.00\n",
      "Total Reward: -55.10\n",
      "Total Reward: -55.20\n",
      "Total Reward: -55.30\n",
      "Total Reward: -55.40\n",
      "Total Reward: -55.50\n",
      "Total Reward: -55.60\n",
      "Total Reward: -54.70\n",
      "Total Reward: -53.80\n",
      "Total Reward: -53.90\n",
      "Total Reward: -54.00\n",
      "Total Reward: -54.10\n",
      "Total Reward: -55.20\n",
      "Total Reward: -55.30\n",
      "Total Reward: -55.40\n",
      "Total Reward: -55.50\n",
      "Total Reward: -56.60\n",
      "Total Reward: -57.70\n",
      "Total Reward: -57.80\n",
      "Total Reward: -57.90\n",
      "Total Reward: -57.00\n",
      "Total Reward: -57.10\n",
      "Total Reward: -57.20\n",
      "Total Reward: -57.30\n",
      "Total Reward: -56.40\n",
      "Total Reward: -55.50\n",
      "Total Reward: -55.60\n",
      "Total Reward: -55.70\n",
      "Total Reward: -55.80\n",
      "Total Reward: -55.90\n",
      "Total Reward: -56.00\n",
      "Total Reward: -46.00\n",
      "Total Reward: -5.40\n",
      "Total Reward: 1.10\n",
      "Total Reward: -50.00\n",
      "Total Reward: -50.10\n",
      "Total Reward: -49.20\n",
      "Total Reward: -49.30\n",
      "Total Reward: -50.40\n",
      "Total Reward: -50.50\n",
      "Total Reward: -50.60\n",
      "Total Reward: -51.70\n",
      "Total Reward: -52.80\n",
      "Total Reward: -53.90\n",
      "Total Reward: -55.00\n",
      "Total Reward: -55.10\n",
      "Total Reward: -54.20\n",
      "Total Reward: -53.30\n",
      "Total Reward: -52.40\n",
      "Total Reward: -51.50\n",
      "Total Reward: -51.60\n",
      "Total Reward: -50.70\n",
      "Total Reward: -49.80\n",
      "Total Reward: -49.90\n",
      "Total Reward: -50.00\n",
      "Total Reward: -50.10\n",
      "Total Reward: -50.20\n",
      "Total Reward: -50.30\n",
      "Total Reward: -50.40\n",
      "Total Reward: -50.50\n",
      "Total Reward: -49.60\n",
      "Total Reward: -49.70\n",
      "Total Reward: -49.80\n",
      "Total Reward: -49.90\n",
      "Total Reward: -50.00\n",
      "Total Reward: -50.10\n",
      "Total Reward: -50.20\n",
      "Total Reward: -50.30\n",
      "Total Reward: -49.40\n",
      "Total Reward: -49.50\n",
      "Total Reward: -48.60\n",
      "Total Reward: -47.70\n",
      "Total Reward: -46.80\n",
      "Total Reward: -45.90\n",
      "Total Reward: -46.00\n",
      "Total Reward: -46.10\n",
      "Total Reward: -47.20\n",
      "Total Reward: -48.30\n",
      "Total Reward: -49.40\n",
      "Total Reward: -50.50\n",
      "Total Reward: -51.60\n",
      "Total Reward: -51.70\n",
      "Total Reward: -51.80\n",
      "Total Reward: -51.90\n",
      "Total Reward: -52.00\n",
      "Total Reward: -52.10\n",
      "Total Reward: -51.20\n",
      "Total Reward: -50.30\n",
      "Total Reward: -50.40\n",
      "Total Reward: -50.50\n",
      "Total Reward: -50.60\n",
      "Total Reward: -50.70\n",
      "Total Reward: -50.80\n",
      "Total Reward: -49.90\n",
      "Total Reward: -50.00\n",
      "Total Reward: -51.10\n",
      "Total Reward: -52.20\n",
      "Total Reward: -53.30\n",
      "Total Reward: -54.40\n",
      "Total Reward: -54.50\n",
      "Total Reward: -55.60\n",
      "Total Reward: -56.70\n",
      "Total Reward: -56.80\n",
      "Total Reward: -56.90\n",
      "Total Reward: -57.00\n",
      "Total Reward: -57.10\n",
      "Total Reward: -57.20\n",
      "Total Reward: -58.30\n",
      "Total Reward: -58.40\n",
      "Total Reward: -58.50\n",
      "Total Reward: -58.60\n",
      "Total Reward: -58.70\n",
      "Total Reward: -58.80\n",
      "Total Reward: -58.90\n",
      "Total Reward: -59.00\n",
      "Total Reward: -58.10\n",
      "Total Reward: -57.20\n",
      "Total Reward: -56.30\n",
      "Total Reward: -56.40\n",
      "Total Reward: -56.50\n",
      "Total Reward: -55.60\n",
      "Total Reward: -55.70\n",
      "Total Reward: -55.80\n",
      "Total Reward: -56.90\n",
      "Total Reward: -57.00\n",
      "Total Reward: -56.10\n",
      "Total Reward: -55.20\n",
      "Total Reward: -54.30\n",
      "Total Reward: -53.40\n",
      "Total Reward: -52.50\n",
      "Total Reward: -52.60\n",
      "Total Reward: -52.70\n",
      "Total Reward: -51.80\n",
      "Total Reward: -50.90\n",
      "Total Reward: -51.00\n",
      "Total Reward: -50.10\n",
      "Total Reward: -50.20\n",
      "Total Reward: -49.30\n",
      "Total Reward: -49.40\n",
      "Total Reward: -49.50\n",
      "Total Reward: -49.60\n",
      "Total Reward: -49.70\n",
      "Total Reward: -39.70\n",
      "Total Reward: 7.20\n",
      "Total Reward: 8.40\n",
      "Total Reward: -43.00\n",
      "Total Reward: -43.10\n",
      "Total Reward: -43.20\n",
      "Total Reward: -43.30\n",
      "Total Reward: -44.40\n",
      "Total Reward: -45.50\n",
      "Total Reward: -46.60\n",
      "Total Reward: -46.70\n",
      "Total Reward: -46.80\n",
      "Total Reward: -46.90\n",
      "Total Reward: -46.00\n",
      "Total Reward: -46.10\n",
      "Total Reward: -47.20\n",
      "Total Reward: -47.30\n",
      "Total Reward: -47.40\n",
      "Total Reward: -46.50\n",
      "Total Reward: -46.60\n",
      "Total Reward: -47.70\n",
      "Total Reward: -48.80\n",
      "Total Reward: -49.90\n",
      "Total Reward: -50.00\n",
      "Total Reward: -50.10\n",
      "Total Reward: -49.20\n",
      "Total Reward: -49.30\n",
      "Total Reward: -49.40\n",
      "Total Reward: -49.50\n",
      "Total Reward: -48.60\n",
      "Total Reward: -47.70\n",
      "Total Reward: -47.80\n",
      "Total Reward: -46.90\n",
      "Total Reward: -46.00\n",
      "Total Reward: -45.10\n",
      "Total Reward: -45.20\n",
      "Total Reward: -46.30\n",
      "Total Reward: -46.40\n",
      "Total Reward: -45.50\n",
      "Total Reward: -44.60\n",
      "Total Reward: -43.70\n",
      "Total Reward: -42.80\n",
      "Total Reward: -43.90\n",
      "Total Reward: -45.00\n",
      "Total Reward: -45.10\n",
      "Total Reward: -45.20\n",
      "Total Reward: -44.30\n",
      "Total Reward: -43.40\n",
      "Total Reward: -44.50\n",
      "Total Reward: -45.60\n",
      "Total Reward: -46.70\n",
      "Total Reward: -46.80\n",
      "Total Reward: -46.90\n",
      "Total Reward: -46.00\n",
      "Total Reward: -45.10\n",
      "Total Reward: -44.20\n",
      "Total Reward: -44.30\n",
      "Total Reward: -43.40\n",
      "Total Reward: -33.40\n",
      "Total Reward: 13.00\n",
      "Total Reward: 9.80\n",
      "Total Reward: 9.20\n",
      "Total Reward: -23.80\n",
      "Total Reward: -42.00\n",
      "Total Reward: -42.10\n",
      "Total Reward: -42.20\n",
      "Total Reward: -43.30\n",
      "Total Reward: -44.40\n",
      "Total Reward: -44.50\n",
      "Total Reward: -45.60\n",
      "Total Reward: -45.70\n",
      "Total Reward: -45.80\n",
      "Total Reward: -45.90\n",
      "Total Reward: -46.00\n",
      "Total Reward: -46.10\n",
      "Total Reward: -45.20\n",
      "Total Reward: -44.30\n",
      "Total Reward: -44.40\n",
      "Total Reward: -43.50\n",
      "Total Reward: -42.60\n",
      "Total Reward: -42.70\n",
      "Total Reward: -42.80\n",
      "Total Reward: -43.90\n",
      "Total Reward: -45.00\n",
      "Total Reward: -45.10\n",
      "Total Reward: -45.20\n",
      "Total Reward: -45.30\n",
      "Total Reward: -44.40\n",
      "Total Reward: -44.50\n",
      "Total Reward: -45.60\n",
      "Total Reward: -45.70\n",
      "Total Reward: -44.80\n",
      "Total Reward: -44.90\n",
      "Total Reward: -44.00\n",
      "Total Reward: -44.10\n",
      "Total Reward: -34.10\n",
      "Total Reward: 10.40\n",
      "Total Reward: 1.00\n",
      "Total Reward: 9.80\n",
      "Total Reward: -47.00\n",
      "Total Reward: -47.10\n",
      "Total Reward: -46.20\n",
      "Total Reward: -46.30\n",
      "Total Reward: -46.40\n",
      "Total Reward: -47.50\n",
      "Total Reward: -47.60\n",
      "Total Reward: -47.70\n",
      "Total Reward: -47.80\n",
      "Total Reward: -47.90\n",
      "Total Reward: -49.00\n",
      "Total Reward: -50.10\n",
      "Total Reward: -51.20\n",
      "Total Reward: -52.30\n",
      "Total Reward: -52.40\n",
      "Total Reward: -51.50\n",
      "Total Reward: -51.60\n",
      "Total Reward: -51.70\n",
      "Total Reward: -51.80\n",
      "Total Reward: -50.90\n",
      "Total Reward: -51.00\n",
      "Total Reward: -51.10\n",
      "Total Reward: -51.20\n",
      "Total Reward: -51.30\n",
      "Total Reward: -51.40\n",
      "Total Reward: -52.50\n",
      "Total Reward: -53.60\n",
      "Total Reward: -54.70\n",
      "Total Reward: -55.80\n",
      "Total Reward: -56.90\n",
      "Total Reward: -57.00\n",
      "Total Reward: -57.10\n",
      "Total Reward: -57.20\n",
      "Total Reward: -57.30\n",
      "Total Reward: -57.40\n",
      "Total Reward: -57.50\n",
      "Total Reward: -56.60\n",
      "Total Reward: -55.70\n",
      "Total Reward: -54.80\n",
      "Total Reward: -54.90\n",
      "Total Reward: -54.00\n",
      "Total Reward: -53.10\n",
      "Total Reward: -53.20\n",
      "Total Reward: -53.30\n",
      "Total Reward: -52.40\n",
      "Total Reward: -51.50\n",
      "Total Reward: -51.60\n",
      "Total Reward: -51.70\n",
      "Total Reward: -52.80\n",
      "Total Reward: -52.90\n",
      "Total Reward: -52.00\n",
      "Total Reward: -51.10\n",
      "Total Reward: -50.20\n",
      "Total Reward: -51.30\n",
      "Total Reward: -51.40\n",
      "Total Reward: -52.50\n",
      "Total Reward: -53.60\n",
      "Total Reward: -53.70\n",
      "Total Reward: -54.80\n",
      "Total Reward: -54.90\n",
      "Total Reward: -55.00\n",
      "Total Reward: -55.10\n",
      "Total Reward: -55.20\n",
      "Total Reward: -55.30\n",
      "Total Reward: -55.40\n",
      "Total Reward: -54.50\n",
      "Total Reward: -53.60\n",
      "Total Reward: -54.70\n",
      "Total Reward: -54.80\n",
      "Total Reward: -53.90\n",
      "Total Reward: -53.00\n",
      "Total Reward: -52.10\n",
      "Total Reward: -53.20\n",
      "Total Reward: -53.30\n",
      "Total Reward: -53.40\n",
      "Total Reward: -52.50\n",
      "Total Reward: -52.60\n",
      "Total Reward: -52.70\n",
      "Total Reward: -52.80\n",
      "Total Reward: -53.90\n",
      "Total Reward: -54.00\n",
      "Total Reward: -54.10\n",
      "Total Reward: -54.20\n",
      "Total Reward: -53.30\n",
      "Total Reward: -54.40\n",
      "Total Reward: -54.50\n",
      "Total Reward: -53.60\n",
      "Total Reward: -54.70\n",
      "Total Reward: -55.80\n",
      "Total Reward: -56.90\n",
      "Total Reward: -57.00\n",
      "Total Reward: -58.10\n",
      "Total Reward: -58.20\n",
      "Total Reward: -58.30\n",
      "Total Reward: -57.40\n",
      "Total Reward: -56.50\n",
      "Total Reward: -57.60\n",
      "Total Reward: -57.70\n",
      "Total Reward: -57.80\n",
      "Total Reward: -57.90\n",
      "Total Reward: -58.00\n",
      "Total Reward: -58.10\n",
      "Total Reward: -58.20\n",
      "Total Reward: -57.30\n",
      "Total Reward: -57.40\n",
      "Total Reward: -57.50\n",
      "Total Reward: -58.60\n",
      "Total Reward: -58.70\n",
      "Total Reward: -59.80\n",
      "Total Reward: -59.90\n",
      "Total Reward: -60.00\n",
      "Total Reward: -59.10\n",
      "Total Reward: -59.20\n",
      "Total Reward: -59.30\n",
      "Total Reward: -60.40\n",
      "Total Reward: -61.50\n",
      "Total Reward: -61.60\n",
      "Total Reward: -60.70\n",
      "Total Reward: -60.80\n",
      "Total Reward: -60.90\n",
      "Total Reward: -62.00\n",
      "Total Reward: -62.10\n",
      "Total Reward: -61.20\n",
      "Total Reward: -60.30\n",
      "Total Reward: -60.40\n",
      "Total Reward: -60.50\n",
      "Total Reward: -60.60\n",
      "Total Reward: -60.70\n",
      "Total Reward: -60.80\n",
      "Total Reward: -60.90\n",
      "Total Reward: -60.00\n",
      "Total Reward: -61.10\n",
      "Total Reward: -61.20\n",
      "Total Reward: -60.30\n",
      "Total Reward: -59.40\n",
      "Total Reward: -58.50\n",
      "Total Reward: -59.60\n",
      "Total Reward: -59.70\n",
      "Total Reward: -59.80\n",
      "Total Reward: -59.90\n",
      "Total Reward: -59.00\n",
      "Total Reward: -59.10\n",
      "Total Reward: -49.10\n",
      "Total Reward: 4.40\n",
      "Total Reward: -41.00\n",
      "Total Reward: -41.10\n",
      "Total Reward: -41.20\n",
      "Total Reward: -41.30\n",
      "Total Reward: -40.40\n",
      "Total Reward: -40.50\n",
      "Total Reward: -40.60\n",
      "Total Reward: -41.70\n",
      "Total Reward: -41.80\n",
      "Total Reward: -41.90\n",
      "Total Reward: -42.00\n",
      "Total Reward: -41.10\n",
      "Total Reward: -41.20\n",
      "Total Reward: -41.30\n",
      "Total Reward: -41.40\n",
      "Total Reward: -41.50\n",
      "Total Reward: -41.60\n",
      "Total Reward: -41.70\n",
      "Total Reward: -41.80\n",
      "Total Reward: -41.90\n",
      "Total Reward: -43.00\n",
      "Total Reward: -43.10\n",
      "Total Reward: -43.20\n",
      "Total Reward: -43.30\n",
      "Total Reward: -43.40\n",
      "Total Reward: -43.50\n",
      "Total Reward: -43.60\n",
      "Total Reward: -43.70\n",
      "Total Reward: -43.80\n",
      "Total Reward: -43.90\n",
      "Total Reward: -44.00\n",
      "Total Reward: -44.10\n",
      "Total Reward: -44.20\n",
      "Total Reward: -44.30\n",
      "Total Reward: -44.40\n",
      "Total Reward: -44.50\n",
      "Total Reward: -44.60\n",
      "Total Reward: -44.70\n",
      "Total Reward: -44.80\n",
      "Total Reward: -45.90\n",
      "Total Reward: -46.00\n",
      "Total Reward: -46.10\n",
      "Total Reward: -46.20\n",
      "Total Reward: -46.30\n",
      "Total Reward: -46.40\n",
      "Total Reward: -45.50\n",
      "Total Reward: -45.60\n",
      "Total Reward: -45.70\n",
      "Total Reward: -45.80\n",
      "Total Reward: -45.90\n",
      "Total Reward: -46.00\n",
      "Total Reward: -46.10\n",
      "Total Reward: -46.20\n",
      "Total Reward: -47.30\n",
      "Total Reward: -47.40\n",
      "Total Reward: -47.50\n",
      "Total Reward: -46.60\n",
      "Total Reward: -46.70\n",
      "Total Reward: -45.80\n",
      "Total Reward: -45.90\n",
      "Total Reward: -46.00\n",
      "Total Reward: -46.10\n",
      "Total Reward: -47.20\n",
      "Total Reward: -47.30\n",
      "Total Reward: -48.40\n",
      "Total Reward: -48.50\n",
      "Total Reward: -48.60\n",
      "Total Reward: -49.70\n",
      "Total Reward: -50.80\n",
      "Total Reward: -51.90\n",
      "Total Reward: -52.00\n",
      "Total Reward: -52.10\n",
      "Total Reward: -52.20\n",
      "Total Reward: -52.30\n",
      "Total Reward: -52.40\n",
      "Total Reward: -52.50\n",
      "Total Reward: -51.60\n",
      "Total Reward: -51.70\n",
      "Total Reward: -51.80\n",
      "Total Reward: -52.90\n",
      "Total Reward: -53.00\n",
      "Total Reward: -53.10\n",
      "Total Reward: -53.20\n",
      "Total Reward: -52.30\n",
      "Total Reward: -53.40\n",
      "Total Reward: -53.50\n",
      "Total Reward: -53.60\n",
      "Total Reward: -53.70\n",
      "Total Reward: -53.80\n",
      "Total Reward: -54.90\n",
      "Total Reward: -55.00\n",
      "Total Reward: -55.10\n",
      "Total Reward: -54.20\n",
      "Total Reward: -54.30\n",
      "Total Reward: -54.40\n",
      "Total Reward: -54.50\n",
      "Total Reward: -54.60\n",
      "Total Reward: -54.70\n",
      "Total Reward: -54.80\n",
      "Total Reward: -54.90\n",
      "Total Reward: -55.00\n",
      "Total Reward: -56.10\n",
      "Total Reward: -56.20\n",
      "Total Reward: -55.30\n",
      "Total Reward: -54.40\n",
      "Total Reward: -53.50\n",
      "Total Reward: -53.60\n",
      "Total Reward: -53.70\n",
      "Total Reward: -53.80\n",
      "Total Reward: -52.90\n",
      "Total Reward: -52.00\n",
      "Total Reward: -52.10\n",
      "Total Reward: -53.20\n",
      "Total Reward: -54.30\n",
      "Total Reward: -55.40\n",
      "Total Reward: -55.50\n",
      "Total Reward: -55.60\n",
      "Total Reward: -55.70\n",
      "Total Reward: -55.80\n",
      "Total Reward: -56.90\n",
      "Total Reward: -58.00\n",
      "Total Reward: -59.10\n",
      "Total Reward: -59.20\n",
      "Total Reward: -59.30\n",
      "Total Reward: -59.40\n",
      "Total Reward: -58.50\n",
      "Total Reward: -57.60\n",
      "Total Reward: -56.70\n",
      "Total Reward: -57.80\n",
      "Total Reward: -57.90\n",
      "Total Reward: -58.00\n",
      "Total Reward: -58.10\n",
      "Total Reward: -57.20\n",
      "Total Reward: -56.30\n",
      "Total Reward: -56.40\n",
      "Total Reward: -56.50\n",
      "Total Reward: -57.60\n",
      "Total Reward: -57.70\n",
      "Total Reward: -57.80\n",
      "Total Reward: -57.90\n",
      "Total Reward: -57.00\n",
      "Total Reward: -57.10\n",
      "Total Reward: -58.20\n",
      "Total Reward: -58.30\n",
      "Total Reward: -58.40\n",
      "Total Reward: -58.50\n",
      "Total Reward: -59.60\n",
      "Total Reward: -59.70\n",
      "Total Reward: -59.80\n",
      "Total Reward: -59.90\n",
      "Total Reward: -59.00\n",
      "Total Reward: -60.10\n",
      "Total Reward: -60.20\n",
      "Total Reward: -60.30\n",
      "Total Reward: -60.40\n",
      "Total Reward: -60.50\n",
      "Total Reward: -59.60\n",
      "Total Reward: -58.70\n",
      "Total Reward: -58.80\n",
      "Total Reward: -58.90\n",
      "Total Reward: -59.00\n",
      "Total Reward: -59.10\n",
      "Total Reward: -58.20\n",
      "Total Reward: -57.30\n",
      "Total Reward: -57.40\n",
      "Total Reward: -57.50\n",
      "Total Reward: -57.60\n",
      "Total Reward: -57.70\n",
      "Total Reward: -57.80\n",
      "Total Reward: -57.90\n",
      "Total Reward: -58.00\n",
      "Total Reward: -58.10\n",
      "Total Reward: -58.20\n",
      "Total Reward: -58.30\n",
      "Total Reward: -58.40\n",
      "Total Reward: -58.50\n",
      "Total Reward: -58.60\n",
      "Total Reward: -58.70\n",
      "Total Reward: -58.80\n",
      "Total Reward: -58.90\n",
      "Total Reward: -59.00\n",
      "Total Reward: -59.10\n",
      "Total Reward: -59.20\n",
      "Total Reward: -59.30\n",
      "Total Reward: -59.40\n",
      "Total Reward: -59.50\n",
      "Total Reward: -59.60\n",
      "Total Reward: -59.70\n",
      "Total Reward: -59.80\n",
      "Total Reward: -58.90\n",
      "Total Reward: -59.00\n",
      "Total Reward: -59.10\n",
      "Total Reward: -59.20\n",
      "Total Reward: -59.30\n",
      "Total Reward: -59.40\n",
      "Total Reward: -60.50\n",
      "Total Reward: -60.60\n",
      "Total Reward: -60.70\n",
      "Total Reward: -59.80\n",
      "Total Reward: -59.90\n",
      "Total Reward: -61.00\n",
      "Total Reward: -61.10\n",
      "Total Reward: -62.20\n",
      "Total Reward: -63.30\n",
      "Total Reward: -63.40\n",
      "Total Reward: -62.50\n",
      "Total Reward: -62.60\n",
      "Total Reward: -63.70\n",
      "Total Reward: -64.80\n",
      "Total Reward: -64.90\n",
      "Total Reward: -66.00\n",
      "Total Reward: -66.10\n",
      "Total Reward: -66.20\n",
      "Total Reward: -65.30\n",
      "Total Reward: -66.40\n",
      "Total Reward: -66.50\n",
      "Total Reward: -66.60\n",
      "Total Reward: -65.70\n",
      "Total Reward: -65.80\n",
      "Total Reward: -65.90\n",
      "Total Reward: -66.00\n",
      "Total Reward: -66.10\n",
      "Total Reward: -67.20\n",
      "Total Reward: -67.30\n",
      "Total Reward: -67.40\n",
      "Total Reward: -66.50\n",
      "Total Reward: -66.60\n",
      "Total Reward: -66.70\n",
      "Total Reward: -66.80\n",
      "Total Reward: -67.90\n",
      "Total Reward: -68.00\n",
      "Total Reward: -68.10\n",
      "Total Reward: -68.20\n",
      "Total Reward: -68.30\n",
      "Total Reward: -68.40\n",
      "Total Reward: -68.50\n",
      "Total Reward: -68.60\n",
      "Total Reward: -68.70\n",
      "Total Reward: -67.80\n",
      "Total Reward: -67.90\n",
      "Total Reward: -68.00\n",
      "Total Reward: -68.10\n",
      "Total Reward: -68.20\n",
      "Total Reward: -68.30\n",
      "Total Reward: -68.40\n",
      "Total Reward: -69.50\n",
      "Total Reward: -69.60\n",
      "Total Reward: -69.70\n",
      "Total Reward: -69.80\n",
      "Total Reward: -69.90\n",
      "Total Reward: -70.00\n",
      "Total Reward: -70.10\n",
      "Total Reward: -70.20\n",
      "Total Reward: -70.30\n",
      "Total Reward: -70.40\n",
      "Total Reward: -70.50\n",
      "Total Reward: -70.60\n",
      "Total Reward: -70.70\n",
      "Total Reward: -70.80\n",
      "Total Reward: -70.90\n",
      "Total Reward: -70.00\n",
      "Total Reward: -69.10\n",
      "Total Reward: -68.20\n",
      "Total Reward: -67.30\n",
      "Total Reward: -67.40\n",
      "Total Reward: -66.50\n",
      "Total Reward: -67.60\n",
      "Total Reward: -68.70\n",
      "Total Reward: -69.80\n",
      "Total Reward: -69.90\n",
      "Total Reward: -71.00\n",
      "Total Reward: -71.10\n",
      "Total Reward: -71.20\n",
      "Total Reward: -70.30\n",
      "Total Reward: -70.40\n",
      "Total Reward: -70.50\n",
      "Total Reward: -70.60\n",
      "Total Reward: -70.70\n",
      "Total Reward: -70.80\n",
      "Total Reward: -69.90\n",
      "Total Reward: -69.00\n",
      "Total Reward: -68.10\n",
      "Total Reward: -69.20\n",
      "Total Reward: -69.30\n",
      "Total Reward: -69.40\n",
      "Total Reward: -69.50\n",
      "Total Reward: -69.60\n",
      "Total Reward: -69.70\n",
      "Total Reward: -69.80\n",
      "Total Reward: -68.90\n",
      "Total Reward: -69.00\n",
      "Total Reward: -69.10\n",
      "Total Reward: -69.20\n",
      "Total Reward: -69.30\n",
      "Total Reward: -69.40\n",
      "Total Reward: -70.50\n",
      "Total Reward: -70.60\n",
      "Total Reward: -70.70\n",
      "Total Reward: -70.80\n",
      "Total Reward: -70.90\n",
      "Total Reward: -71.00\n",
      "Total Reward: -71.10\n",
      "Total Reward: -71.20\n",
      "Total Reward: -72.30\n",
      "Total Reward: -72.40\n",
      "Total Reward: -72.50\n",
      "Total Reward: -71.60\n",
      "Total Reward: -71.70\n",
      "Total Reward: -71.80\n",
      "Total Reward: -71.90\n",
      "Total Reward: -72.00\n",
      "Total Reward: -72.10\n",
      "Total Reward: -72.20\n",
      "Total Reward: -72.30\n",
      "Total Reward: -72.40\n",
      "Total Reward: -72.50\n",
      "Total Reward: -72.60\n",
      "Total Reward: -72.70\n",
      "Total Reward: -72.80\n",
      "Total Reward: -72.90\n",
      "Total Reward: -73.00\n",
      "Total Reward: -73.10\n",
      "Total Reward: -73.20\n",
      "Total Reward: -72.30\n",
      "Total Reward: -72.40\n",
      "Total Reward: -72.50\n",
      "Total Reward: -72.60\n",
      "Total Reward: -73.70\n",
      "Total Reward: -73.80\n",
      "Total Reward: -74.90\n",
      "Total Reward: -75.00\n",
      "Total Reward: -75.10\n",
      "Total Reward: -75.20\n",
      "Total Reward: -74.30\n",
      "Total Reward: -74.40\n",
      "Total Reward: -74.50\n",
      "Total Reward: -74.60\n",
      "Total Reward: -74.70\n",
      "Total Reward: -74.80\n",
      "Total Reward: -74.90\n",
      "Total Reward: -75.00\n",
      "Total Reward: -75.10\n",
      "Total Reward: -75.20\n",
      "Total Reward: -75.30\n",
      "Total Reward: -75.40\n",
      "Total Reward: -75.50\n",
      "Total Reward: -75.60\n",
      "Total Reward: -75.70\n",
      "Total Reward: -74.80\n",
      "Total Reward: -74.90\n",
      "Total Reward: -76.00\n",
      "Total Reward: -77.10\n",
      "Total Reward: -77.20\n",
      "Total Reward: -78.30\n",
      "Total Reward: -78.40\n",
      "Total Reward: -79.50\n",
      "Total Reward: -80.60\n",
      "Total Reward: -80.70\n",
      "Total Reward: -80.80\n",
      "Total Reward: -80.90\n",
      "Total Reward: -81.00\n",
      "Total Reward: -81.10\n",
      "Total Reward: -81.20\n",
      "Total Reward: -81.30\n",
      "Total Reward: -81.40\n",
      "Total Reward: -81.50\n",
      "Total Reward: -81.60\n",
      "Total Reward: -81.70\n",
      "Total Reward: -81.80\n",
      "Total Reward: -81.90\n",
      "Total Reward: -81.00\n",
      "Total Reward: -82.10\n",
      "Total Reward: -82.20\n",
      "Total Reward: -82.30\n",
      "Total Reward: -82.40\n",
      "Total Reward: -82.50\n",
      "Total Reward: -82.60\n",
      "Total Reward: -81.70\n",
      "Total Reward: -80.80\n",
      "Total Reward: -79.90\n",
      "Total Reward: -79.00\n",
      "Total Reward: -79.10\n",
      "Total Reward: -79.20\n",
      "Total Reward: -79.30\n",
      "Total Reward: -79.40\n",
      "Total Reward: -79.50\n",
      "Total Reward: -79.60\n",
      "Total Reward: -79.70\n",
      "Total Reward: -79.80\n",
      "Total Reward: -79.90\n",
      "Total Reward: -80.00\n",
      "Total Reward: -80.10\n",
      "Total Reward: -80.20\n",
      "Total Reward: -80.30\n",
      "Total Reward: -80.40\n",
      "Total Reward: -80.50\n",
      "Total Reward: -80.60\n",
      "Total Reward: -80.70\n",
      "Total Reward: -80.80\n",
      "Total Reward: -80.90\n",
      "Total Reward: -81.00\n",
      "Total Reward: -81.10\n",
      "Total Reward: -81.20\n",
      "Total Reward: -81.30\n",
      "Total Reward: -81.40\n",
      "Total Reward: -81.50\n",
      "Total Reward: -82.60\n",
      "Total Reward: -83.70\n",
      "Total Reward: -83.80\n",
      "Total Reward: -83.90\n",
      "Total Reward: -83.00\n",
      "Total Reward: -82.10\n",
      "Total Reward: -82.20\n",
      "Total Reward: -82.30\n",
      "Total Reward: -82.40\n",
      "Total Reward: -81.50\n",
      "Total Reward: -82.60\n",
      "Total Reward: -82.70\n",
      "Total Reward: -81.80\n",
      "Total Reward: -80.90\n",
      "Total Reward: -80.00\n",
      "Total Reward: -79.10\n",
      "Total Reward: -79.20\n",
      "Total Reward: -79.30\n",
      "Total Reward: -79.40\n",
      "Total Reward: -78.50\n",
      "Total Reward: -78.60\n",
      "Total Reward: -68.60\n",
      "Total Reward: 8.50\n",
      "Episode: 1 | Rewards: 8.50 | Mean_100_Rewards: 8.50 | Loss: 0.97"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  10%|         | 1/10 [00:38<05:45, 38.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reward: -11.20\n",
      "Total Reward: -35.70\n",
      "Total Reward: 4.10\n",
      "Total Reward: 4.90\n",
      "Total Reward: 11.60\n",
      "Total Reward: 3.20\n",
      "Total Reward: 12.60\n",
      "Total Reward: -49.00\n",
      "Total Reward: -49.10\n",
      "Total Reward: -49.20\n",
      "Total Reward: -49.30\n",
      "Total Reward: -49.40\n",
      "Total Reward: -49.50\n",
      "Total Reward: -49.60\n",
      "Total Reward: -49.70\n",
      "Total Reward: -49.80\n",
      "Total Reward: -49.90\n",
      "Total Reward: -50.00\n",
      "Total Reward: -50.10\n",
      "Total Reward: -50.20\n",
      "Total Reward: -50.30\n",
      "Total Reward: -50.40\n",
      "Total Reward: -50.50\n",
      "Total Reward: -50.60\n",
      "Total Reward: -50.70\n",
      "Total Reward: -50.80\n",
      "Total Reward: -50.90\n",
      "Total Reward: -51.00\n",
      "Total Reward: -51.10\n",
      "Total Reward: -51.20\n",
      "Total Reward: -51.30\n",
      "Total Reward: -51.40\n",
      "Total Reward: -51.50\n",
      "Total Reward: -51.60\n",
      "Total Reward: -51.70\n",
      "Total Reward: -52.80\n",
      "Total Reward: -52.90\n",
      "Total Reward: -53.00\n",
      "Total Reward: -53.10\n",
      "Total Reward: -54.20\n",
      "Total Reward: -55.30\n",
      "Total Reward: -55.40\n",
      "Total Reward: -55.50\n",
      "Total Reward: -55.60\n",
      "Total Reward: -55.70\n",
      "Total Reward: -55.80\n",
      "Total Reward: -56.90\n",
      "Total Reward: -57.00\n",
      "Total Reward: -56.10\n",
      "Total Reward: -55.20\n",
      "Total Reward: -55.30\n",
      "Total Reward: -55.40\n",
      "Total Reward: -54.50\n",
      "Total Reward: -53.60\n",
      "Total Reward: -52.70\n",
      "Total Reward: -52.80\n",
      "Total Reward: -52.90\n",
      "Total Reward: -53.00\n",
      "Total Reward: -52.10\n",
      "Total Reward: -52.20\n",
      "Total Reward: -53.30\n",
      "Total Reward: -53.40\n",
      "Total Reward: -53.50\n",
      "Total Reward: -53.60\n",
      "Total Reward: -52.70\n",
      "Total Reward: -52.80\n",
      "Total Reward: -52.90\n",
      "Total Reward: -54.00\n",
      "Total Reward: -55.10\n",
      "Total Reward: -55.20\n",
      "Total Reward: -55.30\n",
      "Total Reward: -55.40\n",
      "Total Reward: -55.50\n",
      "Total Reward: -54.60\n",
      "Total Reward: -53.70\n",
      "Total Reward: -53.80\n",
      "Total Reward: -52.90\n",
      "Total Reward: -54.00\n",
      "Total Reward: -54.10\n",
      "Total Reward: -53.20\n",
      "Total Reward: -52.30\n",
      "Total Reward: -51.40\n",
      "Total Reward: -51.50\n",
      "Total Reward: -51.60\n",
      "Total Reward: -52.70\n",
      "Total Reward: -53.80\n",
      "Total Reward: -54.90\n",
      "Total Reward: -56.00\n",
      "Total Reward: -56.10\n",
      "Total Reward: -57.20\n",
      "Total Reward: -57.30\n",
      "Total Reward: -56.40\n",
      "Total Reward: -56.50\n",
      "Total Reward: -56.60\n",
      "Total Reward: -56.70\n",
      "Total Reward: -57.80\n",
      "Total Reward: -57.90\n",
      "Total Reward: -58.00\n",
      "Total Reward: -57.10\n",
      "Total Reward: -57.20\n",
      "Total Reward: -57.30\n",
      "Total Reward: -57.40\n",
      "Total Reward: -57.50\n",
      "Total Reward: -57.60\n",
      "Total Reward: -57.70\n",
      "Total Reward: -56.80\n",
      "Total Reward: -56.90\n",
      "Total Reward: -58.00\n",
      "Total Reward: -59.10\n",
      "Total Reward: -59.20\n",
      "Total Reward: -59.30\n",
      "Total Reward: -59.40\n",
      "Total Reward: -59.50\n",
      "Total Reward: -59.60\n",
      "Total Reward: -58.70\n",
      "Total Reward: -58.80\n",
      "Total Reward: -58.90\n",
      "Total Reward: -59.00\n",
      "Total Reward: -58.10\n",
      "Total Reward: -57.20\n",
      "Total Reward: -57.30\n",
      "Total Reward: -57.40\n",
      "Total Reward: -57.50\n",
      "Total Reward: -57.60\n",
      "Total Reward: -57.70\n",
      "Total Reward: -58.80\n",
      "Total Reward: -58.90\n",
      "Total Reward: -58.00\n",
      "Total Reward: -57.10\n",
      "Total Reward: -56.20\n",
      "Total Reward: -57.30\n",
      "Total Reward: -57.40\n",
      "Total Reward: -56.50\n",
      "Total Reward: -57.60\n",
      "Total Reward: -58.70\n",
      "Total Reward: -58.80\n",
      "Total Reward: -58.90\n",
      "Total Reward: -59.00\n",
      "Total Reward: -59.10\n",
      "Total Reward: -59.20\n",
      "Total Reward: -59.30\n",
      "Total Reward: -60.40\n",
      "Total Reward: -60.50\n",
      "Total Reward: -60.60\n",
      "Total Reward: -59.70\n",
      "Total Reward: -58.80\n",
      "Total Reward: -57.90\n",
      "Total Reward: -58.00\n",
      "Total Reward: -58.10\n",
      "Total Reward: -59.20\n",
      "Total Reward: -59.30\n",
      "Total Reward: -58.40\n",
      "Total Reward: -59.50\n",
      "Total Reward: -60.60\n",
      "Total Reward: -61.70\n",
      "Total Reward: -62.80\n",
      "Total Reward: -62.90\n",
      "Total Reward: -63.00\n",
      "Total Reward: -64.10\n",
      "Total Reward: -64.20\n",
      "Total Reward: -63.30\n",
      "Total Reward: -64.40\n",
      "Total Reward: -64.50\n",
      "Total Reward: -64.60\n",
      "Total Reward: -64.70\n",
      "Total Reward: -64.80\n",
      "Total Reward: -63.90\n",
      "Total Reward: -64.00\n",
      "Total Reward: -65.10\n",
      "Total Reward: -65.20\n",
      "Total Reward: -66.30\n",
      "Total Reward: -66.40\n",
      "Total Reward: -67.50\n",
      "Total Reward: -67.60\n",
      "Total Reward: -67.70\n",
      "Total Reward: -66.80\n",
      "Total Reward: -65.90\n",
      "Total Reward: -65.00\n",
      "Total Reward: -65.10\n",
      "Total Reward: -65.20\n",
      "Total Reward: -65.30\n",
      "Total Reward: -65.40\n",
      "Total Reward: -64.50\n",
      "Total Reward: -64.60\n",
      "Total Reward: -64.70\n",
      "Total Reward: -64.80\n",
      "Total Reward: -64.90\n",
      "Total Reward: -65.00\n",
      "Total Reward: -65.10\n",
      "Total Reward: -65.20\n",
      "Total Reward: -65.30\n",
      "Total Reward: -64.40\n",
      "Total Reward: -65.50\n",
      "Total Reward: -65.60\n",
      "Total Reward: -64.70\n",
      "Total Reward: -63.80\n",
      "Total Reward: -62.90\n",
      "Total Reward: -64.00\n",
      "Total Reward: -64.10\n",
      "Total Reward: -63.20\n",
      "Total Reward: -64.30\n",
      "Total Reward: -65.40\n",
      "Total Reward: -66.50\n",
      "Total Reward: -67.60\n",
      "Total Reward: -68.70\n",
      "Total Reward: -68.80\n",
      "Total Reward: -67.90\n",
      "Total Reward: -69.00\n",
      "Total Reward: -69.10\n",
      "Total Reward: -68.20\n",
      "Total Reward: -67.30\n",
      "Total Reward: -67.40\n",
      "Total Reward: -67.50\n",
      "Total Reward: -67.60\n",
      "Total Reward: -67.70\n",
      "Total Reward: -67.80\n",
      "Total Reward: -67.90\n",
      "Total Reward: -68.00\n",
      "Total Reward: -68.10\n",
      "Total Reward: -68.20\n",
      "Total Reward: -68.30\n",
      "Total Reward: -68.40\n",
      "Total Reward: -68.50\n",
      "Total Reward: -68.60\n",
      "Total Reward: -68.70\n",
      "Total Reward: -68.80\n",
      "Total Reward: -68.90\n",
      "Total Reward: -68.00\n",
      "Total Reward: -69.10\n",
      "Total Reward: -70.20\n",
      "Total Reward: -70.30\n",
      "Total Reward: -70.40\n",
      "Total Reward: -69.50\n",
      "Total Reward: -68.60\n",
      "Total Reward: -69.70\n",
      "Total Reward: -69.80\n",
      "Total Reward: -69.90\n",
      "Total Reward: -70.00\n",
      "Total Reward: -70.10\n",
      "Total Reward: -70.20\n",
      "Total Reward: -70.30\n",
      "Total Reward: -70.40\n",
      "Total Reward: -70.50\n",
      "Total Reward: -70.60\n",
      "Total Reward: -70.70\n",
      "Total Reward: -70.80\n",
      "Total Reward: -70.90\n",
      "Total Reward: -71.00\n",
      "Total Reward: -71.10\n",
      "Total Reward: -71.20\n",
      "Total Reward: -71.30\n",
      "Total Reward: -71.40\n",
      "Total Reward: -71.50\n",
      "Total Reward: -71.60\n",
      "Total Reward: -71.70\n",
      "Total Reward: -71.80\n",
      "Total Reward: -71.90\n",
      "Total Reward: -73.00\n",
      "Total Reward: -73.10\n",
      "Total Reward: -72.20\n",
      "Total Reward: -73.30\n",
      "Total Reward: -73.40\n",
      "Total Reward: -73.50\n",
      "Total Reward: -72.60\n",
      "Total Reward: -72.70\n",
      "Total Reward: -72.80\n",
      "Total Reward: -72.90\n",
      "Total Reward: -73.00\n",
      "Total Reward: -73.10\n",
      "Total Reward: -73.20\n",
      "Total Reward: -74.30\n",
      "Total Reward: -74.40\n",
      "Total Reward: -73.50\n",
      "Total Reward: -73.60\n",
      "Total Reward: -73.70\n",
      "Total Reward: -73.80\n",
      "Total Reward: -73.90\n",
      "Total Reward: -74.00\n",
      "Total Reward: -74.10\n",
      "Total Reward: -74.20\n",
      "Total Reward: -74.30\n",
      "Total Reward: -74.40\n",
      "Total Reward: -74.50\n",
      "Total Reward: -74.60\n",
      "Total Reward: -74.70\n",
      "Total Reward: -74.80\n",
      "Total Reward: -74.90\n",
      "Total Reward: -75.00\n",
      "Total Reward: -75.10\n",
      "Total Reward: -75.20\n",
      "Total Reward: -75.30\n",
      "Total Reward: -75.40\n",
      "Total Reward: -75.50\n",
      "Total Reward: -75.60\n",
      "Total Reward: -75.70\n",
      "Total Reward: -74.80\n",
      "Total Reward: -75.90\n",
      "Total Reward: -76.00\n",
      "Total Reward: -77.10\n",
      "Total Reward: -77.20\n",
      "Total Reward: -77.30\n",
      "Total Reward: -76.40\n",
      "Total Reward: -75.50\n",
      "Total Reward: -74.60\n",
      "Total Reward: -73.70\n",
      "Total Reward: -74.80\n",
      "Total Reward: -74.90\n",
      "Total Reward: -75.00\n",
      "Total Reward: -74.10\n",
      "Total Reward: -75.20\n",
      "Total Reward: -76.30\n",
      "Total Reward: -77.40\n",
      "Total Reward: -77.50\n",
      "Total Reward: -76.60\n",
      "Total Reward: -77.70\n",
      "Total Reward: -77.80\n",
      "Total Reward: -77.90\n",
      "Total Reward: -78.00\n",
      "Total Reward: -78.10\n",
      "Total Reward: -78.20\n",
      "Total Reward: -78.30\n",
      "Total Reward: -78.40\n",
      "Total Reward: -78.50\n",
      "Total Reward: -78.60\n",
      "Total Reward: -78.70\n",
      "Total Reward: -78.80\n",
      "Total Reward: -78.90\n",
      "Total Reward: -79.00\n",
      "Total Reward: -79.10\n",
      "Total Reward: -79.20\n",
      "Total Reward: -79.30\n",
      "Total Reward: -79.40\n",
      "Total Reward: -79.50\n",
      "Total Reward: -79.60\n",
      "Total Reward: -79.70\n",
      "Total Reward: -79.80\n",
      "Total Reward: -79.90\n",
      "Total Reward: -80.00\n",
      "Total Reward: -80.10\n",
      "Total Reward: -80.20\n",
      "Total Reward: -80.30\n",
      "Total Reward: -80.40\n",
      "Total Reward: -80.50\n",
      "Total Reward: -80.60\n",
      "Total Reward: -80.70\n",
      "Total Reward: -80.80\n",
      "Total Reward: -80.90\n",
      "Total Reward: -81.00\n",
      "Total Reward: -80.10\n",
      "Total Reward: -81.20\n",
      "Total Reward: -81.30\n",
      "Total Reward: -82.40\n",
      "Total Reward: -83.50\n",
      "Total Reward: -83.60\n",
      "Total Reward: -83.70\n",
      "Total Reward: -83.80\n",
      "Total Reward: -83.90\n",
      "Total Reward: -83.00\n",
      "Total Reward: -82.10\n",
      "Total Reward: -81.20\n",
      "Total Reward: -80.30\n",
      "Total Reward: -79.40\n",
      "Total Reward: -80.50\n",
      "Total Reward: -80.60\n",
      "Total Reward: -80.70\n",
      "Total Reward: -79.80\n",
      "Total Reward: -80.90\n",
      "Total Reward: -82.00\n",
      "Total Reward: -83.10\n",
      "Total Reward: -83.20\n",
      "Total Reward: -82.30\n",
      "Total Reward: -83.40\n",
      "Total Reward: -83.50\n",
      "Total Reward: -83.60\n",
      "Total Reward: -83.70\n",
      "Total Reward: -83.80\n",
      "Total Reward: -83.90\n",
      "Total Reward: -84.00\n",
      "Total Reward: -84.10\n",
      "Total Reward: -84.20\n",
      "Total Reward: -84.30\n",
      "Total Reward: -84.40\n",
      "Total Reward: -84.50\n",
      "Total Reward: -84.60\n",
      "Total Reward: -84.70\n",
      "Total Reward: -84.80\n",
      "Total Reward: -84.90\n",
      "Total Reward: -85.00\n",
      "Total Reward: -85.10\n",
      "Total Reward: -85.20\n",
      "Total Reward: -85.30\n",
      "Total Reward: -85.40\n",
      "Total Reward: -85.50\n",
      "Total Reward: -85.60\n",
      "Total Reward: -85.70\n",
      "Total Reward: -85.80\n",
      "Total Reward: -85.90\n",
      "Total Reward: -86.00\n",
      "Total Reward: -86.10\n",
      "Total Reward: -86.20\n",
      "Total Reward: -86.30\n",
      "Total Reward: -86.40\n",
      "Total Reward: -86.50\n",
      "Total Reward: -86.60\n",
      "Total Reward: -86.70\n",
      "Total Reward: -86.80\n",
      "Total Reward: -86.90\n",
      "Total Reward: -87.00\n",
      "Total Reward: -87.10\n",
      "Total Reward: -87.20\n",
      "Total Reward: -87.30\n",
      "Total Reward: -87.40\n",
      "Total Reward: -87.50\n",
      "Total Reward: -87.60\n",
      "Total Reward: -87.70\n",
      "Total Reward: -87.80\n",
      "Total Reward: -87.90\n",
      "Total Reward: -88.00\n",
      "Total Reward: -88.10\n",
      "Total Reward: -88.20\n",
      "Total Reward: -88.30\n",
      "Total Reward: -88.40\n",
      "Total Reward: -88.50\n",
      "Total Reward: -88.60\n",
      "Total Reward: -88.70\n",
      "Total Reward: -88.80\n",
      "Total Reward: -88.90\n",
      "Total Reward: -89.00\n",
      "Total Reward: -89.10\n",
      "Total Reward: -89.20\n",
      "Total Reward: -89.30\n",
      "Total Reward: -89.40\n",
      "Total Reward: -89.50\n",
      "Total Reward: -89.60\n",
      "Total Reward: -89.70\n",
      "Total Reward: -89.80\n",
      "Total Reward: -89.90\n",
      "Total Reward: -90.00\n",
      "Total Reward: -90.10\n",
      "Total Reward: -90.20\n",
      "Total Reward: -90.30\n",
      "Total Reward: -90.40\n",
      "Total Reward: -90.50\n",
      "Total Reward: -90.60\n",
      "Total Reward: -90.70\n",
      "Total Reward: -90.80\n",
      "Total Reward: -90.90\n",
      "Total Reward: -91.00\n",
      "Total Reward: -90.10\n",
      "Total Reward: -90.20\n",
      "Total Reward: -91.30\n",
      "Total Reward: -91.40\n",
      "Total Reward: -92.50\n",
      "Total Reward: -92.60\n",
      "Total Reward: -91.70\n",
      "Total Reward: -91.80\n",
      "Total Reward: -91.90\n",
      "Total Reward: -92.00\n",
      "Total Reward: -92.10\n",
      "Total Reward: -92.20\n",
      "Total Reward: -92.30\n",
      "Total Reward: -92.40\n",
      "Total Reward: -92.50\n",
      "Total Reward: -92.60\n",
      "Total Reward: -92.70\n",
      "Total Reward: -92.80\n",
      "Total Reward: -92.90\n",
      "Total Reward: -93.00\n",
      "Total Reward: -93.10\n",
      "Total Reward: -93.20\n",
      "Total Reward: -93.30\n",
      "Total Reward: -93.40\n",
      "Total Reward: -93.50\n",
      "Total Reward: -93.60\n",
      "Total Reward: -93.70\n",
      "Total Reward: -93.80\n",
      "Total Reward: -93.90\n",
      "Total Reward: -94.00\n",
      "Total Reward: -94.10\n",
      "Total Reward: -94.20\n",
      "Total Reward: -94.30\n",
      "Total Reward: -94.40\n",
      "Total Reward: -94.50\n",
      "Total Reward: -93.60\n",
      "Total Reward: -94.70\n",
      "Total Reward: -95.80\n",
      "Total Reward: -95.90\n",
      "Total Reward: -96.00\n",
      "Total Reward: -95.10\n",
      "Total Reward: -94.20\n",
      "Total Reward: -94.30\n",
      "Total Reward: -94.40\n",
      "Total Reward: -95.50\n",
      "Total Reward: -95.60\n",
      "Total Reward: -95.70\n",
      "Total Reward: -94.80\n",
      "Total Reward: -95.90\n",
      "Total Reward: -96.00\n",
      "Total Reward: -96.10\n",
      "Total Reward: -96.20\n",
      "Total Reward: -96.30\n",
      "Total Reward: -96.40\n",
      "Total Reward: -96.50\n",
      "Total Reward: -96.60\n",
      "Total Reward: -96.70\n",
      "Total Reward: -96.80\n",
      "Total Reward: -96.90\n",
      "Total Reward: -97.00\n",
      "Total Reward: -97.10\n",
      "Total Reward: -97.20\n",
      "Total Reward: -97.30\n",
      "Total Reward: -97.40\n",
      "Total Reward: -97.50\n",
      "Total Reward: -97.60\n",
      "Total Reward: -97.70\n",
      "Total Reward: -97.80\n",
      "Total Reward: -97.90\n",
      "Total Reward: -98.00\n",
      "Total Reward: -98.10\n",
      "Total Reward: -98.20\n",
      "Total Reward: -98.30\n",
      "Total Reward: -98.40\n",
      "Total Reward: -98.50\n",
      "Total Reward: -98.60\n",
      "Total Reward: -98.70\n",
      "Total Reward: -98.80\n",
      "Total Reward: -98.90\n",
      "Total Reward: -99.00\n",
      "Total Reward: -99.10\n",
      "Total Reward: -99.20\n",
      "Total Reward: -99.30\n",
      "Total Reward: -99.40\n",
      "Total Reward: -99.50\n",
      "Total Reward: -99.60\n",
      "Total Reward: -99.70\n",
      "Total Reward: -99.80\n",
      "Total Reward: -99.90\n",
      "Total Reward: -100.00\n",
      "Total Reward: -100.10\n",
      "Total Reward: -100.20\n",
      "Total Reward: -100.30\n",
      "Total Reward: -100.40\n",
      "Total Reward: -100.50\n",
      "Total Reward: -100.60\n",
      "Total Reward: -100.70\n",
      "Total Reward: -100.80\n",
      "Total Reward: -100.90\n",
      "Total Reward: -101.00\n",
      "Total Reward: -101.10\n",
      "Total Reward: -101.20\n",
      "Total Reward: -101.30\n",
      "Total Reward: -101.40\n",
      "Total Reward: -101.50\n",
      "Total Reward: -101.60\n",
      "Total Reward: -101.70\n",
      "Total Reward: -101.80\n",
      "Total Reward: -101.90\n",
      "Total Reward: -102.00\n",
      "Total Reward: -102.10\n",
      "Total Reward: -102.20\n",
      "Total Reward: -102.30\n",
      "Total Reward: -102.40\n",
      "Total Reward: -102.50\n",
      "Total Reward: -102.60\n",
      "Total Reward: -102.70\n",
      "Total Reward: -102.80\n",
      "Total Reward: -102.90\n",
      "Total Reward: -103.00\n",
      "Total Reward: -103.10\n",
      "Total Reward: -103.20\n",
      "Total Reward: -103.30\n",
      "Total Reward: -103.40\n",
      "Total Reward: -103.50\n",
      "Total Reward: -103.60\n",
      "Total Reward: -103.70\n",
      "Total Reward: -103.80\n",
      "Total Reward: -103.90\n",
      "Total Reward: -104.00\n",
      "Total Reward: -104.10\n",
      "Total Reward: -104.20\n",
      "Total Reward: -104.30\n",
      "Total Reward: -104.40\n",
      "Total Reward: -104.50\n",
      "Total Reward: -104.60\n",
      "Total Reward: -104.70\n",
      "Total Reward: -104.80\n",
      "Total Reward: -104.90\n",
      "Total Reward: -105.00\n",
      "Total Reward: -105.10\n",
      "Total Reward: -105.20\n",
      "Total Reward: -105.30\n",
      "Total Reward: -105.40\n",
      "Total Reward: -105.50\n",
      "Total Reward: -105.60\n",
      "Total Reward: -105.70\n",
      "Total Reward: -105.80\n",
      "Total Reward: -105.90\n",
      "Total Reward: -106.00\n",
      "Total Reward: -106.10\n",
      "Total Reward: -106.20\n",
      "Total Reward: -106.30\n",
      "Total Reward: -106.40\n",
      "Total Reward: -106.50\n",
      "Total Reward: -105.60\n",
      "Total Reward: -106.70\n",
      "Total Reward: -106.80\n",
      "Total Reward: -107.90\n",
      "Total Reward: -109.00\n",
      "Total Reward: -109.10\n",
      "Total Reward: -109.20\n",
      "Total Reward: -108.30\n",
      "Total Reward: -108.40\n",
      "Total Reward: -108.50\n",
      "Total Reward: -109.60\n",
      "Total Reward: -109.70\n",
      "Total Reward: -109.80\n",
      "Total Reward: -108.90\n",
      "Total Reward: -108.00\n",
      "Total Reward: -107.10\n",
      "Total Reward: -106.20\n",
      "Total Reward: -105.30\n",
      "Total Reward: -106.40\n",
      "Total Reward: -106.50\n",
      "Total Reward: -106.60\n",
      "Total Reward: -105.70\n",
      "Total Reward: -106.80\n",
      "Total Reward: -107.90\n",
      "Total Reward: -109.00\n",
      "Total Reward: -110.10\n",
      "Total Reward: -111.20\n",
      "Total Reward: -111.30\n",
      "Total Reward: -111.40\n",
      "Total Reward: -110.50\n",
      "Total Reward: -109.60\n",
      "Total Reward: -108.70\n",
      "Total Reward: -107.80\n",
      "Total Reward: -106.90\n",
      "Total Reward: -108.00\n",
      "Total Reward: -108.10\n",
      "Total Reward: -107.20\n",
      "Total Reward: -108.30\n",
      "Total Reward: -109.40\n",
      "Total Reward: -110.50\n",
      "Total Reward: -110.60\n",
      "Total Reward: -110.70\n",
      "Total Reward: -109.80\n",
      "Total Reward: -108.90\n",
      "Total Reward: -108.00\n",
      "Total Reward: -109.10\n",
      "Total Reward: -109.20\n",
      "Total Reward: -108.30\n",
      "Total Reward: -109.40\n",
      "Total Reward: -110.50\n",
      "Total Reward: -110.60\n",
      "Total Reward: -110.70\n",
      "Total Reward: -111.80\n",
      "Total Reward: -112.90\n",
      "Total Reward: -114.00\n",
      "Total Reward: -114.10\n",
      "Total Reward: -114.20\n",
      "Total Reward: -113.30\n",
      "Total Reward: -112.40\n",
      "Total Reward: -112.50\n",
      "Total Reward: -111.60\n",
      "Total Reward: -112.70\n",
      "Total Reward: -112.80\n",
      "Total Reward: -112.90\n",
      "Total Reward: -113.00\n",
      "Total Reward: -113.10\n",
      "Total Reward: -113.20\n",
      "Total Reward: -113.30\n",
      "Total Reward: -113.40\n",
      "Total Reward: -113.50\n",
      "Total Reward: -113.60\n",
      "Total Reward: -113.70\n",
      "Total Reward: -113.80\n",
      "Total Reward: -113.90\n",
      "Total Reward: -114.00\n",
      "Total Reward: -114.10\n",
      "Total Reward: -114.20\n",
      "Total Reward: -114.30\n",
      "Total Reward: -114.40\n",
      "Total Reward: -114.50\n",
      "Total Reward: -114.60\n",
      "Total Reward: -114.70\n",
      "Total Reward: -114.80\n",
      "Total Reward: -114.90\n",
      "Total Reward: -115.00\n",
      "Total Reward: -115.10\n",
      "Total Reward: -115.20\n",
      "Total Reward: -115.30\n",
      "Total Reward: -115.40\n",
      "Total Reward: -115.50\n",
      "Total Reward: -115.60\n",
      "Total Reward: -115.70\n",
      "Total Reward: -115.80\n",
      "Total Reward: -115.90\n",
      "Total Reward: -116.00\n",
      "Total Reward: -116.10\n",
      "Total Reward: -116.20\n",
      "Total Reward: -116.30\n",
      "Total Reward: -116.40\n",
      "Total Reward: -116.50\n",
      "Total Reward: -116.60\n",
      "Total Reward: -116.70\n",
      "Total Reward: -116.80\n",
      "Total Reward: -116.90\n",
      "Total Reward: -117.00\n",
      "Total Reward: -117.10\n",
      "Total Reward: -116.20\n",
      "Total Reward: -116.30\n",
      "Total Reward: -116.40\n",
      "Total Reward: -116.50\n",
      "Total Reward: -116.60\n",
      "Total Reward: -116.70\n",
      "Total Reward: -116.80\n",
      "Total Reward: -116.90\n",
      "Total Reward: -117.00\n",
      "Total Reward: -117.10\n",
      "Total Reward: -117.20\n",
      "Total Reward: -117.30\n",
      "Total Reward: -118.40\n",
      "Total Reward: -118.50\n",
      "Total Reward: -118.60\n",
      "Total Reward: -118.70\n",
      "Total Reward: -118.80\n",
      "Total Reward: -118.90\n",
      "Total Reward: -119.00\n",
      "Total Reward: -119.10\n",
      "Total Reward: -119.20\n",
      "Total Reward: -119.30\n",
      "Total Reward: -119.40\n",
      "Total Reward: -119.50\n",
      "Total Reward: -119.60\n",
      "Total Reward: -119.70\n",
      "Total Reward: -119.80\n",
      "Total Reward: -119.90\n",
      "Total Reward: -120.00\n",
      "Total Reward: -120.10\n",
      "Total Reward: -120.20\n",
      "Total Reward: -120.30\n",
      "Total Reward: -120.40\n",
      "Total Reward: -120.50\n",
      "Total Reward: -120.60\n",
      "Total Reward: -120.70\n",
      "Total Reward: -120.80\n",
      "Total Reward: -120.90\n",
      "Total Reward: -121.00\n",
      "Total Reward: -121.10\n",
      "Total Reward: -121.20\n",
      "Total Reward: -121.30\n",
      "Total Reward: -120.40\n",
      "Total Reward: -120.50\n",
      "Total Reward: -120.60\n",
      "Total Reward: -121.70\n",
      "Total Reward: -121.80\n",
      "Total Reward: -121.90\n",
      "Total Reward: -122.00\n",
      "Total Reward: -122.10\n",
      "Total Reward: -122.20\n",
      "Total Reward: -122.30\n",
      "Total Reward: -122.40\n",
      "Total Reward: -122.50\n",
      "Total Reward: -122.60\n",
      "Total Reward: -122.70\n",
      "Total Reward: -122.80\n",
      "Total Reward: -121.90\n",
      "Total Reward: -123.00\n",
      "Total Reward: -124.10\n",
      "Total Reward: -124.20\n",
      "Total Reward: -125.30\n",
      "Total Reward: -126.40\n",
      "Total Reward: -126.50\n",
      "Total Reward: -125.60\n",
      "Total Reward: -125.70\n",
      "Total Reward: -124.80\n",
      "Total Reward: -123.90\n",
      "Total Reward: -123.00\n",
      "Total Reward: -122.10\n",
      "Total Reward: -121.20\n",
      "Total Reward: -122.30\n",
      "Total Reward: -122.40\n",
      "Total Reward: -121.50\n",
      "Total Reward: -122.60\n",
      "Total Reward: -123.70\n",
      "Total Reward: -123.80\n",
      "Total Reward: -123.90\n",
      "Total Reward: -123.00\n",
      "Total Reward: -122.10\n",
      "Total Reward: -123.20\n",
      "Total Reward: -123.30\n",
      "Total Reward: -122.40\n",
      "Total Reward: -123.50\n",
      "Total Reward: -124.60\n",
      "Total Reward: -125.70\n",
      "Total Reward: -125.80\n",
      "Total Reward: -124.90\n",
      "Total Reward: -126.00\n",
      "Total Reward: -126.10\n",
      "Total Reward: -126.20\n",
      "Total Reward: -126.30\n",
      "Total Reward: -126.40\n",
      "Total Reward: -126.50\n",
      "Total Reward: -126.60\n",
      "Total Reward: -126.70\n",
      "Total Reward: -126.80\n",
      "Total Reward: -126.90\n",
      "Total Reward: -127.00\n",
      "Total Reward: -127.10\n",
      "Total Reward: -127.20\n",
      "Total Reward: -127.30\n",
      "Total Reward: -127.40\n",
      "Total Reward: -127.50\n",
      "Total Reward: -127.60\n",
      "Total Reward: -127.70\n",
      "Total Reward: -127.80\n",
      "Total Reward: -127.90\n",
      "Total Reward: -128.00\n",
      "Total Reward: -128.10\n",
      "Total Reward: -128.20\n",
      "Total Reward: -128.30\n",
      "Total Reward: -128.40\n",
      "Total Reward: -128.50\n",
      "Total Reward: -127.60\n",
      "Total Reward: -128.70\n",
      "Total Reward: -128.80\n",
      "Total Reward: -127.90\n",
      "Total Reward: -127.00\n",
      "Total Reward: -126.10\n",
      "Total Reward: -127.20\n",
      "Total Reward: -127.30\n",
      "Total Reward: -126.40\n",
      "Total Reward: -127.50\n",
      "Total Reward: -128.60\n",
      "Total Reward: -128.70\n",
      "Total Reward: -128.80\n",
      "Total Reward: -127.90\n",
      "Total Reward: -127.00\n",
      "Total Reward: -128.10\n",
      "Total Reward: -128.20\n",
      "Total Reward: -128.30\n",
      "Total Reward: -127.40\n",
      "Total Reward: -128.50\n",
      "Total Reward: -129.60\n",
      "Total Reward: -129.70\n",
      "Total Reward: -129.80\n",
      "Total Reward: -130.90\n",
      "Total Reward: -132.00\n",
      "Total Reward: -133.10\n",
      "Total Reward: -133.20\n",
      "Total Reward: -133.30\n",
      "Total Reward: -133.40\n",
      "Total Reward: -133.50\n",
      "Total Reward: -132.60\n",
      "Total Reward: -131.70\n",
      "Total Reward: -130.80\n",
      "Total Reward: -129.90\n",
      "Total Reward: -129.00\n",
      "Total Reward: -130.10\n",
      "Total Reward: -130.20\n",
      "Total Reward: -129.30\n",
      "Total Reward: -130.40\n",
      "Total Reward: -131.50\n",
      "Total Reward: -132.60\n",
      "Total Reward: -133.70\n",
      "Total Reward: -133.80\n",
      "Total Reward: -133.90\n",
      "Total Reward: -133.00\n",
      "Total Reward: -132.10\n",
      "Total Reward: -131.20\n",
      "Total Reward: -131.30\n",
      "Total Reward: -131.40\n",
      "Total Reward: -132.50\n",
      "Total Reward: -133.60\n",
      "Total Reward: -134.70\n",
      "Total Reward: -135.80\n",
      "Total Reward: -135.90\n",
      "Total Reward: -136.00\n",
      "Total Reward: -135.10\n",
      "Total Reward: -135.20\n",
      "Total Reward: -135.30\n",
      "Total Reward: -134.40\n",
      "Total Reward: -133.50\n",
      "Total Reward: -132.60\n",
      "Total Reward: -131.70\n",
      "Total Reward: -132.80\n",
      "Total Reward: -132.90\n",
      "Total Reward: -132.00\n",
      "Total Reward: -133.10\n",
      "Total Reward: -134.20\n",
      "Total Reward: -134.30\n",
      "Total Reward: -134.40\n",
      "Total Reward: -134.50\n",
      "Total Reward: -135.60\n",
      "Total Reward: -136.70\n",
      "Total Reward: -136.80\n",
      "Total Reward: -136.90\n",
      "Total Reward: -136.00\n",
      "Total Reward: -135.10\n",
      "Total Reward: -134.20\n",
      "Total Reward: -133.30\n",
      "Total Reward: -134.40\n",
      "Total Reward: -134.50\n",
      "Total Reward: -133.60\n",
      "Total Reward: -134.70\n",
      "Total Reward: -135.80\n",
      "Total Reward: -136.90\n",
      "Total Reward: -138.00\n",
      "Total Reward: -138.10\n",
      "Total Reward: -138.20\n",
      "Total Reward: -137.30\n",
      "Total Reward: -136.40\n",
      "Total Reward: -135.50\n",
      "Total Reward: -134.60\n",
      "Total Reward: -135.70\n",
      "Total Reward: -135.80\n",
      "Total Reward: -134.90\n",
      "Total Reward: -136.00\n",
      "Total Reward: -137.10\n",
      "Total Reward: -137.20\n",
      "Total Reward: -137.30\n",
      "Total Reward: -136.40\n",
      "Total Reward: -135.50\n",
      "Total Reward: -136.60\n",
      "Total Reward: -136.70\n",
      "Total Reward: -136.80\n",
      "Total Reward: -136.90\n",
      "Total Reward: -136.00\n",
      "Total Reward: -137.10\n",
      "Total Reward: -138.20\n",
      "Total Reward: -139.30\n",
      "Total Reward: -140.40\n",
      "Total Reward: -140.50\n",
      "Total Reward: -140.60\n",
      "Total Reward: -139.70\n",
      "Total Reward: -138.80\n",
      "Total Reward: -137.90\n",
      "Total Reward: -138.00\n",
      "Total Reward: -138.10\n",
      "Total Reward: -137.20\n",
      "Total Reward: -138.30\n",
      "Total Reward: -139.40\n",
      "Total Reward: -139.50\n",
      "Total Reward: -139.60\n",
      "Total Reward: -139.70\n",
      "Total Reward: -139.80\n",
      "Total Reward: -138.90\n",
      "Total Reward: -138.00\n",
      "Total Reward: -139.10\n",
      "Total Reward: -140.20\n",
      "Total Reward: -141.30\n",
      "Total Reward: -142.40\n",
      "Total Reward: -143.50\n",
      "Total Reward: -144.60\n",
      "Total Reward: -144.70\n",
      "Total Reward: -144.80\n",
      "Total Reward: -143.90\n",
      "Total Reward: -144.00\n",
      "Total Reward: -145.10\n",
      "Total Reward: -145.20\n",
      "Total Reward: -144.30\n",
      "Total Reward: -143.40\n",
      "Total Reward: -143.50\n",
      "Total Reward: -142.60\n",
      "Total Reward: -141.70\n",
      "Total Reward: -142.80\n",
      "Total Reward: -142.90\n",
      "Total Reward: -143.00\n",
      "Total Reward: -143.10\n",
      "Total Reward: -143.20\n",
      "Total Reward: -143.30\n",
      "Total Reward: -142.40\n",
      "Total Reward: -143.50\n",
      "Total Reward: -143.60\n",
      "Total Reward: -144.70\n",
      "Total Reward: -144.80\n",
      "Total Reward: -143.90\n",
      "Total Reward: -144.00\n",
      "Total Reward: -144.10\n",
      "Total Reward: -144.20\n",
      "Total Reward: -143.30\n",
      "Total Reward: -143.40\n",
      "Total Reward: -143.50\n",
      "Total Reward: -143.60\n",
      "Total Reward: -143.70\n",
      "Total Reward: -143.80\n",
      "Total Reward: -144.90\n",
      "Total Reward: -146.00\n",
      "Total Reward: -146.10\n",
      "Total Reward: -147.20\n",
      "Total Reward: -148.30\n",
      "Total Reward: -148.40\n",
      "Total Reward: -148.50\n",
      "Total Reward: -148.60\n",
      "Total Reward: -148.70\n",
      "Total Reward: -148.80\n",
      "Total Reward: -148.90\n",
      "Total Reward: -149.00\n",
      "Total Reward: -149.10\n",
      "Total Reward: -149.20\n",
      "Total Reward: -149.30\n",
      "Total Reward: -149.40\n",
      "Total Reward: -149.50\n",
      "Total Reward: -150.60\n",
      "Total Reward: -151.70\n",
      "Total Reward: -151.80\n",
      "Total Reward: -151.90\n",
      "Total Reward: -152.00\n",
      "Total Reward: -152.10\n",
      "Total Reward: -152.20\n",
      "Total Reward: -153.30\n",
      "Total Reward: -153.40\n",
      "Total Reward: -153.50\n",
      "Total Reward: -152.60\n",
      "Total Reward: -151.70\n",
      "Total Reward: -151.80\n",
      "Total Reward: -151.90\n",
      "Total Reward: -151.00\n",
      "Total Reward: -151.10\n",
      "Total Reward: -150.20\n",
      "Total Reward: -150.30\n",
      "Total Reward: -150.40\n",
      "Total Reward: -150.50\n",
      "Total Reward: -150.60\n",
      "Total Reward: -150.70\n",
      "Total Reward: -150.80\n",
      "Total Reward: -151.90\n",
      "Total Reward: -152.00\n",
      "Total Reward: -152.10\n",
      "Total Reward: -152.20\n",
      "Total Reward: -152.30\n",
      "Total Reward: -151.40\n",
      "Total Reward: -151.50\n",
      "Total Reward: -151.60\n",
      "Total Reward: -151.70\n",
      "Total Reward: -151.80\n",
      "Total Reward: -151.90\n",
      "Total Reward: -152.00\n",
      "Total Reward: -152.10\n",
      "Total Reward: -152.20\n",
      "Total Reward: -152.30\n",
      "Total Reward: -152.40\n",
      "Total Reward: -152.50\n",
      "Total Reward: -152.60\n",
      "Total Reward: -152.70\n",
      "Total Reward: -152.80\n",
      "Total Reward: -152.90\n",
      "Total Reward: -153.00\n",
      "Total Reward: -153.10\n",
      "Total Reward: -153.20\n",
      "Total Reward: -153.30\n",
      "Total Reward: -154.40\n",
      "Total Reward: -154.50\n",
      "Total Reward: -154.60\n",
      "Total Reward: -153.70\n",
      "Total Reward: -153.80\n",
      "Total Reward: -153.90\n",
      "Total Reward: -154.00\n",
      "Total Reward: -154.10\n",
      "Total Reward: -154.20\n",
      "Total Reward: -154.30\n",
      "Total Reward: -154.40\n",
      "Total Reward: -154.50\n",
      "Total Reward: -154.60\n",
      "Total Reward: -154.70\n",
      "Total Reward: -154.80\n",
      "Total Reward: -154.90\n",
      "Total Reward: -155.00\n",
      "Total Reward: -155.10\n",
      "Total Reward: -155.20\n",
      "Total Reward: -156.30\n",
      "Total Reward: -156.40\n",
      "Total Reward: -156.50\n",
      "Total Reward: -156.60\n",
      "Total Reward: -156.70\n",
      "Total Reward: -155.80\n",
      "Total Reward: -155.90\n",
      "Total Reward: -156.00\n",
      "Total Reward: -156.10\n",
      "Total Reward: -156.20\n",
      "Total Reward: -156.30\n",
      "Total Reward: -156.40\n",
      "Total Reward: -156.50\n",
      "Total Reward: -156.60\n",
      "Total Reward: -156.70\n",
      "Total Reward: -156.80\n",
      "Total Reward: -156.90\n",
      "Total Reward: -157.00\n",
      "Total Reward: -157.10\n",
      "Total Reward: -157.20\n",
      "Total Reward: -157.30\n",
      "Total Reward: -157.40\n",
      "Total Reward: -157.50\n",
      "Total Reward: -157.60\n",
      "Total Reward: -157.70\n",
      "Total Reward: -157.80\n",
      "Total Reward: -157.90\n",
      "Total Reward: -158.00\n",
      "Total Reward: -158.10\n",
      "Total Reward: -158.20\n",
      "Total Reward: -158.30\n",
      "Total Reward: -158.40\n",
      "Total Reward: -158.50\n",
      "Total Reward: -158.60\n",
      "Total Reward: -158.70\n",
      "Total Reward: -158.80\n",
      "Total Reward: -158.90\n",
      "Total Reward: -159.00\n",
      "Total Reward: -159.10\n",
      "Total Reward: -159.20\n",
      "Total Reward: -159.30\n",
      "Total Reward: -160.40\n",
      "Total Reward: -160.50\n",
      "Total Reward: -160.60\n",
      "Total Reward: -159.70\n",
      "Total Reward: -159.80\n",
      "Total Reward: -159.90\n",
      "Total Reward: -160.00\n",
      "Total Reward: -160.10\n",
      "Total Reward: -160.20\n",
      "Total Reward: -160.30\n",
      "Total Reward: -160.40\n",
      "Total Reward: -160.50\n",
      "Total Reward: -160.60\n",
      "Total Reward: -160.70\n",
      "Total Reward: -160.80\n",
      "Total Reward: -160.90\n",
      "Total Reward: -161.00\n",
      "Total Reward: -161.10\n",
      "Total Reward: -161.20\n",
      "Total Reward: -161.30\n",
      "Total Reward: -161.40\n",
      "Total Reward: -161.50\n",
      "Total Reward: -161.60\n",
      "Total Reward: -161.70\n",
      "Total Reward: -161.80\n",
      "Total Reward: -161.90\n",
      "Total Reward: -162.00\n",
      "Total Reward: -162.10\n",
      "Total Reward: -162.20\n",
      "Total Reward: -162.30\n",
      "Total Reward: -163.40\n",
      "Total Reward: -163.50\n",
      "Total Reward: -163.60\n",
      "Total Reward: -163.70\n",
      "Total Reward: -164.80\n",
      "Total Reward: -164.90\n",
      "Total Reward: -165.00\n",
      "Total Reward: -165.10\n",
      "Total Reward: -164.20\n",
      "Total Reward: -163.30\n",
      "Total Reward: -162.40\n",
      "Total Reward: -163.50\n",
      "Total Reward: -163.60\n",
      "Total Reward: -162.70\n",
      "Total Reward: -162.80\n",
      "Total Reward: -162.90\n",
      "Total Reward: -162.00\n",
      "Total Reward: -161.10\n",
      "Total Reward: -160.20\n",
      "Total Reward: -159.30\n",
      "Total Reward: -160.40\n",
      "Total Reward: -160.50\n",
      "Total Reward: -159.60\n",
      "Total Reward: -160.70\n",
      "Total Reward: -161.80\n",
      "Total Reward: -162.90\n",
      "Total Reward: -164.00\n",
      "Total Reward: -165.10\n",
      "Total Reward: -165.20\n",
      "Total Reward: -165.30\n",
      "Total Reward: -165.40\n",
      "Total Reward: -165.50\n",
      "Total Reward: -164.60\n",
      "Total Reward: -163.70\n",
      "Total Reward: -162.80\n",
      "Total Reward: -161.90\n",
      "Total Reward: -161.00\n",
      "Total Reward: -162.10\n",
      "Total Reward: -162.20\n",
      "Total Reward: -162.30\n",
      "Total Reward: -161.40\n",
      "Total Reward: -162.50\n",
      "Total Reward: -163.60\n",
      "Total Reward: -163.70\n",
      "Total Reward: -163.80\n",
      "Total Reward: -164.90\n",
      "Total Reward: -166.00\n",
      "Total Reward: -167.10\n",
      "Total Reward: -167.20\n",
      "Total Reward: -167.30\n",
      "Total Reward: -166.40\n",
      "Total Reward: -165.50\n",
      "Total Reward: -164.60\n",
      "Total Reward: -163.70\n",
      "Total Reward: -162.80\n",
      "Total Reward: -163.90\n",
      "Total Reward: -165.00\n",
      "Total Reward: -165.10\n",
      "Total Reward: -165.20\n",
      "Total Reward: -165.30\n",
      "Total Reward: -165.40\n",
      "Total Reward: -164.50\n",
      "Total Reward: -163.60\n",
      "Total Reward: -164.70\n",
      "Total Reward: -165.80\n",
      "Total Reward: -165.90\n",
      "Total Reward: -166.00\n",
      "Total Reward: -166.10\n",
      "Total Reward: -165.20\n",
      "Total Reward: -164.30\n",
      "Total Reward: -165.40\n",
      "Total Reward: -165.50\n",
      "Total Reward: -164.60\n",
      "Total Reward: -165.70\n",
      "Total Reward: -166.80\n",
      "Total Reward: -166.90\n",
      "Total Reward: -167.00\n",
      "Total Reward: -167.10\n",
      "Total Reward: -167.20\n",
      "Total Reward: -166.30\n",
      "Total Reward: -165.40\n",
      "Total Reward: -165.50\n",
      "Total Reward: -155.50\n",
      "Total Reward: -48.00\n",
      "Total Reward: -48.10\n",
      "Total Reward: -48.20\n",
      "Total Reward: -48.30\n",
      "Total Reward: -48.40\n",
      "Total Reward: -48.50\n",
      "Total Reward: -48.60\n",
      "Total Reward: -48.70\n",
      "Total Reward: -48.80\n",
      "Total Reward: -48.90\n",
      "Total Reward: -49.00\n",
      "Total Reward: -49.10\n",
      "Total Reward: -48.20\n",
      "Total Reward: -48.30\n",
      "Total Reward: -48.40\n",
      "Total Reward: -49.50\n",
      "Total Reward: -49.60\n",
      "Total Reward: -49.70\n",
      "Total Reward: -49.80\n",
      "Total Reward: -49.90\n",
      "Total Reward: -50.00\n",
      "Total Reward: -50.10\n",
      "Total Reward: -50.20\n",
      "Total Reward: -50.30\n",
      "Total Reward: -50.40\n",
      "Total Reward: -49.50\n",
      "Total Reward: -49.60\n",
      "Total Reward: -49.70\n",
      "Total Reward: -48.80\n",
      "Total Reward: -47.90\n",
      "Total Reward: -48.00\n",
      "Total Reward: -48.10\n",
      "Total Reward: -47.20\n",
      "Total Reward: -47.30\n",
      "Total Reward: -47.40\n",
      "Total Reward: -47.50\n",
      "Total Reward: -47.60\n",
      "Total Reward: -47.70\n",
      "Total Reward: -47.80\n",
      "Total Reward: -47.90\n",
      "Total Reward: -48.00\n",
      "Total Reward: -49.10\n",
      "Total Reward: -50.20\n",
      "Total Reward: -50.30\n",
      "Total Reward: -50.40\n",
      "Total Reward: -51.50\n",
      "Total Reward: -52.60\n",
      "Total Reward: -52.70\n",
      "Total Reward: -52.80\n",
      "Total Reward: -52.90\n",
      "Total Reward: -52.00\n",
      "Total Reward: -51.10\n",
      "Total Reward: -50.20\n",
      "Total Reward: -50.30\n",
      "Total Reward: -50.40\n",
      "Total Reward: -51.50\n",
      "Total Reward: -51.60\n",
      "Total Reward: -51.70\n",
      "Total Reward: -51.80\n",
      "Total Reward: -52.90\n",
      "Total Reward: -54.00\n",
      "Total Reward: -54.10\n",
      "Total Reward: -54.20\n",
      "Total Reward: -54.30\n",
      "Total Reward: -55.40\n",
      "Total Reward: -55.50\n",
      "Total Reward: -54.60\n",
      "Total Reward: -54.70\n",
      "Total Reward: -53.80\n",
      "Total Reward: -52.90\n",
      "Total Reward: -53.00\n",
      "Total Reward: -53.10\n",
      "Total Reward: -54.20\n",
      "Total Reward: -54.30\n",
      "Total Reward: -55.40\n",
      "Total Reward: -55.50\n",
      "Total Reward: -54.60\n",
      "Total Reward: -54.70\n",
      "Total Reward: -54.80\n",
      "Total Reward: -55.90\n",
      "Total Reward: -56.00\n",
      "Total Reward: -55.10\n",
      "Total Reward: -54.20\n",
      "Total Reward: -54.30\n",
      "Total Reward: -54.40\n",
      "Total Reward: -54.50\n",
      "Total Reward: -54.60\n",
      "Total Reward: -54.70\n",
      "Total Reward: -54.80\n",
      "Total Reward: -55.90\n",
      "Total Reward: -56.00\n",
      "Total Reward: -56.10\n",
      "Total Reward: -55.20\n",
      "Total Reward: -54.30\n",
      "Total Reward: -53.40\n",
      "Total Reward: -53.50\n",
      "Total Reward: -52.60\n",
      "Total Reward: -52.70\n",
      "Total Reward: -52.80\n",
      "Total Reward: -52.90\n",
      "Total Reward: -53.00\n",
      "Total Reward: -53.10\n",
      "Total Reward: -53.20\n",
      "Total Reward: -53.30\n",
      "Total Reward: -53.40\n",
      "Total Reward: -52.50\n",
      "Total Reward: -52.60\n",
      "Total Reward: -52.70\n",
      "Total Reward: -53.80\n",
      "Total Reward: -53.90\n",
      "Total Reward: -54.00\n",
      "Total Reward: -54.10\n",
      "Total Reward: -54.20\n",
      "Total Reward: -54.30\n",
      "Total Reward: -54.40\n",
      "Total Reward: -53.50\n",
      "Total Reward: -52.60\n",
      "Total Reward: -52.70\n",
      "Total Reward: -51.80\n",
      "Total Reward: -50.90\n",
      "Total Reward: -50.00\n",
      "Total Reward: -50.10\n",
      "Total Reward: -49.20\n",
      "Total Reward: -49.30\n",
      "Total Reward: -49.40\n",
      "Total Reward: -49.50\n",
      "Total Reward: -39.50\n",
      "Total Reward: -14.30\n",
      "Total Reward: -16.10\n",
      "Total Reward: 8.50\n",
      "Total Reward: 4.20\n",
      "Total Reward: -55.00\n",
      "Total Reward: -55.10\n",
      "Total Reward: -56.20\n",
      "Total Reward: -56.30\n",
      "Total Reward: -56.40\n",
      "Total Reward: -55.50\n",
      "Total Reward: -54.60\n",
      "Total Reward: -54.70\n",
      "Total Reward: -54.80\n",
      "Total Reward: -53.90\n",
      "Total Reward: -54.00\n",
      "Total Reward: -54.10\n",
      "Total Reward: -54.20\n",
      "Total Reward: -53.30\n",
      "Total Reward: -52.40\n",
      "Total Reward: -51.50\n",
      "Total Reward: -50.60\n",
      "Total Reward: -51.70\n",
      "Total Reward: -51.80\n",
      "Total Reward: -51.90\n",
      "Total Reward: -51.00\n",
      "Total Reward: -52.10\n",
      "Total Reward: -52.20\n",
      "Total Reward: -52.30\n",
      "Total Reward: -53.40\n",
      "Total Reward: -54.50\n",
      "Total Reward: -54.60\n",
      "Total Reward: -54.70\n",
      "Total Reward: -55.80\n",
      "Total Reward: -56.90\n",
      "Total Reward: -57.00\n",
      "Total Reward: -57.10\n",
      "Total Reward: -56.20\n",
      "Total Reward: -55.30\n",
      "Total Reward: -55.40\n",
      "Total Reward: -55.50\n",
      "Total Reward: -54.60\n",
      "Total Reward: -53.70\n",
      "Total Reward: -52.80\n",
      "Total Reward: -53.90\n",
      "Total Reward: -54.00\n",
      "Total Reward: -53.10\n",
      "Total Reward: -52.20\n",
      "Total Reward: -52.30\n",
      "Total Reward: -52.40\n",
      "Total Reward: -52.50\n",
      "Total Reward: -52.60\n",
      "Total Reward: -52.70\n",
      "Total Reward: -52.80\n",
      "Total Reward: -53.90\n",
      "Total Reward: -54.00\n",
      "Total Reward: -54.10\n",
      "Total Reward: -54.20\n",
      "Total Reward: -54.30\n",
      "Total Reward: -53.40\n",
      "Total Reward: -53.50\n",
      "Total Reward: -53.60\n",
      "Total Reward: -53.70\n",
      "Total Reward: -43.70\n",
      "Total Reward: -52.00\n",
      "Total Reward: -52.10\n",
      "Total Reward: -52.20\n",
      "Total Reward: -52.30\n",
      "Total Reward: -52.40\n",
      "Total Reward: -52.50\n",
      "Total Reward: -52.60\n",
      "Total Reward: -52.70\n",
      "Total Reward: -52.80\n",
      "Total Reward: -52.90\n",
      "Total Reward: -53.00\n",
      "Total Reward: -53.10\n",
      "Total Reward: -53.20\n",
      "Total Reward: -53.30\n",
      "Total Reward: -53.40\n",
      "Total Reward: -53.50\n",
      "Total Reward: -53.60\n",
      "Total Reward: -53.70\n",
      "Total Reward: -53.80\n",
      "Total Reward: -53.90\n",
      "Total Reward: -54.00\n",
      "Total Reward: -54.10\n",
      "Total Reward: -53.20\n",
      "Total Reward: -53.30\n",
      "Total Reward: -53.40\n",
      "Total Reward: -54.50\n",
      "Total Reward: -54.60\n",
      "Total Reward: -54.70\n",
      "Total Reward: -54.80\n",
      "Total Reward: -54.90\n",
      "Total Reward: -55.00\n",
      "Total Reward: -55.10\n",
      "Total Reward: -55.20\n",
      "Total Reward: -55.30\n",
      "Total Reward: -55.40\n",
      "Total Reward: -54.50\n",
      "Total Reward: -53.60\n",
      "Total Reward: -52.70\n",
      "Total Reward: -51.80\n",
      "Total Reward: -51.90\n",
      "Total Reward: -52.00\n",
      "Total Reward: -53.10\n",
      "Total Reward: -54.20\n",
      "Total Reward: -54.30\n",
      "Total Reward: -54.40\n",
      "Total Reward: -55.50\n",
      "Total Reward: -55.60\n",
      "Total Reward: -55.70\n",
      "Total Reward: -55.80\n",
      "Total Reward: -55.90\n",
      "Total Reward: -56.00\n",
      "Total Reward: -56.10\n",
      "Total Reward: -56.20\n",
      "Total Reward: -57.30\n",
      "Total Reward: -57.40\n",
      "Total Reward: -57.50\n",
      "Total Reward: -57.60\n",
      "Total Reward: -57.70\n",
      "Total Reward: -57.80\n",
      "Total Reward: -56.90\n",
      "Total Reward: -57.00\n",
      "Total Reward: -57.10\n",
      "Total Reward: -57.20\n",
      "Total Reward: -57.30\n",
      "Total Reward: -57.40\n",
      "Total Reward: -58.50\n",
      "Total Reward: -58.60\n",
      "Total Reward: -58.70\n",
      "Total Reward: -58.80\n",
      "Total Reward: -59.90\n",
      "Total Reward: -61.00\n",
      "Total Reward: -61.10\n",
      "Total Reward: -61.20\n",
      "Total Reward: -61.30\n",
      "Total Reward: -61.40\n",
      "Total Reward: -61.50\n",
      "Total Reward: -60.60\n",
      "Total Reward: -60.70\n",
      "Total Reward: -60.80\n",
      "Total Reward: -60.90\n",
      "Total Reward: -61.00\n",
      "Total Reward: -60.10\n",
      "Total Reward: -60.20\n",
      "Total Reward: -60.30\n",
      "Total Reward: -60.40\n",
      "Total Reward: -60.50\n",
      "Total Reward: -61.60\n",
      "Total Reward: -61.70\n",
      "Total Reward: -61.80\n",
      "Total Reward: -60.90\n",
      "Total Reward: -61.00\n",
      "Total Reward: -61.10\n",
      "Total Reward: -61.20\n",
      "Total Reward: -61.30\n",
      "Total Reward: -61.40\n",
      "Total Reward: -61.50\n",
      "Total Reward: -61.60\n",
      "Total Reward: -61.70\n",
      "Total Reward: -61.80\n",
      "Total Reward: -61.90\n",
      "Total Reward: -62.00\n",
      "Total Reward: -62.10\n",
      "Total Reward: -62.20\n",
      "Total Reward: -62.30\n",
      "Total Reward: -62.40\n",
      "Total Reward: -62.50\n",
      "Total Reward: -62.60\n",
      "Total Reward: -62.70\n",
      "Total Reward: -62.80\n",
      "Total Reward: -62.90\n",
      "Total Reward: -63.00\n",
      "Total Reward: -63.10\n",
      "Total Reward: -63.20\n",
      "Total Reward: -63.30\n",
      "Total Reward: -63.40\n",
      "Total Reward: -63.50\n",
      "Total Reward: -63.60\n",
      "Total Reward: -62.70\n",
      "Total Reward: -62.80\n",
      "Total Reward: -62.90\n",
      "Total Reward: -63.00\n",
      "Total Reward: -63.10\n",
      "Total Reward: -64.20\n",
      "Total Reward: -64.30\n",
      "Total Reward: -64.40\n",
      "Total Reward: -64.50\n",
      "Total Reward: -64.60\n",
      "Total Reward: -64.70\n",
      "Total Reward: -64.80\n",
      "Total Reward: -64.90\n",
      "Total Reward: -65.00\n",
      "Total Reward: -65.10\n",
      "Total Reward: -65.20\n",
      "Total Reward: -65.30\n",
      "Total Reward: -65.40\n",
      "Total Reward: -65.50\n",
      "Total Reward: -65.60\n",
      "Total Reward: -66.70\n",
      "Total Reward: -66.80\n",
      "Total Reward: -66.90\n",
      "Total Reward: -67.00\n",
      "Total Reward: -67.10\n",
      "Total Reward: -66.20\n",
      "Total Reward: -66.30\n",
      "Total Reward: -66.40\n",
      "Total Reward: -66.50\n",
      "Total Reward: -66.60\n",
      "Total Reward: -66.70\n",
      "Total Reward: -66.80\n",
      "Total Reward: -66.90\n",
      "Total Reward: -67.00\n",
      "Total Reward: -67.10\n",
      "Total Reward: -68.20\n",
      "Total Reward: -68.30\n",
      "Total Reward: -68.40\n",
      "Total Reward: -67.50\n",
      "Total Reward: -67.60\n",
      "Total Reward: -67.70\n",
      "Total Reward: -67.80\n",
      "Total Reward: -67.90\n",
      "Total Reward: -68.00\n",
      "Total Reward: -68.10\n",
      "Total Reward: -68.20\n",
      "Total Reward: -68.30\n",
      "Total Reward: -68.40\n",
      "Total Reward: -68.50\n",
      "Total Reward: -68.60\n",
      "Total Reward: -68.70\n",
      "Total Reward: -68.80\n",
      "Total Reward: -67.90\n",
      "Total Reward: -68.00\n",
      "Total Reward: -68.10\n",
      "Total Reward: -67.20\n",
      "Total Reward: -66.30\n",
      "Total Reward: -66.40\n",
      "Total Reward: -66.50\n",
      "Total Reward: -66.60\n",
      "Total Reward: -66.70\n",
      "Total Reward: -66.80\n",
      "Total Reward: -66.90\n",
      "Total Reward: -67.00\n",
      "Total Reward: -68.10\n",
      "Total Reward: -69.20\n",
      "Total Reward: -69.30\n",
      "Total Reward: -69.40\n",
      "Total Reward: -68.50\n",
      "Total Reward: -67.60\n",
      "Total Reward: -67.70\n",
      "Total Reward: -67.80\n",
      "Total Reward: -67.90\n",
      "Total Reward: -68.00\n",
      "Total Reward: -68.10\n",
      "Total Reward: -67.20\n",
      "Total Reward: -67.30\n",
      "Total Reward: -67.40\n",
      "Total Reward: -68.50\n",
      "Total Reward: -68.60\n",
      "Total Reward: -68.70\n",
      "Total Reward: -69.80\n",
      "Total Reward: -70.90\n",
      "Total Reward: -71.00\n",
      "Total Reward: -71.10\n",
      "Total Reward: -72.20\n",
      "Total Reward: -72.30\n",
      "Total Reward: -72.40\n",
      "Total Reward: -72.50\n",
      "Total Reward: -72.60\n",
      "Total Reward: -72.70\n",
      "Total Reward: -72.80\n",
      "Total Reward: -72.90\n",
      "Total Reward: -73.00\n",
      "Total Reward: -73.10\n",
      "Total Reward: -73.20\n",
      "Total Reward: -73.30\n",
      "Total Reward: -73.40\n",
      "Total Reward: -73.50\n",
      "Total Reward: -73.60\n",
      "Total Reward: -73.70\n",
      "Total Reward: -73.80\n",
      "Total Reward: -73.90\n",
      "Total Reward: -74.00\n",
      "Total Reward: -74.10\n",
      "Total Reward: -74.20\n",
      "Total Reward: -74.30\n",
      "Total Reward: -73.40\n",
      "Total Reward: -72.50\n",
      "Total Reward: -72.60\n",
      "Total Reward: -72.70\n",
      "Total Reward: -72.80\n",
      "Total Reward: -72.90\n",
      "Total Reward: -73.00\n",
      "Total Reward: -73.10\n",
      "Total Reward: -73.20\n",
      "Total Reward: -72.30\n",
      "Total Reward: -71.40\n",
      "Total Reward: -71.50\n",
      "Total Reward: -71.60\n",
      "Total Reward: -72.70\n",
      "Total Reward: -73.80\n",
      "Total Reward: -74.90\n",
      "Total Reward: -76.00\n",
      "Total Reward: -76.10\n",
      "Total Reward: -76.20\n",
      "Total Reward: -76.30\n",
      "Total Reward: -75.40\n",
      "Total Reward: -74.50\n",
      "Total Reward: -73.60\n",
      "Total Reward: -73.70\n",
      "Total Reward: -73.80\n",
      "Total Reward: -72.90\n",
      "Total Reward: -73.00\n",
      "Total Reward: -73.10\n",
      "Total Reward: -74.20\n",
      "Total Reward: -74.30\n",
      "Total Reward: -74.40\n",
      "Total Reward: -75.50\n",
      "Total Reward: -75.60\n",
      "Total Reward: -75.70\n",
      "Total Reward: -74.80\n",
      "Total Reward: -73.90\n",
      "Total Reward: -74.00\n",
      "Total Reward: -75.10\n",
      "Total Reward: -75.20\n",
      "Total Reward: -75.30\n",
      "Total Reward: -75.40\n",
      "Total Reward: -74.50\n",
      "Total Reward: -74.60\n",
      "Total Reward: -75.70\n",
      "Total Reward: -75.80\n",
      "Total Reward: -75.90\n",
      "Total Reward: -75.00\n",
      "Total Reward: -75.10\n",
      "Total Reward: -75.20\n",
      "Total Reward: -76.30\n",
      "Total Reward: -77.40\n",
      "Total Reward: -77.50\n",
      "Total Reward: -77.60\n",
      "Total Reward: -76.70\n",
      "Total Reward: -75.80\n",
      "Total Reward: -74.90\n",
      "Total Reward: -76.00\n",
      "Total Reward: -76.10\n",
      "Total Reward: -76.20\n",
      "Total Reward: -75.30\n",
      "Total Reward: -76.40\n",
      "Total Reward: -76.50\n",
      "Total Reward: -76.60\n",
      "Total Reward: -76.70\n",
      "Total Reward: -76.80\n",
      "Total Reward: -76.90\n",
      "Total Reward: -76.00\n",
      "Total Reward: -76.10\n",
      "Total Reward: -76.20\n",
      "Total Reward: -76.30\n",
      "Total Reward: -76.40\n",
      "Total Reward: -77.50\n",
      "Total Reward: -78.60\n",
      "Total Reward: -78.70\n",
      "Total Reward: -78.80\n",
      "Total Reward: -78.90\n",
      "Total Reward: -79.00\n",
      "Total Reward: -79.10\n",
      "Total Reward: -79.20\n",
      "Total Reward: -78.30\n",
      "Total Reward: -78.40\n",
      "Total Reward: -78.50\n",
      "Total Reward: -78.60\n",
      "Total Reward: -78.70\n",
      "Total Reward: -78.80\n",
      "Total Reward: -79.90\n",
      "Total Reward: -80.00\n",
      "Total Reward: -80.10\n",
      "Total Reward: -79.20\n",
      "Total Reward: -78.30\n",
      "Total Reward: -78.40\n",
      "Total Reward: -78.50\n",
      "Total Reward: -79.60\n",
      "Total Reward: -79.70\n",
      "Total Reward: -79.80\n",
      "Total Reward: -80.90\n",
      "Total Reward: -82.00\n",
      "Total Reward: -83.10\n",
      "Total Reward: -84.20\n",
      "Total Reward: -84.30\n",
      "Total Reward: -83.40\n",
      "Total Reward: -82.50\n",
      "Total Reward: -82.60\n",
      "Total Reward: -82.70\n",
      "Total Reward: -82.80\n",
      "Total Reward: -82.90\n",
      "Total Reward: -84.00\n",
      "Total Reward: -84.10\n",
      "Total Reward: -85.20\n",
      "Total Reward: -85.30\n",
      "Total Reward: -85.40\n",
      "Total Reward: -84.50\n",
      "Total Reward: -84.60\n",
      "Total Reward: -85.70\n",
      "Total Reward: -85.80\n",
      "Total Reward: -84.90\n",
      "Total Reward: -84.00\n",
      "Total Reward: -83.10\n",
      "Total Reward: -83.20\n",
      "Total Reward: -83.30\n",
      "Total Reward: -84.40\n",
      "Total Reward: -84.50\n",
      "Total Reward: -84.60\n",
      "Total Reward: -83.70\n",
      "Total Reward: -83.80\n",
      "Total Reward: -83.90\n",
      "Total Reward: -85.00\n",
      "Total Reward: -85.10\n",
      "Total Reward: -85.20\n",
      "Total Reward: -84.30\n",
      "Total Reward: -83.40\n",
      "Total Reward: -82.50\n",
      "Total Reward: -83.60\n",
      "Total Reward: -83.70\n",
      "Total Reward: -83.80\n",
      "Total Reward: -82.90\n",
      "Total Reward: -84.00\n",
      "Total Reward: -85.10\n",
      "Total Reward: -86.20\n",
      "Total Reward: -86.30\n",
      "Total Reward: -86.40\n",
      "Total Reward: -86.50\n",
      "Total Reward: -86.60\n",
      "Total Reward: -86.70\n",
      "Total Reward: -86.80\n",
      "Total Reward: -85.90\n",
      "Total Reward: -85.00\n",
      "Total Reward: -85.10\n",
      "Total Reward: -85.20\n",
      "Total Reward: -85.30\n",
      "Total Reward: -85.40\n",
      "Total Reward: -85.50\n",
      "Total Reward: -85.60\n",
      "Total Reward: -86.70\n",
      "Total Reward: -87.80\n",
      "Total Reward: -87.90\n",
      "Total Reward: -88.00\n",
      "Total Reward: -89.10\n",
      "Total Reward: -89.20\n",
      "Total Reward: -88.30\n",
      "Total Reward: -87.40\n",
      "Total Reward: -87.50\n",
      "Total Reward: -87.60\n",
      "Total Reward: -87.70\n",
      "Total Reward: -86.80\n",
      "Total Reward: -86.90\n",
      "Total Reward: -87.00\n",
      "Total Reward: -87.10\n",
      "Total Reward: -88.20\n",
      "Total Reward: -89.30\n",
      "Total Reward: -90.40\n",
      "Total Reward: -91.50\n",
      "Total Reward: -91.60\n",
      "Total Reward: -91.70\n",
      "Total Reward: -91.80\n",
      "Total Reward: -91.90\n",
      "Total Reward: -92.00\n",
      "Total Reward: -92.10\n",
      "Total Reward: -91.20\n",
      "Total Reward: -91.30\n",
      "Total Reward: -91.40\n",
      "Total Reward: -91.50\n",
      "Total Reward: -91.60\n",
      "Total Reward: -91.70\n",
      "Total Reward: -92.80\n",
      "Total Reward: -92.90\n",
      "Total Reward: -93.00\n",
      "Total Reward: -93.10\n",
      "Total Reward: -93.20\n",
      "Total Reward: -93.30\n",
      "Total Reward: -93.40\n",
      "Total Reward: -93.50\n",
      "Total Reward: -93.60\n",
      "Total Reward: -92.70\n",
      "Total Reward: -92.80\n",
      "Total Reward: -93.90\n",
      "Total Reward: -94.00\n",
      "Total Reward: -94.10\n",
      "Total Reward: -94.20\n",
      "Total Reward: -94.30\n",
      "Total Reward: -94.40\n",
      "Total Reward: -94.50\n",
      "Total Reward: -94.60\n",
      "Total Reward: -94.70\n",
      "Total Reward: -94.80\n",
      "Total Reward: -94.90\n",
      "Total Reward: -95.00\n",
      "Total Reward: -95.10\n",
      "Total Reward: -95.20\n",
      "Total Reward: -95.30\n",
      "Total Reward: -95.40\n",
      "Total Reward: -95.50\n",
      "Total Reward: -95.60\n",
      "Total Reward: -95.70\n",
      "Total Reward: -95.80\n",
      "Total Reward: -95.90\n",
      "Total Reward: -95.00\n",
      "Total Reward: -94.10\n",
      "Total Reward: -94.20\n",
      "Total Reward: -94.30\n",
      "Total Reward: -94.40\n",
      "Total Reward: -94.50\n",
      "Total Reward: -94.60\n",
      "Total Reward: -94.70\n",
      "Total Reward: -95.80\n",
      "Total Reward: -95.90\n",
      "Total Reward: -96.00\n",
      "Total Reward: -96.10\n",
      "Total Reward: -96.20\n",
      "Total Reward: -96.30\n",
      "Total Reward: -96.40\n",
      "Total Reward: -96.50\n",
      "Total Reward: -96.60\n",
      "Total Reward: -96.70\n",
      "Total Reward: -96.80\n",
      "Total Reward: -96.90\n",
      "Total Reward: -98.00\n",
      "Total Reward: -98.10\n",
      "Total Reward: -98.20\n",
      "Total Reward: -98.30\n",
      "Total Reward: -98.40\n",
      "Total Reward: -98.50\n",
      "Total Reward: -98.60\n",
      "Total Reward: -98.70\n",
      "Total Reward: -98.80\n",
      "Total Reward: -98.90\n",
      "Total Reward: -99.00\n",
      "Total Reward: -99.10\n",
      "Total Reward: -99.20\n",
      "Total Reward: -99.30\n",
      "Total Reward: -99.40\n",
      "Total Reward: -99.50\n",
      "Total Reward: -99.60\n",
      "Total Reward: -99.70\n",
      "Total Reward: -99.80\n",
      "Total Reward: -99.90\n",
      "Total Reward: -100.00\n",
      "Total Reward: -100.10\n",
      "Total Reward: -100.20\n",
      "Total Reward: -100.30\n",
      "Total Reward: -100.40\n",
      "Total Reward: -100.50\n",
      "Total Reward: -100.60\n",
      "Total Reward: -100.70\n",
      "Total Reward: -100.80\n",
      "Total Reward: -100.90\n",
      "Total Reward: -101.00\n",
      "Total Reward: -101.10\n",
      "Total Reward: -101.20\n",
      "Total Reward: -101.30\n",
      "Total Reward: -101.40\n",
      "Total Reward: -101.50\n",
      "Total Reward: -101.60\n",
      "Total Reward: -101.70\n",
      "Total Reward: -101.80\n",
      "Total Reward: -101.90\n",
      "Total Reward: -102.00\n",
      "Total Reward: -102.10\n",
      "Total Reward: -102.20\n",
      "Total Reward: -102.30\n",
      "Total Reward: -101.40\n",
      "Total Reward: -100.50\n",
      "Total Reward: -99.60\n",
      "Total Reward: -99.70\n",
      "Total Reward: -99.80\n",
      "Total Reward: -98.90\n",
      "Total Reward: -99.00\n",
      "Total Reward: -99.10\n",
      "Total Reward: -99.20\n",
      "Total Reward: -99.30\n",
      "Total Reward: -99.40\n",
      "Total Reward: -99.50\n",
      "Total Reward: -99.60\n",
      "Total Reward: -99.70\n",
      "Total Reward: -100.80\n",
      "Total Reward: -100.90\n",
      "Total Reward: -101.00\n",
      "Total Reward: -101.10\n",
      "Total Reward: -101.20\n",
      "Total Reward: -102.30\n",
      "Total Reward: -102.40\n",
      "Total Reward: -102.50\n",
      "Total Reward: -102.60\n",
      "Total Reward: -102.70\n",
      "Total Reward: -102.80\n",
      "Total Reward: -102.90\n",
      "Total Reward: -103.00\n",
      "Total Reward: -102.10\n",
      "Total Reward: -102.20\n",
      "Total Reward: -102.30\n",
      "Total Reward: -103.40\n",
      "Total Reward: -103.50\n",
      "Total Reward: -103.60\n",
      "Total Reward: -103.70\n",
      "Total Reward: -103.80\n",
      "Total Reward: -103.90\n",
      "Total Reward: -105.00\n",
      "Total Reward: -105.10\n",
      "Total Reward: -105.20\n",
      "Total Reward: -106.30\n",
      "Total Reward: -106.40\n",
      "Total Reward: -106.50\n",
      "Total Reward: -106.60\n",
      "Total Reward: -106.70\n",
      "Total Reward: -106.80\n",
      "Total Reward: -106.90\n",
      "Total Reward: -107.00\n",
      "Total Reward: -106.10\n",
      "Total Reward: -105.20\n",
      "Total Reward: -104.30\n",
      "Total Reward: -103.40\n",
      "Total Reward: -103.50\n",
      "Total Reward: -103.60\n",
      "Total Reward: -103.70\n",
      "Total Reward: -103.80\n",
      "Total Reward: -103.90\n",
      "Total Reward: -104.00\n",
      "Total Reward: -105.10\n",
      "Total Reward: -106.20\n",
      "Total Reward: -106.30\n",
      "Total Reward: -106.40\n",
      "Total Reward: -106.50\n",
      "Total Reward: -106.60\n",
      "Total Reward: -106.70\n",
      "Total Reward: -106.80\n",
      "Total Reward: -107.90\n",
      "Total Reward: -108.00\n",
      "Total Reward: -108.10\n",
      "Total Reward: -108.20\n",
      "Total Reward: -109.30\n",
      "Total Reward: -109.40\n",
      "Total Reward: -109.50\n",
      "Total Reward: -109.60\n",
      "Total Reward: -109.70\n",
      "Total Reward: -109.80\n",
      "Total Reward: -109.90\n",
      "Total Reward: -110.00\n",
      "Total Reward: -110.10\n",
      "Total Reward: -110.20\n",
      "Total Reward: -110.30\n",
      "Total Reward: -110.40\n",
      "Total Reward: -109.50\n",
      "Total Reward: -108.60\n",
      "Total Reward: -108.70\n",
      "Total Reward: -108.80\n",
      "Total Reward: -108.90\n",
      "Total Reward: -109.00\n",
      "Total Reward: -109.10\n",
      "Total Reward: -109.20\n",
      "Total Reward: -109.30\n",
      "Total Reward: -110.40\n",
      "Total Reward: -110.50\n",
      "Total Reward: -110.60\n",
      "Total Reward: -110.70\n",
      "Total Reward: -110.80\n",
      "Total Reward: -110.90\n",
      "Total Reward: -110.00\n",
      "Total Reward: -110.10\n",
      "Total Reward: -110.20\n",
      "Total Reward: -110.30\n",
      "Total Reward: -111.40\n",
      "Total Reward: -111.50\n",
      "Total Reward: -110.60\n",
      "Total Reward: -109.70\n",
      "Total Reward: -108.80\n",
      "Total Reward: -108.90\n",
      "Total Reward: -109.00\n",
      "Total Reward: -110.10\n",
      "Total Reward: -110.20\n",
      "Total Reward: -110.30\n",
      "Total Reward: -109.40\n",
      "Total Reward: -108.50\n",
      "Total Reward: -109.60\n",
      "Total Reward: -109.70\n",
      "Total Reward: -109.80\n",
      "Total Reward: -109.90\n",
      "Total Reward: -110.00\n",
      "Total Reward: -109.10\n",
      "Total Reward: -109.20\n",
      "Total Reward: -109.30\n",
      "Total Reward: -110.40\n",
      "Total Reward: -111.50\n",
      "Total Reward: -111.60\n",
      "Total Reward: -111.70\n",
      "Total Reward: -110.80\n",
      "Total Reward: -110.90\n",
      "Total Reward: -111.00\n",
      "Total Reward: -111.10\n",
      "Total Reward: -111.20\n",
      "Total Reward: -112.30\n",
      "Total Reward: -112.40\n",
      "Total Reward: -112.50\n",
      "Total Reward: -113.60\n",
      "Total Reward: -113.70\n",
      "Total Reward: -113.80\n",
      "Total Reward: -113.90\n",
      "Total Reward: -114.00\n",
      "Total Reward: -114.10\n",
      "Total Reward: -114.20\n",
      "Total Reward: -113.30\n",
      "Total Reward: -112.40\n",
      "Total Reward: -112.50\n",
      "Total Reward: -112.60\n",
      "Total Reward: -112.70\n",
      "Total Reward: -113.80\n",
      "Total Reward: -113.90\n",
      "Total Reward: -114.00\n",
      "Total Reward: -114.10\n",
      "Total Reward: -114.20\n",
      "Total Reward: -114.30\n",
      "Total Reward: -114.40\n",
      "Total Reward: -114.50\n",
      "Total Reward: -115.60\n",
      "Total Reward: -115.70\n",
      "Total Reward: -115.80\n",
      "Total Reward: -115.90\n",
      "Total Reward: -116.00\n",
      "Total Reward: -116.10\n",
      "Total Reward: -116.20\n",
      "Total Reward: -115.30\n",
      "Total Reward: -115.40\n",
      "Total Reward: -115.50\n",
      "Total Reward: -115.60\n",
      "Total Reward: -115.70\n",
      "Total Reward: -114.80\n",
      "Total Reward: -114.90\n",
      "Total Reward: -115.00\n",
      "Total Reward: -115.10\n",
      "Total Reward: -116.20\n",
      "Total Reward: -116.30\n",
      "Total Reward: -116.40\n",
      "Total Reward: -116.50\n",
      "Total Reward: -116.60\n",
      "Total Reward: -116.70\n",
      "Total Reward: -116.80\n",
      "Total Reward: -116.90\n",
      "Total Reward: -117.00\n",
      "Total Reward: -116.10\n",
      "Total Reward: -116.20\n",
      "Total Reward: -116.30\n",
      "Total Reward: -117.40\n",
      "Total Reward: -118.50\n",
      "Total Reward: -118.60\n",
      "Total Reward: -118.70\n",
      "Total Reward: -118.80\n",
      "Total Reward: -118.90\n",
      "Total Reward: -119.00\n",
      "Total Reward: -118.10\n",
      "Total Reward: -118.20\n",
      "Total Reward: -118.30\n",
      "Total Reward: -118.40\n",
      "Total Reward: -119.50\n",
      "Total Reward: -119.60\n",
      "Total Reward: -120.70\n",
      "Total Reward: -120.80\n",
      "Total Reward: -119.90\n",
      "Total Reward: -119.00\n",
      "Total Reward: -118.10\n",
      "Total Reward: -118.20\n",
      "Total Reward: -118.30\n",
      "Total Reward: -119.40\n",
      "Total Reward: -120.50\n",
      "Total Reward: -121.60\n",
      "Total Reward: -122.70\n",
      "Total Reward: -122.80\n",
      "Total Reward: -122.90\n",
      "Total Reward: -123.00\n",
      "Total Reward: -123.10\n",
      "Total Reward: -123.20\n",
      "Total Reward: -122.30\n",
      "Total Reward: -121.40\n",
      "Total Reward: -121.50\n",
      "Total Reward: -121.60\n",
      "Total Reward: -121.70\n",
      "Total Reward: -121.80\n",
      "Total Reward: -121.90\n",
      "Total Reward: -123.00\n",
      "Total Reward: -123.10\n",
      "Total Reward: -123.20\n",
      "Total Reward: -124.30\n",
      "Total Reward: -124.40\n",
      "Total Reward: -124.50\n",
      "Total Reward: -123.60\n",
      "Total Reward: -123.70\n",
      "Total Reward: -123.80\n",
      "Total Reward: -123.90\n",
      "Total Reward: -124.00\n",
      "Total Reward: -123.10\n",
      "Total Reward: -123.20\n",
      "Total Reward: -123.30\n",
      "Total Reward: -123.40\n",
      "Total Reward: -123.50\n",
      "Total Reward: -123.60\n",
      "Total Reward: -124.70\n",
      "Total Reward: -124.80\n",
      "Total Reward: -124.90\n",
      "Total Reward: -126.00\n",
      "Total Reward: -126.10\n",
      "Total Reward: -125.20\n",
      "Total Reward: -124.30\n",
      "Total Reward: -123.40\n",
      "Total Reward: -123.50\n",
      "Total Reward: -123.60\n",
      "Total Reward: -123.70\n",
      "Total Reward: -123.80\n",
      "Total Reward: -123.90\n",
      "Total Reward: -124.00\n",
      "Total Reward: -124.10\n",
      "Total Reward: -124.20\n",
      "Total Reward: -123.30\n",
      "Total Reward: -123.40\n",
      "Total Reward: -123.50\n",
      "Total Reward: -124.60\n",
      "Total Reward: -125.70\n",
      "Total Reward: -126.80\n",
      "Total Reward: -126.90\n",
      "Total Reward: -127.00\n",
      "Total Reward: -126.10\n",
      "Total Reward: -125.20\n",
      "Total Reward: -125.30\n",
      "Total Reward: -125.40\n",
      "Total Reward: -124.50\n",
      "Total Reward: -124.60\n",
      "Total Reward: -124.70\n",
      "Total Reward: -125.80\n",
      "Total Reward: -126.90\n",
      "Total Reward: -127.00\n",
      "Total Reward: -127.10\n",
      "Total Reward: -127.20\n",
      "Total Reward: -127.30\n",
      "Total Reward: -127.40\n",
      "Total Reward: -127.50\n",
      "Total Reward: -127.60\n",
      "Total Reward: -127.70\n",
      "Total Reward: -127.80\n",
      "Total Reward: -127.90\n",
      "Total Reward: -128.00\n",
      "Total Reward: -128.10\n",
      "Total Reward: -127.20\n",
      "Total Reward: -126.30\n",
      "Total Reward: -125.40\n",
      "Total Reward: -125.50\n",
      "Total Reward: -125.60\n",
      "Total Reward: -125.70\n",
      "Total Reward: -126.80\n",
      "Total Reward: -126.90\n",
      "Total Reward: -128.00\n",
      "Total Reward: -128.10\n",
      "Total Reward: -128.20\n",
      "Total Reward: -128.30\n",
      "Total Reward: -128.40\n",
      "Total Reward: -128.50\n",
      "Total Reward: -127.60\n",
      "Total Reward: -126.70\n",
      "Total Reward: -126.80\n",
      "Total Reward: -126.90\n",
      "Total Reward: -127.00\n",
      "Total Reward: -126.10\n",
      "Total Reward: -126.20\n",
      "Total Reward: -126.30\n",
      "Total Reward: -127.40\n",
      "Total Reward: -127.50\n",
      "Total Reward: -127.60\n",
      "Total Reward: -127.70\n",
      "Total Reward: -127.80\n",
      "Total Reward: -127.90\n",
      "Total Reward: -128.00\n",
      "Total Reward: -128.10\n",
      "Total Reward: -127.20\n",
      "Total Reward: -126.30\n",
      "Total Reward: -125.40\n",
      "Total Reward: -124.50\n",
      "Total Reward: -124.60\n",
      "Total Reward: -123.70\n",
      "Total Reward: -123.80\n",
      "Total Reward: -124.90\n",
      "Total Reward: -125.00\n",
      "Total Reward: -125.10\n",
      "Total Reward: -124.20\n",
      "Total Reward: -114.20\n",
      "Total Reward: -43.00\n",
      "Total Reward: -43.10\n",
      "Total Reward: -43.20\n",
      "Total Reward: -43.30\n",
      "Total Reward: -43.40\n",
      "Total Reward: -42.50\n",
      "Total Reward: -43.60\n",
      "Total Reward: -43.70\n",
      "Total Reward: -43.80\n",
      "Total Reward: -43.90\n",
      "Total Reward: -44.00\n",
      "Total Reward: -44.10\n",
      "Total Reward: -44.20\n",
      "Total Reward: -44.30\n",
      "Total Reward: -43.40\n",
      "Total Reward: -43.50\n",
      "Total Reward: -43.60\n",
      "Total Reward: -44.70\n",
      "Total Reward: -44.80\n",
      "Total Reward: -43.90\n",
      "Total Reward: -43.00\n",
      "Total Reward: -43.10\n",
      "Total Reward: -43.20\n",
      "Total Reward: -44.30\n",
      "Total Reward: -44.40\n",
      "Total Reward: -45.50\n",
      "Total Reward: -45.60\n",
      "Total Reward: -44.70\n",
      "Total Reward: -43.80\n",
      "Total Reward: -43.90\n",
      "Total Reward: -43.00\n",
      "Total Reward: -43.10\n",
      "Total Reward: -44.20\n",
      "Total Reward: -45.30\n",
      "Total Reward: -45.40\n",
      "Total Reward: -45.50\n",
      "Total Reward: -46.60\n",
      "Total Reward: -46.70\n",
      "Total Reward: -45.80\n",
      "Total Reward: -45.90\n",
      "Total Reward: -46.00\n",
      "Total Reward: -46.10\n",
      "Total Reward: -46.20\n",
      "Total Reward: -45.30\n",
      "Total Reward: -44.40\n",
      "Total Reward: -34.40\n",
      "Total Reward: -47.00\n",
      "Total Reward: -48.10\n",
      "Total Reward: -48.20\n",
      "Total Reward: -48.30\n",
      "Total Reward: -48.40\n",
      "Total Reward: -48.50\n",
      "Total Reward: -48.60\n",
      "Total Reward: -48.70\n",
      "Total Reward: -49.80\n",
      "Total Reward: -49.90\n",
      "Total Reward: -50.00\n",
      "Total Reward: -50.10\n",
      "Total Reward: -50.20\n",
      "Total Reward: -49.30\n",
      "Total Reward: -49.40\n",
      "Total Reward: -49.50\n",
      "Total Reward: -50.60\n",
      "Total Reward: -51.70\n",
      "Total Reward: -51.80\n",
      "Total Reward: -50.90\n",
      "Total Reward: -51.00\n",
      "Total Reward: -51.10\n",
      "Total Reward: -51.20\n",
      "Total Reward: -51.30\n",
      "Total Reward: -51.40\n",
      "Total Reward: -50.50\n",
      "Total Reward: -49.60\n",
      "Total Reward: -49.70\n",
      "Total Reward: -49.80\n",
      "Total Reward: -49.90\n",
      "Total Reward: -50.00\n",
      "Total Reward: -50.10\n",
      "Total Reward: -49.20\n",
      "Total Reward: -49.30\n",
      "Total Reward: -49.40\n",
      "Total Reward: -49.50\n",
      "Total Reward: -49.60\n",
      "Total Reward: -49.70\n",
      "Total Reward: -49.80\n",
      "Total Reward: -49.90\n",
      "Total Reward: -50.00\n",
      "Total Reward: -50.10\n",
      "Total Reward: -50.20\n",
      "Total Reward: -50.30\n",
      "Total Reward: -50.40\n",
      "Total Reward: -50.50\n",
      "Total Reward: -51.60\n",
      "Total Reward: -51.70\n",
      "Total Reward: -51.80\n",
      "Total Reward: -51.90\n",
      "Total Reward: -52.00\n",
      "Total Reward: -53.10\n",
      "Total Reward: -53.20\n",
      "Total Reward: -53.30\n",
      "Total Reward: -53.40\n",
      "Total Reward: -53.50\n",
      "Total Reward: -53.60\n",
      "Total Reward: -53.70\n",
      "Total Reward: -53.80\n",
      "Total Reward: -52.90\n",
      "Total Reward: -52.00\n",
      "Total Reward: -52.10\n",
      "Total Reward: -52.20\n",
      "Total Reward: -53.30\n",
      "Total Reward: -54.40\n",
      "Total Reward: -54.50\n",
      "Total Reward: -54.60\n",
      "Total Reward: -53.70\n",
      "Total Reward: -52.80\n",
      "Total Reward: -52.90\n",
      "Total Reward: -53.00\n",
      "Total Reward: -54.10\n",
      "Total Reward: -55.20\n",
      "Total Reward: -55.30\n",
      "Total Reward: -56.40\n",
      "Total Reward: -56.50\n",
      "Total Reward: -56.60\n",
      "Total Reward: -56.70\n",
      "Total Reward: -56.80\n",
      "Total Reward: -56.90\n",
      "Total Reward: -57.00\n",
      "Total Reward: -57.10\n",
      "Total Reward: -57.20\n",
      "Total Reward: -57.30\n",
      "Total Reward: -57.40\n",
      "Total Reward: -57.50\n",
      "Total Reward: -56.60\n",
      "Total Reward: -56.70\n",
      "Total Reward: -56.80\n",
      "Total Reward: -56.90\n",
      "Total Reward: -57.00\n",
      "Total Reward: -57.10\n",
      "Total Reward: -57.20\n",
      "Total Reward: -57.30\n",
      "Total Reward: -57.40\n",
      "Total Reward: -57.50\n",
      "Total Reward: -57.60\n",
      "Total Reward: -57.70\n",
      "Total Reward: -57.80\n",
      "Total Reward: -57.90\n",
      "Total Reward: -59.00\n",
      "Total Reward: -59.10\n",
      "Total Reward: -59.20\n",
      "Total Reward: -59.30\n",
      "Total Reward: -59.40\n",
      "Total Reward: -59.50\n",
      "Total Reward: -59.60\n",
      "Total Reward: -59.70\n",
      "Total Reward: -59.80\n",
      "Total Reward: -59.90\n",
      "Total Reward: -60.00\n",
      "Total Reward: -60.10\n",
      "Total Reward: -60.20\n",
      "Total Reward: -60.30\n",
      "Total Reward: -60.40\n",
      "Total Reward: -60.50\n",
      "Total Reward: -60.60\n",
      "Total Reward: -60.70\n",
      "Total Reward: -60.80\n",
      "Total Reward: -60.90\n",
      "Total Reward: -61.00\n",
      "Total Reward: -62.10\n",
      "Total Reward: -62.20\n",
      "Total Reward: -62.30\n",
      "Total Reward: -62.40\n",
      "Total Reward: -62.50\n",
      "Total Reward: -62.60\n",
      "Total Reward: -62.70\n",
      "Total Reward: -62.80\n",
      "Total Reward: -62.90\n",
      "Total Reward: -63.00\n",
      "Total Reward: -62.10\n",
      "Total Reward: -61.20\n",
      "Total Reward: -60.30\n",
      "Total Reward: -60.40\n",
      "Total Reward: -60.50\n",
      "Total Reward: -61.60\n",
      "Total Reward: -61.70\n",
      "Total Reward: -61.80\n",
      "Total Reward: -61.90\n",
      "Total Reward: -62.00\n",
      "Total Reward: -62.10\n",
      "Total Reward: -62.20\n",
      "Total Reward: -62.30\n",
      "Total Reward: -62.40\n",
      "Total Reward: -62.50\n",
      "Total Reward: -62.60\n",
      "Total Reward: -62.70\n",
      "Total Reward: -62.80\n",
      "Total Reward: -62.90\n",
      "Total Reward: -64.00\n",
      "Total Reward: -64.10\n",
      "Total Reward: -64.20\n",
      "Total Reward: -64.30\n",
      "Total Reward: -64.40\n",
      "Total Reward: -64.50\n",
      "Total Reward: -64.60\n",
      "Total Reward: -64.70\n",
      "Total Reward: -64.80\n",
      "Total Reward: -64.90\n",
      "Total Reward: -65.00\n",
      "Total Reward: -65.10\n",
      "Total Reward: -65.20\n",
      "Total Reward: -65.30\n",
      "Total Reward: -65.40\n",
      "Total Reward: -65.50\n",
      "Total Reward: -65.60\n",
      "Total Reward: -65.70\n",
      "Total Reward: -65.80\n",
      "Total Reward: -65.90\n",
      "Total Reward: -66.00\n",
      "Total Reward: -66.10\n",
      "Total Reward: -66.20\n",
      "Total Reward: -66.30\n",
      "Total Reward: -66.40\n",
      "Total Reward: -66.50\n",
      "Total Reward: -66.60\n",
      "Total Reward: -66.70\n",
      "Total Reward: -65.80\n",
      "Total Reward: -65.90\n",
      "Total Reward: -66.00\n",
      "Total Reward: -65.10\n",
      "Total Reward: -65.20\n",
      "Total Reward: -65.30\n",
      "Total Reward: -66.40\n",
      "Total Reward: -66.50\n",
      "Total Reward: -66.60\n",
      "Total Reward: -66.70\n",
      "Total Reward: -66.80\n",
      "Total Reward: -66.90\n",
      "Total Reward: -67.00\n",
      "Total Reward: -67.10\n",
      "Total Reward: -67.20\n",
      "Total Reward: -67.30\n",
      "Total Reward: -67.40\n",
      "Total Reward: -67.50\n",
      "Total Reward: -67.60\n",
      "Total Reward: -67.70\n",
      "Total Reward: -67.80\n",
      "Total Reward: -67.90\n",
      "Total Reward: -67.00\n",
      "Total Reward: -66.10\n",
      "Total Reward: -65.20\n",
      "Total Reward: -65.30\n",
      "Total Reward: -65.40\n",
      "Total Reward: -65.50\n",
      "Total Reward: -66.60\n",
      "Total Reward: -66.70\n",
      "Total Reward: -67.80\n",
      "Total Reward: -67.90\n",
      "Total Reward: -68.00\n",
      "Total Reward: -68.10\n",
      "Total Reward: -67.20\n",
      "Total Reward: -67.30\n",
      "Total Reward: -67.40\n",
      "Total Reward: -67.50\n",
      "Total Reward: -67.60\n",
      "Total Reward: -68.70\n",
      "Total Reward: -69.80\n",
      "Total Reward: -69.90\n",
      "Total Reward: -70.00\n",
      "Total Reward: -70.10\n",
      "Total Reward: -70.20\n",
      "Total Reward: -70.30\n",
      "Total Reward: -70.40\n",
      "Total Reward: -70.50\n",
      "Total Reward: -70.60\n",
      "Total Reward: -70.70\n",
      "Total Reward: -70.80\n",
      "Total Reward: -70.90\n",
      "Total Reward: -71.00\n",
      "Total Reward: -71.10\n",
      "Total Reward: -71.20\n",
      "Total Reward: -71.30\n",
      "Total Reward: -71.40\n",
      "Total Reward: -70.50\n",
      "Total Reward: -70.60\n",
      "Total Reward: -70.70\n",
      "Total Reward: -70.80\n",
      "Total Reward: -70.90\n",
      "Total Reward: -70.00\n",
      "Total Reward: -70.10\n",
      "Total Reward: -71.20\n",
      "Total Reward: -72.30\n",
      "Total Reward: -72.40\n",
      "Total Reward: -72.50\n",
      "Total Reward: -72.60\n",
      "Total Reward: -73.70\n",
      "Total Reward: -74.80\n",
      "Total Reward: -74.90\n",
      "Total Reward: -75.00\n",
      "Total Reward: -75.10\n",
      "Total Reward: -75.20\n",
      "Total Reward: -75.30\n",
      "Total Reward: -75.40\n",
      "Total Reward: -75.50\n",
      "Total Reward: -75.60\n",
      "Total Reward: -75.70\n",
      "Total Reward: -76.80\n",
      "Total Reward: -76.90\n",
      "Total Reward: -77.00\n",
      "Total Reward: -77.10\n",
      "Total Reward: -77.20\n",
      "Total Reward: -77.30\n",
      "Total Reward: -77.40\n",
      "Total Reward: -78.50\n",
      "Total Reward: -78.60\n",
      "Total Reward: -78.70\n",
      "Total Reward: -78.80\n",
      "Total Reward: -77.90\n",
      "Total Reward: -78.00\n",
      "Total Reward: -78.10\n",
      "Total Reward: -78.20\n",
      "Total Reward: -78.30\n",
      "Total Reward: -78.40\n",
      "Total Reward: -79.50\n",
      "Total Reward: -79.60\n",
      "Total Reward: -79.70\n",
      "Total Reward: -79.80\n",
      "Total Reward: -79.90\n",
      "Total Reward: -80.00\n",
      "Total Reward: -80.10\n",
      "Total Reward: -80.20\n",
      "Total Reward: -80.30\n",
      "Total Reward: -80.40\n",
      "Total Reward: -80.50\n",
      "Total Reward: -80.60\n",
      "Total Reward: -80.70\n",
      "Total Reward: -80.80\n",
      "Total Reward: -80.90\n",
      "Total Reward: -81.00\n",
      "Total Reward: -81.10\n",
      "Total Reward: -81.20\n",
      "Total Reward: -81.30\n",
      "Total Reward: -81.40\n",
      "Total Reward: -81.50\n",
      "Total Reward: -81.60\n",
      "Total Reward: -81.70\n",
      "Total Reward: -80.80\n",
      "Total Reward: -80.90\n",
      "Total Reward: -81.00\n",
      "Total Reward: -81.10\n",
      "Total Reward: -80.20\n",
      "Total Reward: -80.30\n",
      "Total Reward: -80.40\n",
      "Total Reward: -80.50\n",
      "Total Reward: -80.60\n",
      "Total Reward: -81.70\n",
      "Total Reward: -81.80\n",
      "Total Reward: -81.90\n",
      "Total Reward: -82.00\n",
      "Total Reward: -82.10\n",
      "Total Reward: -82.20\n",
      "Total Reward: -82.30\n",
      "Total Reward: -82.40\n",
      "Total Reward: -82.50\n",
      "Total Reward: -82.60\n",
      "Total Reward: -82.70\n",
      "Total Reward: -81.80\n",
      "Total Reward: -81.90\n",
      "Total Reward: -82.00\n",
      "Total Reward: -82.10\n",
      "Total Reward: -81.20\n",
      "Total Reward: -80.30\n",
      "Total Reward: -80.40\n",
      "Total Reward: -80.50\n",
      "Total Reward: -80.60\n",
      "Total Reward: -80.70\n",
      "Total Reward: -80.80\n",
      "Total Reward: -80.90\n",
      "Total Reward: -81.00\n",
      "Total Reward: -81.10\n",
      "Total Reward: -81.20\n",
      "Total Reward: -82.30\n",
      "Total Reward: -82.40\n",
      "Total Reward: -82.50\n",
      "Total Reward: -81.60\n",
      "Total Reward: -80.70\n",
      "Total Reward: -79.80\n",
      "Total Reward: -79.90\n",
      "Total Reward: -80.00\n",
      "Total Reward: -80.10\n",
      "Total Reward: -80.20\n",
      "Total Reward: -80.30\n",
      "Total Reward: -80.40\n",
      "Total Reward: -80.50\n",
      "Total Reward: -80.60\n",
      "Total Reward: -80.70\n",
      "Total Reward: -80.80\n",
      "Total Reward: -80.90\n",
      "Total Reward: -81.00\n",
      "Total Reward: -81.10\n",
      "Total Reward: -81.20\n",
      "Total Reward: -81.30\n",
      "Total Reward: -81.40\n",
      "Total Reward: -81.50\n",
      "Total Reward: -81.60\n",
      "Total Reward: -81.70\n",
      "Total Reward: -81.80\n",
      "Total Reward: -81.90\n",
      "Total Reward: -82.00\n",
      "Total Reward: -82.10\n",
      "Total Reward: -82.20\n",
      "Total Reward: -82.30\n",
      "Total Reward: -82.40\n",
      "Total Reward: -82.50\n",
      "Total Reward: -82.60\n",
      "Total Reward: -82.70\n",
      "Total Reward: -82.80\n",
      "Total Reward: -82.90\n",
      "Total Reward: -83.00\n",
      "Total Reward: -83.10\n",
      "Total Reward: -83.20\n",
      "Total Reward: -83.30\n",
      "Total Reward: -83.40\n",
      "Total Reward: -83.50\n",
      "Total Reward: -83.60\n",
      "Total Reward: -83.70\n",
      "Total Reward: -83.80\n",
      "Total Reward: -83.90\n",
      "Total Reward: -84.00\n",
      "Total Reward: -84.10\n",
      "Total Reward: -84.20\n",
      "Total Reward: -84.30\n",
      "Total Reward: -84.40\n",
      "Total Reward: -84.50\n",
      "Total Reward: -84.60\n",
      "Total Reward: -84.70\n",
      "Total Reward: -84.80\n",
      "Total Reward: -85.90\n",
      "Total Reward: -86.00\n",
      "Total Reward: -86.10\n",
      "Total Reward: -86.20\n",
      "Total Reward: -87.30\n",
      "Total Reward: -88.40\n",
      "Total Reward: -88.50\n",
      "Total Reward: -87.60\n",
      "Total Reward: -86.70\n",
      "Total Reward: -86.80\n",
      "Total Reward: -86.90\n",
      "Total Reward: -87.00\n",
      "Total Reward: -87.10\n",
      "Total Reward: -87.20\n",
      "Total Reward: -87.30\n",
      "Total Reward: -87.40\n",
      "Total Reward: -87.50\n",
      "Total Reward: -87.60\n",
      "Total Reward: -87.70\n",
      "Total Reward: -86.80\n",
      "Total Reward: -86.90\n",
      "Total Reward: -87.00\n",
      "Total Reward: -88.10\n",
      "Total Reward: -88.20\n",
      "Total Reward: -88.30\n",
      "Total Reward: -87.40\n",
      "Total Reward: -87.50\n",
      "Total Reward: -87.60\n",
      "Total Reward: -86.70\n",
      "Total Reward: -87.80\n",
      "Total Reward: -87.90\n",
      "Total Reward: -87.00\n",
      "Total Reward: -87.10\n",
      "Total Reward: -87.20\n",
      "Total Reward: -87.30\n",
      "Total Reward: -86.40\n",
      "Total Reward: -86.50\n",
      "Total Reward: -87.60\n",
      "Total Reward: -87.70\n",
      "Total Reward: -87.80\n",
      "Total Reward: -87.90\n",
      "Total Reward: -88.00\n",
      "Total Reward: -88.10\n",
      "Total Reward: -88.20\n",
      "Total Reward: -88.30\n",
      "Total Reward: -88.40\n",
      "Total Reward: -87.50\n",
      "Total Reward: -86.60\n",
      "Total Reward: -86.70\n",
      "Total Reward: -86.80\n",
      "Total Reward: -86.90\n",
      "Total Reward: -87.00\n",
      "Total Reward: -87.10\n",
      "Total Reward: -87.20\n",
      "Total Reward: -87.30\n",
      "Total Reward: -87.40\n",
      "Total Reward: -87.50\n",
      "Total Reward: -87.60\n",
      "Total Reward: -87.70\n",
      "Total Reward: -87.80\n",
      "Total Reward: -87.90\n",
      "Total Reward: -88.00\n",
      "Total Reward: -88.10\n",
      "Total Reward: -88.20\n",
      "Total Reward: -88.30\n",
      "Total Reward: -88.40\n",
      "Total Reward: -88.50\n",
      "Total Reward: -88.60\n",
      "Total Reward: -89.70\n",
      "Total Reward: -89.80\n",
      "Total Reward: -89.90\n",
      "Total Reward: -90.00\n",
      "Total Reward: -90.10\n",
      "Total Reward: -90.20\n",
      "Total Reward: -90.30\n",
      "Total Reward: -89.40\n",
      "Total Reward: -89.50\n",
      "Total Reward: -89.60\n",
      "Total Reward: -89.70\n",
      "Total Reward: -89.80\n",
      "Total Reward: -89.90\n",
      "Total Reward: -90.00\n",
      "Total Reward: -90.10\n",
      "Total Reward: -90.20\n",
      "Total Reward: -90.30\n",
      "Total Reward: -90.40\n",
      "Total Reward: -90.50\n",
      "Total Reward: -90.60\n",
      "Total Reward: -90.70\n",
      "Total Reward: -90.80\n",
      "Total Reward: -91.90\n",
      "Total Reward: -92.00\n",
      "Total Reward: -92.10\n",
      "Total Reward: -92.20\n",
      "Total Reward: -91.30\n",
      "Total Reward: -91.40\n",
      "Total Reward: -91.50\n",
      "Total Reward: -91.60\n",
      "Total Reward: -91.70\n",
      "Total Reward: -91.80\n",
      "Total Reward: -90.90\n",
      "Total Reward: -90.00\n",
      "Total Reward: -89.10\n",
      "Total Reward: -89.20\n",
      "Total Reward: -89.30\n",
      "Total Reward: -89.40\n",
      "Total Reward: -89.50\n",
      "Total Reward: -89.60\n",
      "Total Reward: -89.70\n",
      "Total Reward: -89.80\n",
      "Total Reward: -89.90\n",
      "Total Reward: -90.00\n",
      "Total Reward: -90.10\n",
      "Total Reward: -90.20\n",
      "Total Reward: -90.30\n",
      "Total Reward: -91.40\n",
      "Total Reward: -91.50\n",
      "Total Reward: -91.60\n",
      "Total Reward: -92.70\n",
      "Total Reward: -92.80\n",
      "Total Reward: -92.90\n",
      "Total Reward: -92.00\n",
      "Total Reward: -91.10\n",
      "Total Reward: -91.20\n",
      "Total Reward: -90.30\n",
      "Total Reward: -91.40\n",
      "Total Reward: -91.50\n",
      "Total Reward: -92.60\n",
      "Total Reward: -92.70\n",
      "Total Reward: -91.80\n",
      "Total Reward: -91.90\n",
      "Total Reward: -92.00\n",
      "Total Reward: -92.10\n",
      "Total Reward: -93.20\n",
      "Total Reward: -93.30\n",
      "Total Reward: -93.40\n",
      "Total Reward: -94.50\n",
      "Total Reward: -94.60\n",
      "Total Reward: -94.70\n",
      "Total Reward: -94.80\n",
      "Total Reward: -93.90\n",
      "Total Reward: -94.00\n",
      "Total Reward: -94.10\n",
      "Total Reward: -95.20\n",
      "Total Reward: -95.30\n",
      "Total Reward: -95.40\n",
      "Total Reward: -95.50\n",
      "Total Reward: -95.60\n",
      "Total Reward: -95.70\n",
      "Total Reward: -95.80\n",
      "Total Reward: -95.90\n",
      "Total Reward: -96.00\n",
      "Total Reward: -96.10\n",
      "Total Reward: -96.20\n",
      "Total Reward: -96.30\n",
      "Total Reward: -96.40\n",
      "Total Reward: -96.50\n",
      "Total Reward: -95.60\n",
      "Total Reward: -95.70\n",
      "Total Reward: -94.80\n",
      "Total Reward: -95.90\n",
      "Total Reward: -96.00\n",
      "Total Reward: -96.10\n",
      "Total Reward: -96.20\n",
      "Total Reward: -97.30\n",
      "Total Reward: -97.40\n",
      "Total Reward: -97.50\n",
      "Total Reward: -96.60\n",
      "Total Reward: -96.70\n",
      "Total Reward: -96.80\n",
      "Total Reward: -95.90\n",
      "Total Reward: -95.00\n",
      "Total Reward: -94.10\n",
      "Total Reward: -94.20\n",
      "Total Reward: -94.30\n",
      "Total Reward: -94.40\n",
      "Total Reward: -95.50\n",
      "Total Reward: -95.60\n",
      "Total Reward: -95.70\n",
      "Total Reward: -94.80\n",
      "Total Reward: -94.90\n",
      "Total Reward: -84.90\n",
      "Total Reward: -50.00\n",
      "Total Reward: -50.10\n",
      "Total Reward: -50.20\n",
      "Total Reward: -50.30\n",
      "Total Reward: -50.40\n",
      "Total Reward: -50.50\n",
      "Total Reward: -50.60\n",
      "Total Reward: -50.70\n",
      "Total Reward: -50.80\n",
      "Total Reward: -50.90\n",
      "Total Reward: -51.00\n",
      "Total Reward: -50.10\n",
      "Total Reward: -51.20\n",
      "Total Reward: -51.30\n",
      "Total Reward: -51.40\n",
      "Total Reward: -50.50\n",
      "Total Reward: -51.60\n",
      "Total Reward: -51.70\n",
      "Total Reward: -51.80\n",
      "Total Reward: -51.90\n",
      "Total Reward: -52.00\n",
      "Total Reward: -52.10\n",
      "Total Reward: -52.20\n",
      "Total Reward: -52.30\n",
      "Total Reward: -52.40\n",
      "Total Reward: -52.50\n",
      "Total Reward: -52.60\n",
      "Total Reward: -52.70\n",
      "Total Reward: -52.80\n",
      "Total Reward: -51.90\n",
      "Total Reward: -53.00\n",
      "Total Reward: -53.10\n",
      "Total Reward: -52.20\n",
      "Total Reward: -51.30\n",
      "Total Reward: -51.40\n",
      "Total Reward: -51.50\n",
      "Total Reward: -52.60\n",
      "Total Reward: -53.70\n",
      "Total Reward: -54.80\n",
      "Total Reward: -54.90\n",
      "Total Reward: -55.00\n",
      "Total Reward: -54.10\n",
      "Total Reward: -53.20\n",
      "Total Reward: -52.30\n",
      "Total Reward: -51.40\n",
      "Total Reward: -52.50\n",
      "Total Reward: -52.60\n",
      "Total Reward: -51.70\n",
      "Total Reward: -52.80\n",
      "Total Reward: -53.90\n",
      "Total Reward: -54.00\n",
      "Total Reward: -54.10\n",
      "Total Reward: -53.20\n",
      "Total Reward: -52.30\n",
      "Total Reward: -53.40\n",
      "Total Reward: -53.50\n",
      "Total Reward: -52.60\n",
      "Total Reward: -53.70\n",
      "Total Reward: -54.80\n",
      "Total Reward: -54.90\n",
      "Total Reward: -55.00\n",
      "Total Reward: -55.10\n",
      "Total Reward: -55.20\n",
      "Total Reward: -55.30\n",
      "Total Reward: -56.40\n",
      "Total Reward: -56.50\n",
      "Total Reward: -55.60\n",
      "Total Reward: -56.70\n",
      "Total Reward: -56.80\n",
      "Total Reward: -56.90\n",
      "Total Reward: -57.00\n",
      "Total Reward: -57.10\n",
      "Total Reward: -56.20\n",
      "Total Reward: -56.30\n",
      "Total Reward: -57.40\n",
      "Total Reward: -57.50\n",
      "Total Reward: -58.60\n",
      "Total Reward: -58.70\n",
      "Total Reward: -57.80\n",
      "Total Reward: -57.90\n",
      "Total Reward: -58.00\n",
      "Total Reward: -58.10\n",
      "Total Reward: -58.20\n",
      "Total Reward: -58.30\n",
      "Total Reward: -58.40\n",
      "Total Reward: -58.50\n",
      "Total Reward: -58.60\n",
      "Total Reward: -58.70\n",
      "Total Reward: -58.80\n",
      "Total Reward: -58.90\n",
      "Total Reward: -59.00\n",
      "Total Reward: -59.10\n",
      "Total Reward: -59.20\n",
      "Total Reward: -58.30\n",
      "Total Reward: -59.40\n",
      "Total Reward: -59.50\n",
      "Total Reward: -60.60\n",
      "Total Reward: -60.70\n",
      "Total Reward: -60.80\n",
      "Total Reward: -59.90\n",
      "Total Reward: -59.00\n",
      "Total Reward: -58.10\n",
      "Total Reward: -57.20\n",
      "Total Reward: -58.30\n",
      "Total Reward: -58.40\n",
      "Total Reward: -57.50\n",
      "Total Reward: -58.60\n",
      "Total Reward: -58.70\n",
      "Total Reward: -57.80\n",
      "Total Reward: -58.90\n",
      "Total Reward: -59.00\n",
      "Total Reward: -59.10\n",
      "Total Reward: -59.20\n",
      "Total Reward: -59.30\n",
      "Total Reward: -59.40\n",
      "Total Reward: -59.50\n",
      "Total Reward: -58.60\n",
      "Total Reward: -59.70\n",
      "Total Reward: -59.80\n",
      "Total Reward: -58.90\n",
      "Total Reward: -60.00\n",
      "Total Reward: -60.10\n",
      "Total Reward: -60.20\n",
      "Total Reward: -60.30\n",
      "Total Reward: -59.40\n",
      "Total Reward: -60.50\n",
      "Total Reward: -60.60\n",
      "Total Reward: -60.70\n",
      "Total Reward: -59.80\n",
      "Total Reward: -60.90\n",
      "Total Reward: -61.00\n",
      "Total Reward: -60.10\n",
      "Total Reward: -61.20\n",
      "Total Reward: -62.30\n",
      "Total Reward: -63.40\n",
      "Total Reward: -63.50\n",
      "Total Reward: -63.60\n",
      "Total Reward: -62.70\n",
      "Total Reward: -61.80\n",
      "Total Reward: -60.90\n",
      "Total Reward: -62.00\n",
      "Total Reward: -62.10\n",
      "Total Reward: -61.20\n",
      "Total Reward: -62.30\n",
      "Total Reward: -62.40\n",
      "Total Reward: -61.50\n",
      "Total Reward: -62.60\n",
      "Total Reward: -62.70\n",
      "Total Reward: -62.80\n",
      "Total Reward: -62.90\n",
      "Total Reward: -62.00\n",
      "Total Reward: -63.10\n",
      "Total Reward: -63.20\n",
      "Total Reward: -63.30\n",
      "Total Reward: -63.40\n",
      "Total Reward: -62.50\n",
      "Total Reward: -63.60\n",
      "Total Reward: -63.70\n",
      "Total Reward: -62.80\n",
      "Total Reward: -62.90\n",
      "Total Reward: -52.90\n",
      "Total Reward: -50.00\n",
      "Total Reward: -51.10\n",
      "Total Reward: -51.20\n",
      "Total Reward: -50.30\n",
      "Total Reward: -49.40\n",
      "Total Reward: -49.50\n",
      "Total Reward: -50.60\n",
      "Total Reward: -50.70\n",
      "Total Reward: -51.80\n",
      "Total Reward: -51.90\n",
      "Total Reward: -51.00\n",
      "Total Reward: -50.10\n",
      "Total Reward: -49.20\n",
      "Total Reward: -49.30\n",
      "Total Reward: -49.40\n",
      "Total Reward: -49.50\n",
      "Total Reward: -49.60\n",
      "Total Reward: -49.70\n",
      "Total Reward: -49.80\n",
      "Total Reward: -49.90\n",
      "Total Reward: -50.00\n",
      "Total Reward: -51.10\n",
      "Total Reward: -52.20\n",
      "Total Reward: -52.30\n",
      "Total Reward: -53.40\n",
      "Total Reward: -54.50\n",
      "Total Reward: -55.60\n",
      "Total Reward: -55.70\n",
      "Total Reward: -56.80\n",
      "Total Reward: -56.90\n",
      "Total Reward: -57.00\n",
      "Total Reward: -57.10\n",
      "Total Reward: -57.20\n",
      "Total Reward: -57.30\n",
      "Total Reward: -57.40\n",
      "Total Reward: -57.50\n",
      "Total Reward: -56.60\n",
      "Total Reward: -56.70\n",
      "Total Reward: -56.80\n",
      "Total Reward: -56.90\n",
      "Total Reward: -56.00\n",
      "Total Reward: -55.10\n",
      "Total Reward: -55.20\n",
      "Total Reward: -54.30\n",
      "Total Reward: -54.40\n",
      "Total Reward: -54.50\n",
      "Total Reward: -54.60\n",
      "Total Reward: -55.70\n",
      "Total Reward: -55.80\n",
      "Total Reward: -54.90\n",
      "Total Reward: -54.00\n",
      "Total Reward: -54.10\n",
      "Total Reward: -54.20\n",
      "Total Reward: -55.30\n",
      "Total Reward: -56.40\n",
      "Total Reward: -56.50\n",
      "Total Reward: -56.60\n",
      "Total Reward: -57.70\n",
      "Total Reward: -58.80\n",
      "Total Reward: -59.90\n",
      "Total Reward: -61.00\n",
      "Total Reward: -61.10\n",
      "Total Reward: -60.20\n",
      "Total Reward: -59.30\n",
      "Total Reward: -60.40\n",
      "Total Reward: -61.50\n",
      "Total Reward: -62.60\n",
      "Total Reward: -63.70\n",
      "Total Reward: -63.80\n",
      "Total Reward: -63.90\n",
      "Total Reward: -64.00\n",
      "Total Reward: -64.10\n",
      "Total Reward: -63.20\n",
      "Total Reward: -62.30\n",
      "Total Reward: -61.40\n",
      "Total Reward: -60.50\n",
      "Total Reward: -61.60\n",
      "Total Reward: -62.70\n",
      "Total Reward: -62.80\n",
      "Total Reward: -62.90\n",
      "Total Reward: -63.00\n",
      "Total Reward: -63.10\n",
      "Total Reward: -62.20\n",
      "Total Reward: -62.30\n",
      "Total Reward: -62.40\n",
      "Total Reward: -62.50\n",
      "Total Reward: -62.60\n",
      "Total Reward: -62.70\n",
      "Total Reward: -61.80\n",
      "Total Reward: -61.90\n",
      "Total Reward: -62.00\n",
      "Total Reward: -62.10\n",
      "Total Reward: -63.20\n",
      "Total Reward: -63.30\n",
      "Total Reward: -62.40\n",
      "Total Reward: -62.50\n",
      "Total Reward: -61.60\n",
      "Total Reward: -61.70\n",
      "Total Reward: -61.80\n",
      "Total Reward: -61.90\n",
      "Total Reward: -62.00\n",
      "Total Reward: -62.10\n",
      "Total Reward: -62.20\n",
      "Total Reward: -63.30\n",
      "Total Reward: -64.40\n",
      "Total Reward: -64.50\n",
      "Total Reward: -64.60\n",
      "Total Reward: -64.70\n",
      "Total Reward: -63.80\n",
      "Total Reward: -62.90\n",
      "Total Reward: -63.00\n",
      "Total Reward: -63.10\n",
      "Total Reward: -62.20\n",
      "Total Reward: -62.30\n",
      "Total Reward: -63.40\n",
      "Total Reward: -63.50\n",
      "Total Reward: -63.60\n",
      "Total Reward: -63.70\n",
      "Total Reward: -63.80\n",
      "Total Reward: -63.90\n",
      "Total Reward: -64.00\n",
      "Total Reward: -64.10\n",
      "Total Reward: -65.20\n",
      "Total Reward: -66.30\n",
      "Total Reward: -67.40\n",
      "Total Reward: -68.50\n",
      "Total Reward: -68.60\n",
      "Total Reward: -68.70\n",
      "Total Reward: -67.80\n",
      "Total Reward: -66.90\n",
      "Total Reward: -66.00\n",
      "Total Reward: -65.10\n",
      "Total Reward: -65.20\n",
      "Total Reward: -64.30\n",
      "Total Reward: -64.40\n",
      "Total Reward: -65.50\n",
      "Total Reward: -66.60\n",
      "Total Reward: -66.70\n",
      "Total Reward: -67.80\n",
      "Total Reward: -67.90\n",
      "Total Reward: -69.00\n",
      "Total Reward: -70.10\n",
      "Total Reward: -70.20\n",
      "Total Reward: -71.30\n",
      "Total Reward: -71.40\n",
      "Total Reward: -71.50\n",
      "Total Reward: -71.60\n",
      "Total Reward: -70.70\n",
      "Total Reward: -69.80\n",
      "Total Reward: -68.90\n",
      "Total Reward: -68.00\n",
      "Total Reward: -69.10\n",
      "Total Reward: -70.20\n",
      "Total Reward: -71.30\n",
      "Total Reward: -71.40\n",
      "Total Reward: -71.50\n",
      "Total Reward: -70.60\n",
      "Total Reward: -70.70\n",
      "Total Reward: -70.80\n",
      "Total Reward: -71.90\n",
      "Total Reward: -73.00\n",
      "Total Reward: -73.10\n",
      "Total Reward: -72.20\n",
      "Total Reward: -71.30\n",
      "Total Reward: -70.40\n",
      "Total Reward: -70.50\n",
      "Total Reward: -70.60\n",
      "Total Reward: -71.70\n",
      "Total Reward: -72.80\n",
      "Total Reward: -73.90\n",
      "Total Reward: -74.00\n",
      "Total Reward: -74.10\n",
      "Total Reward: -73.20\n",
      "Total Reward: -72.30\n",
      "Total Reward: -71.40\n",
      "Total Reward: -70.50\n",
      "Total Reward: -69.60\n",
      "Total Reward: -68.70\n",
      "Total Reward: -68.80\n",
      "Total Reward: -67.90\n",
      "Total Reward: -67.00\n",
      "Total Reward: -66.10\n",
      "Total Reward: -65.20\n",
      "Total Reward: -66.30\n",
      "Total Reward: -66.40\n",
      "Total Reward: -66.50\n",
      "Total Reward: -65.60\n",
      "Total Reward: -66.70\n",
      "Total Reward: -67.80\n",
      "Total Reward: -68.90\n",
      "Total Reward: -70.00\n",
      "Total Reward: -70.10\n",
      "Total Reward: -71.20\n",
      "Total Reward: -71.30\n",
      "Total Reward: -70.40\n",
      "Total Reward: -69.50\n",
      "Total Reward: -69.60\n",
      "Total Reward: -68.70\n",
      "Total Reward: -67.80\n",
      "Total Reward: -67.90\n",
      "Total Reward: -68.00\n",
      "Total Reward: -68.10\n",
      "Total Reward: -68.20\n",
      "Total Reward: -68.30\n",
      "Total Reward: -68.40\n",
      "Total Reward: -68.50\n",
      "Total Reward: -68.60\n",
      "Total Reward: -68.70\n",
      "Total Reward: -68.80\n",
      "Total Reward: -67.90\n",
      "Total Reward: -68.00\n",
      "Total Reward: -68.10\n",
      "Total Reward: -69.20\n",
      "Total Reward: -69.30\n",
      "Total Reward: -70.40\n",
      "Total Reward: -70.50\n",
      "Total Reward: -69.60\n",
      "Total Reward: -69.70\n",
      "Total Reward: -69.80\n",
      "Total Reward: -69.90\n",
      "Total Reward: -70.00\n",
      "Total Reward: -70.10\n",
      "Total Reward: -70.20\n",
      "Total Reward: -69.30\n",
      "Total Reward: -69.40\n",
      "Total Reward: -69.50\n",
      "Total Reward: -70.60\n",
      "Total Reward: -70.70\n",
      "Total Reward: -70.80\n",
      "Total Reward: -70.90\n",
      "Total Reward: -70.00\n",
      "Total Reward: -70.10\n",
      "Total Reward: -70.20\n",
      "Total Reward: -71.30\n",
      "Total Reward: -71.40\n",
      "Total Reward: -71.50\n",
      "Total Reward: -70.60\n",
      "Total Reward: -70.70\n",
      "Total Reward: -70.80\n",
      "Total Reward: -70.90\n",
      "Total Reward: -71.00\n",
      "Total Reward: -71.10\n",
      "Total Reward: -71.20\n",
      "Total Reward: -71.30\n",
      "Total Reward: -71.40\n",
      "Total Reward: -71.50\n",
      "Total Reward: -71.60\n",
      "Total Reward: -71.70\n",
      "Total Reward: -71.80\n",
      "Total Reward: -72.90\n",
      "Total Reward: -74.00\n",
      "Total Reward: -75.10\n",
      "Total Reward: -75.20\n",
      "Total Reward: -75.30\n",
      "Total Reward: -75.40\n",
      "Total Reward: -76.50\n",
      "Total Reward: -76.60\n",
      "Total Reward: -76.70\n",
      "Total Reward: -76.80\n",
      "Total Reward: -76.90\n",
      "Total Reward: -77.00\n",
      "Total Reward: -77.10\n",
      "Total Reward: -77.20\n",
      "Total Reward: -77.30\n",
      "Total Reward: -77.40\n",
      "Total Reward: -77.50\n",
      "Total Reward: -77.60\n",
      "Total Reward: -77.70\n",
      "Total Reward: -77.80\n",
      "Total Reward: -77.90\n",
      "Total Reward: -78.00\n",
      "Total Reward: -78.10\n",
      "Total Reward: -78.20\n",
      "Total Reward: -78.30\n",
      "Total Reward: -78.40\n",
      "Total Reward: -78.50\n",
      "Total Reward: -78.60\n",
      "Total Reward: -78.70\n",
      "Total Reward: -78.80\n",
      "Total Reward: -78.90\n",
      "Total Reward: -79.00\n",
      "Total Reward: -79.10\n",
      "Total Reward: -79.20\n",
      "Total Reward: -79.30\n",
      "Total Reward: -79.40\n",
      "Total Reward: -78.50\n",
      "Total Reward: -78.60\n",
      "Total Reward: -78.70\n",
      "Total Reward: -78.80\n",
      "Total Reward: -79.90\n",
      "Total Reward: -81.00\n",
      "Total Reward: -81.10\n",
      "Total Reward: -82.20\n",
      "Total Reward: -83.30\n",
      "Total Reward: -84.40\n",
      "Total Reward: -84.50\n",
      "Total Reward: -83.60\n",
      "Total Reward: -83.70\n",
      "Total Reward: -83.80\n",
      "Total Reward: -83.90\n",
      "Total Reward: -85.00\n",
      "Total Reward: -85.10\n",
      "Total Reward: -86.20\n",
      "Total Reward: -86.30\n",
      "Total Reward: -86.40\n",
      "Total Reward: -87.50\n",
      "Total Reward: -87.60\n",
      "Total Reward: -88.70\n",
      "Total Reward: -88.80\n",
      "Total Reward: -87.90\n",
      "Total Reward: -88.00\n",
      "Total Reward: -88.10\n",
      "Total Reward: -88.20\n",
      "Total Reward: -88.30\n",
      "Total Reward: -88.40\n",
      "Total Reward: -88.50\n",
      "Total Reward: -88.60\n",
      "Total Reward: -87.70\n",
      "Total Reward: -86.80\n",
      "Total Reward: -85.90\n",
      "Total Reward: -85.00\n",
      "Total Reward: -85.10\n",
      "Total Reward: -86.20\n",
      "Total Reward: -86.30\n",
      "Total Reward: -86.40\n",
      "Total Reward: -85.50\n",
      "Total Reward: -85.60\n",
      "Total Reward: -86.70\n",
      "Total Reward: -87.80\n",
      "Total Reward: -87.90\n",
      "Total Reward: -87.00\n",
      "Total Reward: -86.10\n",
      "Total Reward: -86.20\n",
      "Total Reward: -86.30\n",
      "Total Reward: -86.40\n",
      "Total Reward: -86.50\n",
      "Total Reward: -86.60\n",
      "Total Reward: -86.70\n",
      "Total Reward: -87.80\n",
      "Total Reward: -88.90\n",
      "Total Reward: -90.00\n",
      "Total Reward: -91.10\n",
      "Total Reward: -91.20\n",
      "Total Reward: -91.30\n",
      "Total Reward: -91.40\n",
      "Total Reward: -91.50\n",
      "Total Reward: -91.60\n",
      "Total Reward: -91.70\n",
      "Total Reward: -91.80\n",
      "Total Reward: -91.90\n",
      "Total Reward: -92.00\n",
      "Total Reward: -92.10\n",
      "Total Reward: -93.20\n",
      "Total Reward: -93.30\n",
      "Total Reward: -93.40\n",
      "Total Reward: -93.50\n",
      "Total Reward: -93.60\n",
      "Total Reward: -93.70\n",
      "Total Reward: -93.80\n",
      "Total Reward: -94.90\n",
      "Total Reward: -95.00\n",
      "Total Reward: -95.10\n",
      "Total Reward: -95.20\n",
      "Total Reward: -95.30\n",
      "Total Reward: -95.40\n",
      "Total Reward: -95.50\n",
      "Total Reward: -95.60\n",
      "Total Reward: -95.70\n",
      "Total Reward: -95.80\n",
      "Total Reward: -95.90\n",
      "Total Reward: -96.00\n",
      "Total Reward: -95.10\n",
      "Total Reward: -94.20\n",
      "Total Reward: -93.30\n",
      "Total Reward: -92.40\n",
      "Total Reward: -91.50\n",
      "Total Reward: -91.60\n",
      "Total Reward: -91.70\n",
      "Total Reward: -92.80\n",
      "Total Reward: -93.90\n",
      "Total Reward: -95.00\n",
      "Total Reward: -95.10\n",
      "Total Reward: -95.20\n",
      "Total Reward: -95.30\n",
      "Total Reward: -95.40\n",
      "Total Reward: -96.50\n",
      "Total Reward: -96.60\n",
      "Total Reward: -97.70\n",
      "Total Reward: -98.80\n",
      "Total Reward: -98.90\n",
      "Total Reward: -99.00\n",
      "Total Reward: -99.10\n",
      "Total Reward: -99.20\n",
      "Total Reward: -99.30\n",
      "Total Reward: -99.40\n",
      "Total Reward: -98.50\n",
      "Total Reward: -97.60\n",
      "Total Reward: -97.70\n",
      "Total Reward: -97.80\n",
      "Total Reward: -98.90\n",
      "Total Reward: -99.00\n",
      "Total Reward: -100.10\n",
      "Total Reward: -100.20\n",
      "Total Reward: -99.30\n",
      "Total Reward: -99.40\n",
      "Total Reward: -99.50\n",
      "Total Reward: -99.60\n",
      "Total Reward: -99.70\n",
      "Total Reward: -99.80\n",
      "Total Reward: -99.90\n",
      "Total Reward: -100.00\n",
      "Total Reward: -100.10\n",
      "Total Reward: -100.20\n",
      "Total Reward: -100.30\n",
      "Total Reward: -100.40\n",
      "Total Reward: -99.50\n",
      "Total Reward: -98.60\n",
      "Total Reward: -98.70\n",
      "Total Reward: -98.80\n",
      "Total Reward: -98.90\n",
      "Total Reward: -99.00\n",
      "Total Reward: -99.10\n",
      "Total Reward: -99.20\n",
      "Total Reward: -99.30\n",
      "Total Reward: -99.40\n",
      "Total Reward: -99.50\n",
      "Total Reward: -99.60\n",
      "Total Reward: -99.70\n",
      "Total Reward: -100.80\n",
      "Total Reward: -101.90\n",
      "Total Reward: -103.00\n",
      "Total Reward: -103.10\n",
      "Total Reward: -102.20\n",
      "Total Reward: -101.30\n",
      "Total Reward: -101.40\n",
      "Total Reward: -101.50\n",
      "Total Reward: -101.60\n",
      "Total Reward: -100.70\n",
      "Total Reward: -100.80\n",
      "Total Reward: -101.90\n",
      "Total Reward: -103.00\n",
      "Total Reward: -103.10\n",
      "Total Reward: -103.20\n",
      "Total Reward: -103.30\n",
      "Total Reward: -103.40\n",
      "Total Reward: -103.50\n",
      "Total Reward: -103.60\n",
      "Total Reward: -102.70\n",
      "Total Reward: -101.80\n",
      "Total Reward: -100.90\n",
      "Total Reward: -100.00\n",
      "Total Reward: -99.10\n",
      "Total Reward: -98.20\n",
      "Total Reward: -99.30\n",
      "Total Reward: -100.40\n",
      "Total Reward: -100.50\n",
      "Total Reward: -99.60\n",
      "Total Reward: -99.70\n",
      "Total Reward: -99.80\n",
      "Total Reward: -98.90\n",
      "Total Reward: -98.00\n",
      "Total Reward: -97.10\n",
      "Total Reward: -96.20\n",
      "Total Reward: -95.30\n",
      "Total Reward: -95.40\n",
      "Total Reward: -94.50\n",
      "Total Reward: -93.60\n",
      "Total Reward: -93.70\n",
      "Total Reward: -94.80\n",
      "Total Reward: -94.90\n",
      "Total Reward: -96.00\n",
      "Total Reward: -97.10\n",
      "Total Reward: -98.20\n",
      "Total Reward: -98.30\n",
      "Total Reward: -98.40\n",
      "Total Reward: -97.50\n",
      "Total Reward: -96.60\n",
      "Total Reward: -96.70\n",
      "Total Reward: -97.80\n",
      "Total Reward: -97.90\n",
      "Total Reward: -98.00\n",
      "Total Reward: -98.10\n",
      "Total Reward: -97.20\n",
      "Total Reward: -97.30\n",
      "Total Reward: -97.40\n",
      "Total Reward: -97.50\n",
      "Total Reward: -97.60\n",
      "Total Reward: -97.70\n",
      "Total Reward: -98.80\n",
      "Total Reward: -98.90\n",
      "Total Reward: -99.00\n",
      "Total Reward: -99.10\n",
      "Total Reward: -99.20\n",
      "Total Reward: -100.30\n",
      "Total Reward: -101.40\n",
      "Total Reward: -102.50\n",
      "Total Reward: -102.60\n",
      "Total Reward: -102.70\n",
      "Total Reward: -102.80\n",
      "Total Reward: -102.90\n",
      "Total Reward: -103.00\n",
      "Total Reward: -103.10\n",
      "Total Reward: -103.20\n",
      "Total Reward: -103.30\n",
      "Total Reward: -103.40\n",
      "Total Reward: -103.50\n",
      "Total Reward: -103.60\n",
      "Total Reward: -103.70\n",
      "Total Reward: -103.80\n",
      "Total Reward: -103.90\n",
      "Total Reward: -104.00\n",
      "Total Reward: -104.10\n",
      "Total Reward: -104.20\n",
      "Total Reward: -104.30\n",
      "Total Reward: -104.40\n",
      "Total Reward: -104.50\n",
      "Total Reward: -104.60\n",
      "Total Reward: -104.70\n",
      "Total Reward: -104.80\n",
      "Total Reward: -104.90\n",
      "Total Reward: -105.00\n",
      "Total Reward: -105.10\n",
      "Total Reward: -105.20\n",
      "Total Reward: -104.30\n",
      "Total Reward: -104.40\n",
      "Total Reward: -103.50\n",
      "Total Reward: -102.60\n",
      "Total Reward: -101.70\n",
      "Total Reward: -101.80\n",
      "Total Reward: -100.90\n",
      "Total Reward: -101.00\n",
      "Total Reward: -102.10\n",
      "Total Reward: -103.20\n",
      "Total Reward: -104.30\n",
      "Total Reward: -105.40\n",
      "Total Reward: -106.50\n",
      "Total Reward: -106.60\n",
      "Total Reward: -106.70\n",
      "Total Reward: -105.80\n",
      "Total Reward: -104.90\n",
      "Total Reward: -104.00\n",
      "Total Reward: -103.10\n",
      "Total Reward: -103.20\n",
      "Total Reward: -102.30\n",
      "Total Reward: -102.40\n",
      "Total Reward: -102.50\n",
      "Total Reward: -103.60\n",
      "Total Reward: -103.70\n",
      "Total Reward: -104.80\n",
      "Total Reward: -105.90\n",
      "Total Reward: -107.00\n",
      "Total Reward: -108.10\n",
      "Total Reward: -108.20\n",
      "Total Reward: -109.30\n",
      "Total Reward: -110.40\n",
      "Total Reward: -110.50\n",
      "Total Reward: -110.60\n",
      "Total Reward: -110.70\n",
      "Total Reward: -110.80\n",
      "Total Reward: -110.90\n",
      "Total Reward: -111.00\n",
      "Total Reward: -111.10\n",
      "Total Reward: -111.20\n",
      "Total Reward: -111.30\n",
      "Total Reward: -110.40\n",
      "Total Reward: -109.50\n",
      "Total Reward: -109.60\n",
      "Total Reward: -109.70\n",
      "Total Reward: -110.80\n",
      "Total Reward: -110.90\n",
      "Total Reward: -111.00\n",
      "Total Reward: -110.10\n",
      "Total Reward: -109.20\n",
      "Total Reward: -108.30\n",
      "Total Reward: -108.40\n",
      "Total Reward: -108.50\n",
      "Total Reward: -108.60\n",
      "Total Reward: -108.70\n",
      "Total Reward: -108.80\n",
      "Total Reward: -108.90\n",
      "Total Reward: -110.00\n",
      "Total Reward: -111.10\n",
      "Total Reward: -112.20\n",
      "Total Reward: -113.30\n",
      "Total Reward: -113.40\n",
      "Total Reward: -113.50\n",
      "Total Reward: -113.60\n",
      "Total Reward: -113.70\n",
      "Total Reward: -113.80\n",
      "Total Reward: -112.90\n",
      "Total Reward: -113.00\n",
      "Total Reward: -113.10\n",
      "Total Reward: -114.20\n",
      "Total Reward: -114.30\n",
      "Total Reward: -114.40\n",
      "Total Reward: -113.50\n",
      "Total Reward: -113.60\n",
      "Total Reward: -113.70\n",
      "Total Reward: -113.80\n",
      "Total Reward: -113.90\n",
      "Total Reward: -113.00\n",
      "Total Reward: -113.10\n",
      "Total Reward: -114.20\n",
      "Total Reward: -115.30\n",
      "Total Reward: -115.40\n",
      "Total Reward: -114.50\n",
      "Total Reward: -113.60\n",
      "Total Reward: -114.70\n",
      "Total Reward: -115.80\n",
      "Total Reward: -116.90\n",
      "Total Reward: -118.00\n",
      "Total Reward: -119.10\n",
      "Total Reward: -119.20\n",
      "Total Reward: -119.30\n",
      "Total Reward: -119.40\n",
      "Total Reward: -118.50\n",
      "Total Reward: -117.60\n",
      "Total Reward: -117.70\n",
      "Total Reward: -117.80\n",
      "Total Reward: -117.90\n",
      "Total Reward: -117.00\n",
      "Total Reward: -116.10\n",
      "Total Reward: -115.20\n",
      "Total Reward: -115.30\n",
      "Total Reward: -115.40\n",
      "Total Reward: -115.50\n",
      "Total Reward: -115.60\n",
      "Total Reward: -115.70\n",
      "Total Reward: -115.80\n",
      "Total Reward: -115.90\n",
      "Total Reward: -116.00\n",
      "Total Reward: -117.10\n",
      "Total Reward: -117.20\n",
      "Total Reward: -118.30\n",
      "Total Reward: -118.40\n",
      "Total Reward: -119.50\n",
      "Total Reward: -119.60\n",
      "Total Reward: -118.70\n",
      "Total Reward: -117.80\n",
      "Total Reward: -116.90\n",
      "Total Reward: -116.00\n",
      "Total Reward: -115.10\n",
      "Total Reward: -114.20\n",
      "Total Reward: -113.30\n",
      "Total Reward: -113.40\n",
      "Total Reward: -113.50\n",
      "Total Reward: -113.60\n",
      "Total Reward: -113.70\n",
      "Total Reward: -113.80\n",
      "Total Reward: -113.90\n",
      "Total Reward: -115.00\n",
      "Total Reward: -116.10\n",
      "Total Reward: -117.20\n",
      "Total Reward: -118.30\n",
      "Total Reward: -119.40\n",
      "Total Reward: -120.50\n",
      "Total Reward: -121.60\n",
      "Total Reward: -121.70\n",
      "Total Reward: -121.80\n",
      "Total Reward: -121.90\n",
      "Total Reward: -123.00\n",
      "Total Reward: -123.10\n",
      "Total Reward: -124.20\n",
      "Total Reward: -124.30\n",
      "Total Reward: -123.40\n",
      "Total Reward: -122.50\n",
      "Total Reward: -121.60\n",
      "Total Reward: -120.70\n",
      "Total Reward: -119.80\n",
      "Total Reward: -119.90\n",
      "Total Reward: -120.00\n",
      "Total Reward: -121.10\n",
      "Total Reward: -122.20\n",
      "Total Reward: -122.30\n",
      "Total Reward: -123.40\n",
      "Total Reward: -124.50\n",
      "Total Reward: -124.60\n",
      "Total Reward: -124.70\n",
      "Total Reward: -124.80\n",
      "Total Reward: -125.90\n",
      "Total Reward: -127.00\n",
      "Total Reward: -127.10\n",
      "Total Reward: -126.20\n",
      "Total Reward: -126.30\n",
      "Total Reward: -126.40\n",
      "Total Reward: -125.50\n",
      "Total Reward: -125.60\n",
      "Total Reward: -125.70\n",
      "Total Reward: -125.80\n",
      "Total Reward: -125.90\n",
      "Total Reward: -126.00\n",
      "Total Reward: -126.10\n",
      "Total Reward: -125.20\n",
      "Total Reward: -124.30\n",
      "Total Reward: -123.40\n",
      "Total Reward: -122.50\n",
      "Total Reward: -122.60\n",
      "Total Reward: -121.70\n",
      "Total Reward: -120.80\n",
      "Total Reward: -120.90\n",
      "Total Reward: -121.00\n",
      "Total Reward: -121.10\n",
      "Total Reward: -121.20\n",
      "Total Reward: -121.30\n",
      "Total Reward: -121.40\n",
      "Total Reward: -121.50\n",
      "Total Reward: -121.60\n",
      "Total Reward: -121.70\n",
      "Total Reward: -121.80\n",
      "Total Reward: -121.90\n",
      "Total Reward: -122.00\n",
      "Total Reward: -122.10\n",
      "Total Reward: -122.20\n",
      "Total Reward: -122.30\n",
      "Total Reward: -122.40\n",
      "Total Reward: -122.50\n",
      "Total Reward: -122.60\n",
      "Total Reward: -122.70\n",
      "Total Reward: -122.80\n",
      "Total Reward: -121.90\n",
      "Total Reward: -121.00\n",
      "Total Reward: -121.10\n",
      "Total Reward: -122.20\n",
      "Total Reward: -123.30\n",
      "Total Reward: -123.40\n",
      "Total Reward: -124.50\n",
      "Total Reward: -125.60\n",
      "Total Reward: -126.70\n",
      "Total Reward: -126.80\n",
      "Total Reward: -126.90\n",
      "Total Reward: -127.00\n",
      "Total Reward: -127.10\n",
      "Total Reward: -127.20\n",
      "Total Reward: -127.30\n",
      "Total Reward: -128.40\n",
      "Total Reward: -129.50\n",
      "Total Reward: -130.60\n",
      "Total Reward: -130.70\n",
      "Total Reward: -130.80\n",
      "Total Reward: -129.90\n",
      "Total Reward: -129.00\n",
      "Total Reward: -128.10\n",
      "Total Reward: -128.20\n",
      "Total Reward: -128.30\n",
      "Total Reward: -128.40\n",
      "Total Reward: -128.50\n",
      "Total Reward: -127.60\n",
      "Total Reward: -126.70\n",
      "Total Reward: -125.80\n",
      "Total Reward: -125.90\n",
      "Total Reward: -126.00\n",
      "Total Reward: -126.10\n",
      "Total Reward: -125.20\n",
      "Total Reward: -124.30\n",
      "Total Reward: -123.40\n",
      "Total Reward: -122.50\n",
      "Total Reward: -122.60\n",
      "Total Reward: -121.70\n",
      "Total Reward: -121.80\n",
      "Total Reward: -121.90\n",
      "Total Reward: -122.00\n",
      "Total Reward: -122.10\n",
      "Total Reward: -122.20\n",
      "Total Reward: -122.30\n",
      "Total Reward: -122.40\n",
      "Total Reward: -123.50\n",
      "Total Reward: -123.60\n",
      "Total Reward: -122.70\n",
      "Total Reward: -122.80\n",
      "Total Reward: -122.90\n",
      "Total Reward: -123.00\n",
      "Total Reward: -124.10\n",
      "Total Reward: -125.20\n",
      "Total Reward: -126.30\n",
      "Total Reward: -127.40\n",
      "Total Reward: -127.50\n",
      "Total Reward: -127.60\n",
      "Total Reward: -128.70\n",
      "Total Reward: -129.80\n",
      "Total Reward: -130.90\n",
      "Total Reward: -131.00\n",
      "Total Reward: -130.10\n",
      "Total Reward: -130.20\n",
      "Total Reward: -130.30\n",
      "Total Reward: -130.40\n",
      "Total Reward: -130.50\n",
      "Total Reward: -130.60\n",
      "Total Reward: -130.70\n",
      "Total Reward: -130.80\n",
      "Total Reward: -130.90\n",
      "Total Reward: -131.00\n",
      "Total Reward: -130.10\n",
      "Total Reward: -130.20\n",
      "Total Reward: -129.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  10%|         | 1/10 [01:35<14:19, 95.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reward: -128.40\n",
      "Total Reward: -128.50\n",
      "Total Reward: -129.60\n",
      "Total Reward: -130.70\n",
      "Total Reward: -130.80\n",
      "Total Reward: -131.90\n",
      "Total Reward: -133.00\n",
      "Total Reward: -133.10\n",
      "Total Reward: -133.20\n",
      "Total Reward: -133.30\n",
      "Total Reward: -132.40\n",
      "Total Reward: -131.50\n",
      "Total Reward: -131.60\n",
      "Total Reward: -131.70\n",
      "Total Reward: -132.80\n",
      "Total Reward: -133.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[1;32m<timed exec>:1\u001B[0m\n",
      "Cell \u001B[1;32mIn[40], line 57\u001B[0m, in \u001B[0;36mrun_upside_down\u001B[1;34m(max_episodes)\u001B[0m\n\u001B[0;32m     54\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_episodes_per_iter):\n\u001B[0;32m     55\u001B[0m     \u001B[38;5;66;03m# Sample exploratory commands based on buffer\u001B[39;00m\n\u001B[0;32m     56\u001B[0m     new_desired_reward, new_desired_horizon \u001B[38;5;241m=\u001B[39m sampling_exploration()\n\u001B[1;32m---> 57\u001B[0m     generated_episode \u001B[38;5;241m=\u001B[39m \u001B[43mgenerate_episode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnew_desired_reward\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnew_desired_horizon\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     58\u001B[0m     buffer\u001B[38;5;241m.\u001B[39madd_sample(generated_episode[\u001B[38;5;241m0\u001B[39m], generated_episode[\u001B[38;5;241m1\u001B[39m], generated_episode[\u001B[38;5;241m2\u001B[39m])\n\u001B[0;32m     60\u001B[0m new_desired_reward, new_desired_horizon \u001B[38;5;241m=\u001B[39m sampling_exploration()\n",
      "Cell \u001B[1;32mIn[40], line 13\u001B[0m, in \u001B[0;36mgenerate_episode\u001B[1;34m(desired_return, desired_time_horizon)\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m     12\u001B[0m     state_tensor \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mfrom_numpy(state)\u001B[38;5;241m.\u001B[39mfloat()\u001B[38;5;241m.\u001B[39mpermute(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mto(device) \n\u001B[1;32m---> 13\u001B[0m     action \u001B[38;5;241m=\u001B[39m \u001B[43mbf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate_tensor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munsqueeze\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdesired_return\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdesired_time_horizon\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mitem()\n\u001B[0;32m     14\u001B[0m     next_obs, reward, done, truncated, _ \u001B[38;5;241m=\u001B[39m env\u001B[38;5;241m.\u001B[39mstep(action)\n\u001B[0;32m     15\u001B[0m     next_state \u001B[38;5;241m=\u001B[39m next_obs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimage\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "Cell \u001B[1;32mIn[31], line 57\u001B[0m, in \u001B[0;36mBF.action\u001B[1;34m(self, state, desire, horizon)\u001B[0m\n\u001B[0;32m     55\u001B[0m action_prob \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward(state, command)\n\u001B[0;32m     56\u001B[0m probs \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msoftmax(action_prob, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m---> 57\u001B[0m m \u001B[38;5;241m=\u001B[39m \u001B[43mCategorical\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprobs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     58\u001B[0m action \u001B[38;5;241m=\u001B[39m m\u001B[38;5;241m.\u001B[39msample()\n\u001B[0;32m     59\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m action\n",
      "File \u001B[1;32mC:\\python\\venv\\Lib\\site-packages\\torch\\distributions\\categorical.py:70\u001B[0m, in \u001B[0;36mCategorical.__init__\u001B[1;34m(self, probs, logits, validate_args)\u001B[0m\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_events \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_param\u001B[38;5;241m.\u001B[39msize()[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m     67\u001B[0m batch_shape \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_param\u001B[38;5;241m.\u001B[39msize()[:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_param\u001B[38;5;241m.\u001B[39mndimension() \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mSize()\n\u001B[0;32m     69\u001B[0m )\n\u001B[1;32m---> 70\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mbatch_shape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidate_args\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidate_args\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\python\\venv\\Lib\\site-packages\\torch\\distributions\\distribution.py:67\u001B[0m, in \u001B[0;36mDistribution.__init__\u001B[1;34m(self, batch_shape, event_shape, validate_args)\u001B[0m\n\u001B[0;32m     65\u001B[0m         value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, param)\n\u001B[0;32m     66\u001B[0m         valid \u001B[38;5;241m=\u001B[39m constraint\u001B[38;5;241m.\u001B[39mcheck(value)\n\u001B[1;32m---> 67\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m valid\u001B[38;5;241m.\u001B[39mall():\n\u001B[0;32m     68\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m     69\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected parameter \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mparam\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     70\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(value)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m of shape \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtuple\u001B[39m(value\u001B[38;5;241m.\u001B[39mshape)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m) \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     73\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbut found invalid values:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mvalue\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     74\u001B[0m             )\n\u001B[0;32m     75\u001B[0m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m()\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rewards, average, d, h, loss = run_upside_down(max_episodes=10)\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.subplot(2,2,1)\n",
    "plt.title(\"Rewards\")\n",
    "plt.plot(rewards, label=\"rewards\")\n",
    "plt.plot(average, label=\"average100\")\n",
    "plt.legend()\n",
    "plt.subplot(2,2,2)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(loss)\n",
    "plt.subplot(2,2,3)\n",
    "plt.title(\"desired Rewards\")\n",
    "plt.plot(d)\n",
    "plt.subplot(2,2,4)\n",
    "plt.title(\"desired Horizon\")\n",
    "plt.plot(h)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T13:22:41.935866Z",
     "start_time": "2024-07-09T13:21:06.304705Z"
    }
   },
   "id": "f4a5b6532f56baa6",
   "execution_count": 42
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fb9e3349f429fb95"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# SAVE MODEL\n",
    "name = \"model_FourRoom_Mannul.pth\"\n",
    "torch.save(bf.state_dict(), name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T13:22:41.994986Z",
     "start_time": "2024-07-09T13:22:41.936862Z"
    }
   },
   "id": "501c0be0208fc452",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[ 0.0921, -0.0920, -0.0440],\n",
      "          [ 0.0816, -0.1901,  0.1075],\n",
      "          [-0.0472,  0.0909,  0.0198]],\n",
      "\n",
      "         [[-0.0322,  0.0461,  0.0024],\n",
      "          [ 0.0601, -0.0844, -0.0231],\n",
      "          [-0.0269,  0.0189, -0.0095]],\n",
      "\n",
      "         [[ 0.1599,  0.0527, -0.0787],\n",
      "          [-0.1262, -0.0416, -0.0921],\n",
      "          [-0.0710,  0.0005,  0.1064]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1149, -0.1744,  0.1452],\n",
      "          [ 0.0602,  0.1879,  0.1404],\n",
      "          [-0.1706, -0.1818, -0.0859]],\n",
      "\n",
      "         [[ 0.1836, -0.0176,  0.0999],\n",
      "          [-0.0712,  0.2066, -0.0609],\n",
      "          [ 0.1640,  0.0228, -0.0786]],\n",
      "\n",
      "         [[ 0.1099, -0.0887,  0.0752],\n",
      "          [-0.0430, -0.0071, -0.1664],\n",
      "          [-0.0779,  0.1188, -0.0285]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1738,  0.1437, -0.0113],\n",
      "          [-0.1356,  0.1194,  0.0791],\n",
      "          [-0.1345,  0.1261,  0.1443]],\n",
      "\n",
      "         [[ 0.1491, -0.1307, -0.0477],\n",
      "          [-0.0240,  0.0054, -0.1584],\n",
      "          [-0.1570,  0.0814, -0.0534]],\n",
      "\n",
      "         [[ 0.0772, -0.0071,  0.0497],\n",
      "          [ 0.0290,  0.0527,  0.0828],\n",
      "          [-0.1906,  0.0785, -0.1428]]],\n",
      "\n",
      "\n",
      "        [[[-0.1582, -0.0009, -0.0484],\n",
      "          [ 0.1011, -0.1239, -0.1879],\n",
      "          [ 0.1227, -0.0464,  0.0852]],\n",
      "\n",
      "         [[ 0.0553, -0.1569,  0.0231],\n",
      "          [ 0.0410, -0.1414, -0.1083],\n",
      "          [ 0.0518,  0.0115, -0.1120]],\n",
      "\n",
      "         [[-0.0716,  0.1636, -0.0512],\n",
      "          [ 0.0945,  0.0708, -0.1413],\n",
      "          [-0.1810,  0.1671, -0.0126]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1232,  0.0325,  0.0508],\n",
      "          [ 0.1372,  0.1766, -0.1395],\n",
      "          [ 0.0150,  0.1347,  0.1255]],\n",
      "\n",
      "         [[ 0.1049, -0.1523, -0.1507],\n",
      "          [-0.1338,  0.0084,  0.1768],\n",
      "          [-0.1426,  0.0818, -0.1269]],\n",
      "\n",
      "         [[-0.1934, -0.0507,  0.1002],\n",
      "          [ 0.1658, -0.1299,  0.0303],\n",
      "          [ 0.1519,  0.1151,  0.1065]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1184,  0.1031,  0.0319],\n",
      "          [-0.1656, -0.1950, -0.1040],\n",
      "          [-0.0702, -0.1664,  0.0544]],\n",
      "\n",
      "         [[ 0.0511, -0.0561,  0.0720],\n",
      "          [ 0.0451,  0.0982,  0.1260],\n",
      "          [-0.0932,  0.1627, -0.0256]],\n",
      "\n",
      "         [[-0.0240, -0.1991, -0.1408],\n",
      "          [-0.1467, -0.1159,  0.1210],\n",
      "          [-0.1107, -0.1923,  0.0580]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0798,  0.1407, -0.0816],\n",
      "          [ 0.0311, -0.0885, -0.0494],\n",
      "          [-0.1583, -0.1212, -0.0596]],\n",
      "\n",
      "         [[ 0.0976,  0.0375,  0.0530],\n",
      "          [ 0.1767,  0.1612,  0.1146],\n",
      "          [-0.0158, -0.1758,  0.1324]],\n",
      "\n",
      "         [[-0.0294, -0.0015, -0.1494],\n",
      "          [-0.0489, -0.1429,  0.1705],\n",
      "          [-0.1707, -0.1838, -0.0073]]],\n",
      "\n",
      "\n",
      "        [[[-0.1172,  0.0546, -0.0847],\n",
      "          [-0.1012,  0.0007,  0.1298],\n",
      "          [-0.1494,  0.0770,  0.1114]],\n",
      "\n",
      "         [[ 0.1729, -0.1509,  0.0316],\n",
      "          [-0.1552,  0.1508, -0.0865],\n",
      "          [ 0.1059, -0.0053, -0.0246]],\n",
      "\n",
      "         [[-0.0201,  0.0164,  0.0776],\n",
      "          [ 0.0167,  0.0442, -0.1862],\n",
      "          [ 0.1255,  0.1530,  0.1456]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1195, -0.1467, -0.0587],\n",
      "          [ 0.1514, -0.1527,  0.1827],\n",
      "          [-0.1812, -0.1463,  0.0961]],\n",
      "\n",
      "         [[-0.1656, -0.0739,  0.1262],\n",
      "          [ 0.1348,  0.1636, -0.0465],\n",
      "          [-0.1684,  0.1707, -0.0481]],\n",
      "\n",
      "         [[-0.0982,  0.0380, -0.1333],\n",
      "          [ 0.1097,  0.1135, -0.1528],\n",
      "          [-0.1846, -0.0268,  0.0807]]],\n",
      "\n",
      "\n",
      "        [[[-0.0078, -0.0996,  0.0064],\n",
      "          [-0.1705, -0.1267, -0.1227],\n",
      "          [ 0.1574,  0.1674, -0.0711]],\n",
      "\n",
      "         [[ 0.0105,  0.0866,  0.0203],\n",
      "          [-0.0791,  0.1272,  0.1315],\n",
      "          [-0.0019, -0.0162,  0.1817]],\n",
      "\n",
      "         [[ 0.1692, -0.1106,  0.1900],\n",
      "          [ 0.0647, -0.1118,  0.1229],\n",
      "          [-0.1415,  0.1788, -0.1184]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0625,  0.0685,  0.0567],\n",
      "          [ 0.1579, -0.0814, -0.0798],\n",
      "          [-0.1666, -0.0036, -0.0825]],\n",
      "\n",
      "         [[ 0.0256, -0.0216,  0.0841],\n",
      "          [ 0.1822,  0.0732, -0.0467],\n",
      "          [-0.0754, -0.1477,  0.1814]],\n",
      "\n",
      "         [[-0.0163,  0.0604,  0.0298],\n",
      "          [-0.1056,  0.1267,  0.1268],\n",
      "          [ 0.0306, -0.0873, -0.0597]]],\n",
      "\n",
      "\n",
      "        [[[-0.0423, -0.0951, -0.0776],\n",
      "          [-0.0437, -0.0467,  0.0623],\n",
      "          [-0.0842, -0.0220, -0.0610]],\n",
      "\n",
      "         [[-0.1647,  0.1884,  0.0755],\n",
      "          [ 0.1733, -0.0268, -0.0287],\n",
      "          [-0.1865, -0.0679,  0.1453]],\n",
      "\n",
      "         [[-0.2334, -0.0524,  0.1486],\n",
      "          [ 0.0959,  0.0798, -0.0187],\n",
      "          [-0.0479, -0.0331, -0.0541]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0803, -0.0655, -0.1120],\n",
      "          [ 0.0373, -0.1455, -0.0480],\n",
      "          [ 0.0915,  0.0650,  0.1555]],\n",
      "\n",
      "         [[-0.1313,  0.0017, -0.0688],\n",
      "          [-0.1140, -0.1146,  0.0363],\n",
      "          [ 0.0121, -0.1063, -0.1496]],\n",
      "\n",
      "         [[-0.1595,  0.1886, -0.0367],\n",
      "          [-0.0509, -0.0771, -0.1032],\n",
      "          [-0.1841, -0.1211,  0.1037]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0630, -0.0469, -0.0607],\n",
      "          [ 0.1547,  0.1783,  0.2135],\n",
      "          [ 0.0837,  0.1271,  0.0096]],\n",
      "\n",
      "         [[-0.0968, -0.1740,  0.1216],\n",
      "          [-0.0192,  0.0864, -0.0020],\n",
      "          [-0.1797, -0.0960,  0.0379]],\n",
      "\n",
      "         [[-0.0228, -0.1693,  0.0748],\n",
      "          [ 0.0179, -0.0508,  0.0705],\n",
      "          [ 0.0444, -0.0672,  0.1627]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0716,  0.0016, -0.0477],\n",
      "          [-0.1826,  0.1357, -0.0503],\n",
      "          [-0.1549,  0.0890,  0.0559]],\n",
      "\n",
      "         [[ 0.0299, -0.0537, -0.0748],\n",
      "          [ 0.0190,  0.1382,  0.0186],\n",
      "          [-0.1109,  0.1729, -0.0093]],\n",
      "\n",
      "         [[ 0.1371,  0.0355,  0.1676],\n",
      "          [ 0.1023, -0.1036,  0.1363],\n",
      "          [ 0.0028, -0.1534, -0.0345]]],\n",
      "\n",
      "\n",
      "        [[[-0.1878, -0.0961, -0.1862],\n",
      "          [ 0.1276, -0.0286, -0.1321],\n",
      "          [ 0.0879,  0.0954, -0.1674]],\n",
      "\n",
      "         [[ 0.0683,  0.0924, -0.1569],\n",
      "          [ 0.1768, -0.0946, -0.0675],\n",
      "          [-0.1309,  0.2184,  0.0610]],\n",
      "\n",
      "         [[ 0.1470,  0.0162,  0.0548],\n",
      "          [-0.0734, -0.1432, -0.0683],\n",
      "          [-0.0207,  0.0009, -0.1336]]]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0024,  0.0884,  0.0776, -0.1712,  0.1076,  0.0544,  0.1865,  0.1436,\n",
      "        -0.1505,  0.1998, -0.1732,  0.1532,  0.0702,  0.0994, -0.0943,  0.1655],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-0.0533, -0.0849,  0.0223],\n",
      "          [ 0.0397,  0.0725, -0.0155],\n",
      "          [ 0.0768,  0.0457, -0.0464]],\n",
      "\n",
      "         [[-0.0921,  0.0486, -0.0457],\n",
      "          [ 0.0206, -0.0678,  0.0651],\n",
      "          [ 0.0086, -0.0187,  0.0238]],\n",
      "\n",
      "         [[-0.0701, -0.0258, -0.0075],\n",
      "          [-0.0576, -0.0288, -0.0439],\n",
      "          [ 0.0725,  0.0620,  0.0619]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0215, -0.0630, -0.0567],\n",
      "          [ 0.0211, -0.0156,  0.0439],\n",
      "          [-0.0046, -0.0823, -0.0771]],\n",
      "\n",
      "         [[-0.0334, -0.0263, -0.0007],\n",
      "          [-0.0279,  0.0225, -0.0361],\n",
      "          [ 0.0518,  0.0099, -0.0354]],\n",
      "\n",
      "         [[ 0.0580,  0.0382, -0.0407],\n",
      "          [-0.0796,  0.0692,  0.0512],\n",
      "          [ 0.0278,  0.0011,  0.0546]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0316,  0.0154, -0.0291],\n",
      "          [ 0.0706,  0.0064, -0.0315],\n",
      "          [-0.0114,  0.0707,  0.0452]],\n",
      "\n",
      "         [[-0.0211,  0.0681,  0.0217],\n",
      "          [-0.0572, -0.0892,  0.0356],\n",
      "          [ 0.0657, -0.0615,  0.0199]],\n",
      "\n",
      "         [[-0.0093, -0.0302, -0.0348],\n",
      "          [ 0.0103,  0.0061,  0.0441],\n",
      "          [ 0.0178,  0.0257,  0.0615]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0769, -0.0303, -0.0269],\n",
      "          [ 0.0577, -0.0562, -0.0607],\n",
      "          [-0.0120, -0.0325,  0.0185]],\n",
      "\n",
      "         [[-0.0026, -0.0622,  0.0483],\n",
      "          [ 0.0392,  0.0059, -0.0877],\n",
      "          [ 0.0266,  0.0431,  0.0110]],\n",
      "\n",
      "         [[-0.0438, -0.0107, -0.0444],\n",
      "          [ 0.0670,  0.0646, -0.0242],\n",
      "          [-0.0668,  0.0347,  0.0306]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0299, -0.0814,  0.0102],\n",
      "          [-0.0453, -0.0885, -0.0681],\n",
      "          [ 0.0392,  0.0317, -0.0695]],\n",
      "\n",
      "         [[ 0.0423,  0.0580,  0.0553],\n",
      "          [ 0.0479, -0.0138,  0.0502],\n",
      "          [ 0.0747,  0.0500, -0.0588]],\n",
      "\n",
      "         [[-0.0438,  0.0558,  0.0565],\n",
      "          [ 0.0424, -0.0441, -0.0244],\n",
      "          [-0.0751, -0.0594,  0.0504]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0172, -0.0510,  0.0314],\n",
      "          [-0.0915, -0.0944, -0.0638],\n",
      "          [-0.0754,  0.0330, -0.0117]],\n",
      "\n",
      "         [[-0.0508,  0.0508, -0.0255],\n",
      "          [ 0.0426, -0.0316, -0.0747],\n",
      "          [ 0.0209,  0.0489, -0.0843]],\n",
      "\n",
      "         [[-0.0920, -0.0836, -0.0890],\n",
      "          [-0.0997, -0.1235, -0.1507],\n",
      "          [-0.0750, -0.1393, -0.1395]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0298,  0.0123,  0.0138],\n",
      "          [ 0.0059,  0.0655,  0.0629],\n",
      "          [-0.0795,  0.0057,  0.0104]],\n",
      "\n",
      "         [[ 0.0022, -0.0433,  0.0172],\n",
      "          [-0.0323,  0.0282,  0.0101],\n",
      "          [ 0.0474, -0.0182, -0.0365]],\n",
      "\n",
      "         [[ 0.0508,  0.0408,  0.0146],\n",
      "          [-0.0954,  0.0212, -0.0060],\n",
      "          [-0.0976, -0.0950, -0.0008]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0715, -0.0915,  0.0537],\n",
      "          [-0.0568,  0.0585, -0.0747],\n",
      "          [ 0.0343, -0.0463,  0.0433]],\n",
      "\n",
      "         [[ 0.0681,  0.0568, -0.0564],\n",
      "          [-0.0376, -0.0663, -0.0271],\n",
      "          [ 0.0108,  0.0436, -0.0532]],\n",
      "\n",
      "         [[ 0.0560, -0.0236, -0.0137],\n",
      "          [-0.0423,  0.0060, -0.0035],\n",
      "          [ 0.0647,  0.0428,  0.0404]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0367, -0.0116,  0.0410],\n",
      "          [ 0.0531,  0.0497,  0.0447],\n",
      "          [-0.0400, -0.0059, -0.0419]],\n",
      "\n",
      "         [[ 0.0289, -0.0379, -0.1008],\n",
      "          [-0.0494, -0.0829, -0.0003],\n",
      "          [ 0.0477, -0.0192, -0.0488]],\n",
      "\n",
      "         [[-0.0401, -0.0801,  0.0238],\n",
      "          [ 0.0352, -0.0726,  0.0462],\n",
      "          [ 0.0150, -0.0865,  0.0372]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0344, -0.0179, -0.0985],\n",
      "          [ 0.0200, -0.0480, -0.0598],\n",
      "          [ 0.0176,  0.0055, -0.0671]],\n",
      "\n",
      "         [[ 0.0165, -0.0032, -0.0408],\n",
      "          [ 0.0423, -0.0111,  0.0237],\n",
      "          [-0.0312,  0.0146,  0.0065]],\n",
      "\n",
      "         [[ 0.0551, -0.0858, -0.0312],\n",
      "          [ 0.0341, -0.0529, -0.0760],\n",
      "          [ 0.0413,  0.0232,  0.0536]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0068, -0.0397, -0.0725],\n",
      "          [-0.0886,  0.0079, -0.0236],\n",
      "          [ 0.0521,  0.0361, -0.0012]],\n",
      "\n",
      "         [[ 0.0752,  0.0173,  0.0018],\n",
      "          [ 0.0743, -0.0103,  0.0082],\n",
      "          [-0.0091,  0.0822,  0.0101]],\n",
      "\n",
      "         [[-0.0425, -0.0931, -0.0119],\n",
      "          [-0.0110,  0.0169,  0.0133],\n",
      "          [-0.0822, -0.0914, -0.0494]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0123, -0.0268,  0.0009],\n",
      "          [ 0.0417,  0.0465,  0.0206],\n",
      "          [-0.0351, -0.0844,  0.0249]],\n",
      "\n",
      "         [[ 0.0318, -0.0135, -0.0124],\n",
      "          [ 0.0177, -0.0760, -0.0900],\n",
      "          [-0.0782, -0.0101, -0.0809]],\n",
      "\n",
      "         [[-0.0070,  0.0128,  0.1152],\n",
      "          [ 0.0455,  0.0658,  0.0718],\n",
      "          [-0.0173,  0.0390,  0.0819]]]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0516,  0.0471, -0.0877,  0.0489,  0.0181, -0.0430,  0.0276, -0.0058,\n",
      "        -0.0830, -0.0677, -0.0479,  0.0168, -0.0162, -0.0714,  0.0667,  0.0267,\n",
      "         0.0182, -0.0996,  0.0194,  0.0498, -0.0605, -0.0615, -0.0331, -0.0412,\n",
      "         0.0530,  0.0592,  0.0598, -0.0466, -0.0760, -0.0213, -0.0852, -0.0411],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0062, -0.0029, -0.0014,  ..., -0.0049, -0.0075, -0.0063],\n",
      "        [-0.0014, -0.0050, -0.0056,  ..., -0.0054, -0.0044, -0.0066],\n",
      "        [-0.0060, -0.0080, -0.0058,  ..., -0.0066, -0.0065, -0.0090],\n",
      "        ...,\n",
      "        [-0.0073, -0.0063, -0.0063,  ..., -0.0033, -0.0072, -0.0036],\n",
      "        [-0.0029, -0.0067, -0.0082,  ..., -0.0063, -0.0049, -0.0080],\n",
      "        [-0.0067, -0.0056, -0.0077,  ..., -0.0091, -0.0028, -0.0033]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0062, -0.0023, -0.0033, -0.0074,  0.0050, -0.0044, -0.0045, -0.0071,\n",
      "         0.0104, -0.0031, -0.0052, -0.0025, -0.0008, -0.0022,  0.0007, -0.0046,\n",
      "        -0.0051, -0.0058, -0.0041, -0.0068,  0.0004, -0.0116, -0.0054, -0.0085,\n",
      "         0.0098, -0.0070, -0.0035, -0.0067, -0.0031, -0.0059, -0.0026, -0.0062,\n",
      "        -0.0064, -0.0021, -0.0074, -0.0064, -0.0049, -0.0049, -0.0053, -0.0022,\n",
      "        -0.0072, -0.0066, -0.0064,  0.0141, -0.0010, -0.0081, -0.0055, -0.0065,\n",
      "        -0.0045, -0.0058, -0.0075, -0.0021,  0.0180, -0.0027, -0.0020, -0.0038,\n",
      "        -0.0045, -0.0048,  0.0077, -0.0047, -0.0025, -0.0035, -0.0036, -0.0045],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.4408, -0.6473],\n",
      "        [ 0.3214, -0.5338],\n",
      "        [-0.5524, -0.0300],\n",
      "        [ 0.0781,  0.2974],\n",
      "        [ 0.4653,  0.3796],\n",
      "        [-0.3456,  0.5434],\n",
      "        [ 0.4013,  0.1099],\n",
      "        [ 0.6455, -0.0292],\n",
      "        [-0.2826, -0.1176],\n",
      "        [ 0.6502,  0.3060],\n",
      "        [-0.3919, -0.2793],\n",
      "        [-0.0238, -0.5866],\n",
      "        [-0.2056, -0.0434],\n",
      "        [ 0.0577,  0.4798],\n",
      "        [-0.0704, -0.1586],\n",
      "        [ 0.3905,  0.2520],\n",
      "        [ 0.1698, -0.1374],\n",
      "        [ 0.6216,  0.2742],\n",
      "        [ 0.6955, -0.2198],\n",
      "        [-0.2783,  0.4363],\n",
      "        [-0.6556,  0.2699],\n",
      "        [-0.2115, -0.6322],\n",
      "        [ 0.3927, -0.4315],\n",
      "        [ 0.1099, -0.1163],\n",
      "        [-0.0907, -0.1524],\n",
      "        [-0.0055,  0.0780],\n",
      "        [ 0.0535,  0.6497],\n",
      "        [ 0.2457,  0.5451],\n",
      "        [ 0.3986, -0.6274],\n",
      "        [ 0.2763,  0.3160],\n",
      "        [ 0.2064, -0.1198],\n",
      "        [ 0.2307,  0.0449],\n",
      "        [ 0.2097, -0.3338],\n",
      "        [-0.0754,  0.3797],\n",
      "        [-0.4450,  0.6050],\n",
      "        [-0.1916, -0.3469],\n",
      "        [ 0.3691, -0.3066],\n",
      "        [ 0.6709, -0.7048],\n",
      "        [-0.6066, -0.3085],\n",
      "        [-0.0753, -0.1131],\n",
      "        [-0.3263,  0.4581],\n",
      "        [-0.7060, -0.6339],\n",
      "        [-0.6918, -0.3144],\n",
      "        [ 0.4149, -0.4078],\n",
      "        [-0.0662,  0.4919],\n",
      "        [ 0.1561, -0.5941],\n",
      "        [ 0.1962, -0.0216],\n",
      "        [ 0.3802, -0.6525],\n",
      "        [-0.5557,  0.3687],\n",
      "        [ 0.4240,  0.1734],\n",
      "        [ 0.0134,  0.3288],\n",
      "        [ 0.0571, -0.5822],\n",
      "        [-0.4413,  0.1468],\n",
      "        [ 0.4145, -0.1158],\n",
      "        [ 0.3021,  0.3416],\n",
      "        [ 0.4670, -0.4488],\n",
      "        [-0.3569, -0.3838],\n",
      "        [-0.5419, -0.4666],\n",
      "        [ 0.6308,  0.4286],\n",
      "        [ 0.3115,  0.1654],\n",
      "        [ 0.3842,  0.1495],\n",
      "        [-0.5981, -0.5285],\n",
      "        [-0.1120,  0.1566],\n",
      "        [ 0.5327, -0.2854]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.3384,  0.5811,  0.2342,  0.1066,  0.1206,  0.2553, -0.2695,  0.1572,\n",
      "        -0.4502,  0.3731, -0.3635, -0.3466, -0.6913,  0.4205,  0.4828, -0.6151,\n",
      "        -0.1391,  0.3389, -0.5966,  0.5077,  0.1646, -0.4841, -0.1829,  0.2763,\n",
      "         0.1382, -0.5994, -0.2176,  0.0628,  0.2769,  0.0618,  0.5208,  0.1309,\n",
      "         0.1974, -0.0131,  0.0396,  0.1978,  0.6517,  0.3176, -0.4428,  0.0306,\n",
      "         0.5471, -0.4798, -0.3811,  0.5035, -0.2712,  0.5250, -0.0741, -0.0722,\n",
      "        -0.4413, -0.5066, -0.3481, -0.5243, -0.3821,  0.3190, -0.4985, -0.2186,\n",
      "        -0.0199,  0.6705,  0.1360,  0.1019, -0.3767,  0.0064,  0.3198, -0.6834],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0733, -0.0076,  0.0652,  ...,  0.0174,  0.0224, -0.0061],\n",
      "        [ 0.0233,  0.0819, -0.0582,  ...,  0.0181,  0.0452,  0.0362],\n",
      "        [-0.0724,  0.0755,  0.0355,  ..., -0.0067,  0.0493,  0.0592],\n",
      "        ...,\n",
      "        [ 0.0145,  0.0492,  0.0589,  ..., -0.0459,  0.0688,  0.0417],\n",
      "        [ 0.0063, -0.0344, -0.0662,  ...,  0.0069, -0.0009, -0.0336],\n",
      "        [ 0.0424, -0.0082, -0.0378,  ..., -0.0458,  0.0409, -0.0475]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0401, -0.0753,  0.0616,  0.0233, -0.0046, -0.0803, -0.0645, -0.0694,\n",
      "         0.0625,  0.0799, -0.0743,  0.0474, -0.0587,  0.0168, -0.0889,  0.0145,\n",
      "         0.0322, -0.0030,  0.0157,  0.0252,  0.0382, -0.0589, -0.0441, -0.0884,\n",
      "         0.0596, -0.1126, -0.0624,  0.0760,  0.0495,  0.0691, -0.0507,  0.0769,\n",
      "         0.0491, -0.0511, -0.0787,  0.0018,  0.0704,  0.0380,  0.0672, -0.0573,\n",
      "         0.0227,  0.0372, -0.0624,  0.0241, -0.0836, -0.0574, -0.0167,  0.0025,\n",
      "        -0.0009, -0.0452, -0.0523, -0.0614,  0.0246, -0.0435, -0.0448, -0.0422,\n",
      "         0.0092,  0.0540,  0.0919, -0.0848, -0.0201,  0.0058, -0.0757,  0.0813],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0532, -0.0007, -0.0832,  ..., -0.1728, -0.0968,  0.1201],\n",
      "        [-0.0592, -0.1135, -0.0094,  ...,  0.1054, -0.0930, -0.0850],\n",
      "        [-0.0165,  0.0266, -0.0523,  ...,  0.0816, -0.0930, -0.0734],\n",
      "        ...,\n",
      "        [ 0.1081,  0.0178, -0.0219,  ..., -0.0236, -0.0817,  0.0114],\n",
      "        [ 0.0337,  0.1131,  0.0926,  ..., -0.0356, -0.0773, -0.0269],\n",
      "        [-0.0964,  0.0282,  0.0003,  ...,  0.0367, -0.0301,  0.0809]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1086,  0.0613, -0.1097, -0.0214, -0.0272,  0.0459, -0.0770, -0.0788,\n",
      "        -0.0034,  0.0069, -0.0650,  0.0557, -0.0962,  0.0117, -0.0934, -0.0544,\n",
      "        -0.1030,  0.1381, -0.1245, -0.0060,  0.0641,  0.1103,  0.0030, -0.0250,\n",
      "         0.0604, -0.0279, -0.0097,  0.0340,  0.0244,  0.0073,  0.0124, -0.0280,\n",
      "        -0.0588, -0.0401,  0.0169, -0.1149, -0.0946,  0.0419,  0.0714, -0.0102,\n",
      "        -0.0188,  0.1001, -0.0699, -0.0992, -0.0669,  0.0974, -0.0328, -0.0796,\n",
      "        -0.0414,  0.0512, -0.1078,  0.0624,  0.0171, -0.1043, -0.0175,  0.0267,\n",
      "         0.0097, -0.0487, -0.0153, -0.0100, -0.1023, -0.0600,  0.0201,  0.0089],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0948,  0.1049, -0.0309,  0.0383,  0.0787,  0.0664,  0.0766, -0.1154,\n",
      "         -0.0148,  0.0041, -0.0186, -0.0336, -0.0955, -0.0519, -0.0519,  0.0167,\n",
      "         -0.0817, -0.0461, -0.0536, -0.1170,  0.1026, -0.0418, -0.0982,  0.0271,\n",
      "         -0.1102, -0.1313,  0.0649, -0.0203,  0.1146, -0.0760, -0.1101,  0.0848,\n",
      "         -0.1240, -0.0982, -0.0002, -0.0571, -0.1069,  0.0136,  0.1022,  0.1222,\n",
      "         -0.0543, -0.0958,  0.0195,  0.0147,  0.0468, -0.1099,  0.0124, -0.0255,\n",
      "          0.0395, -0.0844,  0.0641, -0.0967, -0.0642,  0.0189, -0.0694,  0.0919,\n",
      "          0.0500,  0.1027, -0.0221, -0.0638,  0.0616, -0.0911,  0.0205,  0.0940],\n",
      "        [-0.0192, -0.1141, -0.0836, -0.1053, -0.0988,  0.0740, -0.1049,  0.0630,\n",
      "          0.0981, -0.1043, -0.1146, -0.0201, -0.0765, -0.0353, -0.0143,  0.0399,\n",
      "          0.0818,  0.0962,  0.0507,  0.0521,  0.0212,  0.0451, -0.0175, -0.0552,\n",
      "         -0.1133, -0.0859,  0.0172, -0.0374, -0.0446,  0.0080,  0.0140, -0.0987,\n",
      "         -0.0368, -0.0585, -0.0693, -0.0110,  0.0199, -0.0772,  0.0339,  0.0714,\n",
      "          0.0003, -0.0623, -0.0383, -0.0872, -0.0744,  0.1043,  0.0631, -0.0535,\n",
      "         -0.0974,  0.0784, -0.0544,  0.0456, -0.0183, -0.1041, -0.0191,  0.0562,\n",
      "          0.0556,  0.1051, -0.0630,  0.0744,  0.0605,  0.0925,  0.0887, -0.1188],\n",
      "        [ 0.0307,  0.0405, -0.0878,  0.0811,  0.0231,  0.0559,  0.0482, -0.0577,\n",
      "          0.0169,  0.0143, -0.0934, -0.0527, -0.1295, -0.0876, -0.0250,  0.0495,\n",
      "         -0.0250,  0.0981,  0.0833,  0.0448, -0.0609, -0.0364,  0.0915, -0.1171,\n",
      "          0.0340,  0.0763,  0.0383, -0.0771, -0.1191, -0.0430,  0.0009,  0.0859,\n",
      "          0.0499,  0.0697,  0.0444, -0.0842,  0.0191, -0.0127, -0.0649, -0.1046,\n",
      "          0.0173,  0.0423,  0.0426,  0.0245,  0.1148,  0.0151,  0.0256,  0.0804,\n",
      "          0.0167,  0.0318, -0.0220,  0.0535, -0.1125,  0.0050,  0.0408,  0.0091,\n",
      "          0.0740,  0.1166, -0.0003,  0.0960, -0.0315, -0.0570, -0.0141,  0.0965]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0981,  0.0050,  0.0551], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "## OBSERVE THE WEIGHTS after training\n",
    "for p in bf.parameters():\n",
    "    print(p)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T13:22:42.123014Z",
     "start_time": "2024-07-09T13:22:41.995980Z"
    }
   },
   "id": "75764cd252f09ffc",
   "execution_count": 44
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
